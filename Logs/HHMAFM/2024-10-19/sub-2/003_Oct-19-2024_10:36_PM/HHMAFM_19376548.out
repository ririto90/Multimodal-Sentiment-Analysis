Number of GPUs available: 2
Logs directory: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-19-sub_1/003_Oct-19-2024_10:36_PM
/home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-19-sub_1/003_Oct-19-2024_10:36_PM
> training arguments:
>>> rand_seed: 8
>>> model_name: mfcchfusion2
>>> dataset: mvsa-mts
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7fa739d49a80>
>>> learning_rate: 0.001
>>> dropout_rate: 0.5
>>> num_epoch: 10
>>> batch_size: 128
>>> log_step: 20
>>> max_seq_len: 64
>>> polarities_dim: 3
>>> clip_grad: 5.0
>>> path_image: ./Datasets/MVSA-MTS/images-indexed
>>> crop_size: 224
>>> roberta_text_feature_dim: 768
>>> roberta_topic_feature_dim: 50
>>> resnet_feature_dim: 2048
>>> densenet_feature_dim: 1024
>>> common_dim: 512
>>> num_classes: 3
>>> model_class: <class 'models.mfcchfusion2.MFCCHFUSION2'>
Preparing mvsa-mts dataset...
-------------- Loading Datasets/MVSA-MTS/mvsa-mts/train.tsv ---------------
Time taken to load Datasets/MVSA-MTS/mvsa-mts/train.tsv: 266.79 seconds (4.45 minutes)
The number of problematic samples: 402
-------------- Loading Datasets/MVSA-MTS/mvsa-mts/val.tsv ---------------
Time taken to load Datasets/MVSA-MTS/mvsa-mts/val.tsv: 88.98 seconds (1.48 minutes)
The number of problematic samples: 136
-------------- Loading Datasets/MVSA-MTS/mvsa-mts/test.tsv ---------------
Time taken to load Datasets/MVSA-MTS/mvsa-mts/test.tsv: 87.20 seconds (1.45 minutes)
The number of problematic samples: 142
Total Training Samples: 19600
Number of Training Samples: 11760
Number of Development Samples: 3920
Number of Test Samples: 3920
Number of unique sentiment classes: 3
building model
Using 2 GPUs
n_trainable_params: 11225091, n_nontrainable_params: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
Batch 0 completed in 4.24 seconds (0.07 minutes)
max_dev_f1: 0, max_test_f1: 0
loss: 0.965883, dev_acc: 52.91% (0.529082), dev_f1: 23.07% (0.230675), test_acc: 53.78% (0.537755), test_f1: 23.31% (0.233134)
Batch 20 completed in 1.24 seconds (0.02 minutes)
max_dev_f1: 0.23067511956400844, max_test_f1: 0.23313426233134263
loss: 5.757807, dev_acc: 43.70% (0.436990), dev_f1: 28.85% (0.288460), test_acc: 41.05% (0.410459), test_f1: 27.53% (0.275335)
Batch 40 completed in 1.24 seconds (0.02 minutes)
loss: 2.769679, dev_acc: 35.33% (0.353316), dev_f1: 24.92% (0.249218), test_acc: 34.21% (0.342092), test_f1: 26.06% (0.260562)
Batch 60 completed in 1.23 seconds (0.02 minutes)
loss: 9.862617, dev_acc: 35.71% (0.357143), dev_f1: 28.00% (0.280005), test_acc: 35.38% (0.353827), test_f1: 26.74% (0.267365)
Batch 80 completed in 1.31 seconds (0.02 minutes)
max_dev_f1: 0.28845985081175957, max_test_f1: 0.27533513335924625
loss: 3.479362, dev_acc: 44.72% (0.447194), dev_f1: 30.64% (0.306446), test_acc: 45.69% (0.456888), test_f1: 31.30% (0.312984)
Epoch 0 completed in 363.55 seconds (6.06 minutes), avg loss: 6.587410
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
Batch 0 completed in 1.25 seconds (0.02 minutes)
loss: 2.237426, dev_acc: 22.50% (0.225000), dev_f1: 21.81% (0.218091), test_acc: 24.34% (0.243367), test_f1: 24.03% (0.240286)
Batch 20 completed in 1.25 seconds (0.02 minutes)
loss: 1.974571, dev_acc: 46.91% (0.469133), dev_f1: 29.08% (0.290805), test_acc: 46.73% (0.467347), test_f1: 30.55% (0.305506)
Batch 40 completed in 1.31 seconds (0.02 minutes)
max_dev_f1: 0.3064455833867947, max_test_f1: 0.31298406940635953
loss: 3.288601, dev_acc: 48.55% (0.485459), dev_f1: 30.82% (0.308232), test_acc: 49.01% (0.490051), test_f1: 32.02% (0.320172)
Batch 60 completed in 1.60 seconds (0.03 minutes)
loss: 5.556557, dev_acc: 40.13% (0.401276), dev_f1: 20.28% (0.202766), test_acc: 39.06% (0.390561), test_f1: 20.34% (0.203366)
Batch 80 completed in 1.30 seconds (0.02 minutes)
loss: 5.577919, dev_acc: 41.02% (0.410204), dev_f1: 22.61% (0.226103), test_acc: 39.62% (0.396173), test_f1: 21.45% (0.214541)
Epoch 1 completed in 363.19 seconds (6.05 minutes), avg loss: 4.693917
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
Batch 0 completed in 1.25 seconds (0.02 minutes)
max_dev_f1: 0.3082318953277215, max_test_f1: 0.3201720376065513
loss: 12.701484, dev_acc: 50.59% (0.505867), dev_f1: 31.37% (0.313684), test_acc: 50.56% (0.505612), test_f1: 31.05% (0.310501)
Batch 20 completed in 1.23 seconds (0.02 minutes)
loss: 7.117821, dev_acc: 49.72% (0.497194), dev_f1: 29.48% (0.294813), test_acc: 50.46% (0.504592), test_f1: 29.03% (0.290273)
Batch 40 completed in 1.25 seconds (0.02 minutes)
loss: 7.483806, dev_acc: 52.91% (0.529082), dev_f1: 23.07% (0.230675), test_acc: 53.52% (0.535204), test_f1: 24.16% (0.241627)
Batch 60 completed in 1.24 seconds (0.02 minutes)
loss: 3.323912, dev_acc: 41.30% (0.413010), dev_f1: 24.75% (0.247495), test_acc: 42.78% (0.427806), test_f1: 28.30% (0.282968)
Batch 80 completed in 1.25 seconds (0.02 minutes)
loss: 3.142597, dev_acc: 48.21% (0.482143), dev_f1: 30.58% (0.305760), test_acc: 50.94% (0.509439), test_f1: 30.38% (0.303825)
Epoch 2 completed in 366.34 seconds (6.11 minutes), avg loss: 4.364206
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
Batch 0 completed in 1.25 seconds (0.02 minutes)
max_dev_f1: 0.3136838700293068, max_test_f1: 0.31050068532700803
loss: 1.888803, dev_acc: 46.99% (0.469898), dev_f1: 32.38% (0.323800), test_acc: 46.07% (0.460714), test_f1: 31.31% (0.313093)
Batch 20 completed in 1.29 seconds (0.02 minutes)
loss: 2.590301, dev_acc: 48.19% (0.481888), dev_f1: 31.63% (0.316311), test_acc: 51.30% (0.513010), test_f1: 29.09% (0.290925)
Batch 40 completed in 1.25 seconds (0.02 minutes)
loss: 1.303770, dev_acc: 52.04% (0.520408), dev_f1: 23.50% (0.234957), test_acc: 51.35% (0.513520), test_f1: 24.51% (0.245110)
Batch 60 completed in 1.25 seconds (0.02 minutes)
loss: 1.319070, dev_acc: 40.69% (0.406888), dev_f1: 23.90% (0.238960), test_acc: 38.67% (0.386735), test_f1: 26.11% (0.261068)
Batch 80 completed in 1.25 seconds (0.02 minutes)
loss: 1.409796, dev_acc: 48.90% (0.489031), dev_f1: 30.36% (0.303552), test_acc: 48.27% (0.482653), test_f1: 31.99% (0.319911)
Epoch 3 completed in 366.16 seconds (6.10 minutes), avg loss: 1.768321
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
Batch 0 completed in 1.24 seconds (0.02 minutes)
loss: 1.085328, dev_acc: 44.01% (0.440051), dev_f1: 29.82% (0.298188), test_acc: 42.55% (0.425510), test_f1: 28.08% (0.280840)
Batch 20 completed in 1.25 seconds (0.02 minutes)
loss: 2.429436, dev_acc: 49.82% (0.498214), dev_f1: 31.95% (0.319471), test_acc: 50.03% (0.500255), test_f1: 30.51% (0.305123)
Batch 40 completed in 1.25 seconds (0.02 minutes)
loss: 1.404494, dev_acc: 49.44% (0.494388), dev_f1: 31.26% (0.312590), test_acc: 48.49% (0.484949), test_f1: 32.38% (0.323771)
Batch 60 completed in 1.23 seconds (0.02 minutes)
loss: 2.190345, dev_acc: 36.76% (0.367602), dev_f1: 30.82% (0.308234), test_acc: 39.34% (0.393367), test_f1: 30.80% (0.308042)
Batch 80 completed in 1.24 seconds (0.02 minutes)
loss: 1.778341, dev_acc: 45.82% (0.458163), dev_f1: 26.46% (0.264579), test_acc: 45.66% (0.456633), test_f1: 26.79% (0.267932)
Epoch 4 completed in 366.17 seconds (6.10 minutes), avg loss: 1.644349
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
Batch 0 completed in 1.25 seconds (0.02 minutes)
loss: 1.167238, dev_acc: 50.51% (0.505102), dev_f1: 30.60% (0.306013), test_acc: 50.38% (0.503827), test_f1: 31.78% (0.317839)
Batch 20 completed in 1.63 seconds (0.03 minutes)
loss: 2.724578, dev_acc: 41.99% (0.419898), dev_f1: 29.60% (0.296005), test_acc: 37.76% (0.377551), test_f1: 26.20% (0.262015)
Batch 40 completed in 1.25 seconds (0.02 minutes)
loss: 1.014104, dev_acc: 39.52% (0.395153), dev_f1: 27.13% (0.271308), test_acc: 39.72% (0.397194), test_f1: 24.38% (0.243775)
Batch 60 completed in 1.25 seconds (0.02 minutes)
loss: 1.146775, dev_acc: 51.81% (0.518112), dev_f1: 28.39% (0.283945), test_acc: 51.79% (0.517857), test_f1: 26.36% (0.263611)
Batch 80 completed in 1.24 seconds (0.02 minutes)
loss: 1.019482, dev_acc: 48.19% (0.481888), dev_f1: 31.09% (0.310893), test_acc: 50.69% (0.506888), test_f1: 30.12% (0.301228)
Epoch 5 completed in 366.61 seconds (6.11 minutes), avg loss: 1.310181
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
Batch 0 completed in 1.25 seconds (0.02 minutes)
loss: 1.050548, dev_acc: 47.40% (0.473980), dev_f1: 31.03% (0.310290), test_acc: 46.61% (0.466071), test_f1: 31.23% (0.312281)
Batch 20 completed in 1.25 seconds (0.02 minutes)
loss: 1.259100, dev_acc: 51.63% (0.516327), dev_f1: 26.67% (0.266653), test_acc: 52.53% (0.525255), test_f1: 26.15% (0.261463)
Batch 40 completed in 1.29 seconds (0.02 minutes)
loss: 0.874459, dev_acc: 42.22% (0.422194), dev_f1: 25.98% (0.259847), test_acc: 41.30% (0.413010), test_f1: 25.33% (0.253342)
Batch 60 completed in 1.56 seconds (0.03 minutes)
loss: 1.098394, dev_acc: 45.38% (0.453827), dev_f1: 31.24% (0.312411), test_acc: 43.60% (0.435969), test_f1: 31.31% (0.313097)
Batch 80 completed in 1.24 seconds (0.02 minutes)
max_dev_f1: 0.32379981601869495, max_test_f1: 0.31309329287270465
loss: 0.926701, dev_acc: 48.04% (0.480357), dev_f1: 32.65% (0.326522), test_acc: 49.36% (0.493622), test_f1: 32.78% (0.327750)
Epoch 6 completed in 365.08 seconds (6.08 minutes), avg loss: 1.099515
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 7
Batch 0 completed in 1.24 seconds (0.02 minutes)
loss: 1.117566, dev_acc: 50.82% (0.508163), dev_f1: 30.85% (0.308451), test_acc: 51.05% (0.510459), test_f1: 29.23% (0.292336)
Batch 20 completed in 1.30 seconds (0.02 minutes)
loss: 1.010953, dev_acc: 48.75% (0.487500), dev_f1: 29.93% (0.299321), test_acc: 51.43% (0.514286), test_f1: 30.47% (0.304674)
Batch 40 completed in 1.25 seconds (0.02 minutes)
loss: 0.925625, dev_acc: 46.15% (0.461480), dev_f1: 32.59% (0.325869), test_acc: 46.38% (0.463776), test_f1: 31.79% (0.317857)
Batch 60 completed in 1.25 seconds (0.02 minutes)
max_dev_f1: 0.32652203655674, max_test_f1: 0.3277500519858598
loss: 1.229640, dev_acc: 48.27% (0.482653), dev_f1: 32.78% (0.327792), test_acc: 45.08% (0.450765), test_f1: 31.15% (0.311487)
Batch 80 completed in 1.31 seconds (0.02 minutes)
loss: 1.013263, dev_acc: 48.83% (0.488265), dev_f1: 32.59% (0.325948), test_acc: 46.86% (0.468622), test_f1: 31.83% (0.318300)
Epoch 7 completed in 365.54 seconds (6.09 minutes), avg loss: 1.116926
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 8
Batch 0 completed in 1.25 seconds (0.02 minutes)
loss: 1.388101, dev_acc: 44.52% (0.445153), dev_f1: 30.49% (0.304920), test_acc: 44.90% (0.448980), test_f1: 31.07% (0.310703)
Batch 20 completed in 1.25 seconds (0.02 minutes)
loss: 0.984872, dev_acc: 51.33% (0.513265), dev_f1: 29.13% (0.291335), test_acc: 51.05% (0.510459), test_f1: 29.27% (0.292705)
Batch 40 completed in 1.25 seconds (0.02 minutes)
loss: 0.913701, dev_acc: 43.57% (0.435714), dev_f1: 29.46% (0.294595), test_acc: 46.51% (0.465051), test_f1: 32.21% (0.322055)
Batch 60 completed in 1.30 seconds (0.02 minutes)
loss: 1.355991, dev_acc: 45.66% (0.456633), dev_f1: 31.41% (0.314140), test_acc: 44.21% (0.442092), test_f1: 30.58% (0.305781)
Batch 80 completed in 1.26 seconds (0.02 minutes)
loss: 1.070676, dev_acc: 46.07% (0.460714), dev_f1: 31.79% (0.317949), test_acc: 45.28% (0.452806), test_f1: 31.23% (0.312330)
Epoch 8 completed in 366.52 seconds (6.11 minutes), avg loss: 1.070881
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 9
Batch 0 completed in 1.30 seconds (0.02 minutes)
loss: 1.308530, dev_acc: 47.24% (0.472449), dev_f1: 32.48% (0.324841), test_acc: 47.93% (0.479337), test_f1: 32.63% (0.326301)
Batch 20 completed in 1.24 seconds (0.02 minutes)
loss: 0.908444, dev_acc: 43.34% (0.433418), dev_f1: 28.67% (0.286672), test_acc: 42.50% (0.425000), test_f1: 28.71% (0.287141)
Batch 40 completed in 1.30 seconds (0.02 minutes)
loss: 0.922923, dev_acc: 46.40% (0.464031), dev_f1: 32.03% (0.320334), test_acc: 46.61% (0.466071), test_f1: 32.11% (0.321130)
Batch 60 completed in 1.24 seconds (0.02 minutes)
loss: 0.885081, dev_acc: 48.62% (0.486224), dev_f1: 32.33% (0.323295), test_acc: 46.15% (0.461480), test_f1: 31.89% (0.318859)
Batch 80 completed in 1.23 seconds (0.02 minutes)
loss: 1.666222, dev_acc: 52.91% (0.529082), dev_f1: 23.07% (0.230675), test_acc: 53.78% (0.537755), test_f1: 23.31% (0.233134)
Epoch 9 completed in 365.84 seconds (6.10 minutes), avg loss: 1.143509
Max dev F1: 32.78% (0.327792), Max test F1: 31.15% (0.311487)
Reading TensorBoard loss at each epoch:
Available tags: {'images': [], 'audio': [], 'histograms': [], 'scalars': ['Loss/train', 'Loss/epoch'], 'distributions': [], 'tensors': [], 'graph': False, 'meta_graph': False, 'run_metadata': []}
Step: 0, Loss: 0.9658833742141724
Step: 1, Loss: 17.734811782836914
Step: 2, Loss: 1.9901154041290283
Step: 3, Loss: 13.744185447692871
Step: 4, Loss: 8.254040718078613
Step: 5, Loss: 4.666070461273193
Step: 6, Loss: 2.7109291553497314
Step: 7, Loss: 6.655810356140137
Step: 8, Loss: 6.106093883514404
Step: 9, Loss: 8.661291122436523
Step: 10, Loss: 10.2314453125
Step: 11, Loss: 3.4951796531677246
Step: 12, Loss: 8.944292068481445
Step: 13, Loss: 12.714188575744629
Step: 14, Loss: 4.328388214111328
Step: 15, Loss: 9.355395317077637
Step: 16, Loss: 8.444023132324219
Step: 17, Loss: 5.842747688293457
Step: 18, Loss: 2.651099920272827
Step: 19, Loss: 10.54525375366211
Step: 20, Loss: 5.757806777954102
Step: 21, Loss: 4.063807487487793
Step: 22, Loss: 9.657251358032227
Step: 23, Loss: 5.0189528465271
Step: 24, Loss: 9.409256935119629
Step: 25, Loss: 10.02681827545166
Step: 26, Loss: 8.982380867004395
Step: 27, Loss: 12.299881935119629
Step: 28, Loss: 5.402188301086426
Step: 29, Loss: 7.3494343757629395
Step: 30, Loss: 11.707035064697266
Step: 31, Loss: 5.050357341766357
Step: 32, Loss: 4.860973834991455
Step: 33, Loss: 5.851895332336426
Step: 34, Loss: 6.953054428100586
Step: 35, Loss: 2.9375457763671875
Step: 36, Loss: 5.202291965484619
Step: 37, Loss: 5.172440528869629
Step: 38, Loss: 9.669500350952148
Step: 39, Loss: 3.4636669158935547
Step: 40, Loss: 2.769679307937622
Step: 41, Loss: 7.6639084815979
Step: 42, Loss: 12.254902839660645
Step: 43, Loss: 18.177513122558594
Step: 44, Loss: 16.20362091064453
Step: 45, Loss: 3.494765043258667
Step: 46, Loss: 3.42276668548584
Step: 47, Loss: 9.740373611450195
Step: 48, Loss: 9.865402221679688
Step: 49, Loss: 9.190296173095703
Step: 50, Loss: 7.213652610778809
Step: 51, Loss: 6.445893287658691
Step: 52, Loss: 3.7781827449798584
Step: 53, Loss: 2.971886396408081
Step: 54, Loss: 3.6955676078796387
Step: 55, Loss: 5.310943603515625
Step: 56, Loss: 5.777039527893066
Step: 57, Loss: 2.2292768955230713
Step: 58, Loss: 6.5359110832214355
Step: 59, Loss: 9.543098449707031
Step: 60, Loss: 9.862616539001465
Step: 61, Loss: 1.7891334295272827
Step: 62, Loss: 3.913817882537842
Step: 63, Loss: 11.971092224121094
Step: 64, Loss: 5.28804874420166
Step: 65, Loss: 10.455144882202148
Step: 66, Loss: 5.473638534545898
Step: 67, Loss: 11.280503273010254
Step: 68, Loss: 6.785408020019531
Step: 69, Loss: 14.365789413452148
Step: 70, Loss: 3.2830209732055664
Step: 71, Loss: 5.090258598327637
Step: 72, Loss: 3.095947027206421
Step: 73, Loss: 4.584803104400635
Step: 74, Loss: 3.0776891708374023
Step: 75, Loss: 3.224778175354004
Step: 76, Loss: 8.668905258178711
Step: 77, Loss: 1.6371861696243286
Step: 78, Loss: 4.414964199066162
Step: 79, Loss: 3.7302823066711426
Step: 80, Loss: 3.4793617725372314
Step: 81, Loss: 4.2639994621276855
Step: 82, Loss: 4.2972092628479
Step: 83, Loss: 5.879672050476074
Step: 84, Loss: 2.6631782054901123
Step: 85, Loss: 2.8612804412841797
Step: 86, Loss: 7.975544452667236
Step: 87, Loss: 4.867283344268799
Step: 88, Loss: 3.029564380645752
Step: 89, Loss: 2.9651646614074707
Step: 90, Loss: 2.3749687671661377
Step: 91, Loss: 6.22902774810791
Step: 92, Loss: 2.2374255657196045
Step: 93, Loss: 3.307089328765869
Step: 94, Loss: 3.845618724822998
Step: 95, Loss: 6.126893997192383
Step: 96, Loss: 5.444912910461426
Step: 97, Loss: 6.449763774871826
Step: 98, Loss: 5.634969711303711
Step: 99, Loss: 1.977913737297058
Step: 100, Loss: 6.060915470123291
Step: 101, Loss: 4.540301322937012
Step: 102, Loss: 3.23688006401062
Step: 103, Loss: 2.7891225814819336
Step: 104, Loss: 1.2893296480178833
Step: 105, Loss: 4.426721572875977
Step: 106, Loss: 2.657651424407959
Step: 107, Loss: 1.8466497659683228
Step: 108, Loss: 2.055769681930542
Step: 109, Loss: 2.9461679458618164
Step: 110, Loss: 3.751925230026245
Step: 111, Loss: 4.83428955078125
Step: 112, Loss: 1.974570631980896
Step: 113, Loss: 3.395357370376587
Step: 114, Loss: 5.280531406402588
Step: 115, Loss: 2.9296021461486816
Step: 116, Loss: 1.5723216533660889
Step: 117, Loss: 2.381610870361328
Step: 118, Loss: 6.585936546325684
Step: 119, Loss: 5.2387895584106445
Step: 120, Loss: 2.4469568729400635
Step: 121, Loss: 3.54294490814209
Step: 122, Loss: 5.230205059051514
Step: 123, Loss: 3.7911925315856934
Step: 124, Loss: 2.8033275604248047
Step: 125, Loss: 3.4703707695007324
Step: 126, Loss: 6.077250003814697
Step: 127, Loss: 3.479841947555542
Step: 128, Loss: 4.053150177001953
Step: 129, Loss: 6.341958522796631
Step: 130, Loss: 3.036297559738159
Step: 131, Loss: 3.890442132949829
Step: 132, Loss: 3.2886009216308594
Step: 133, Loss: 3.122781991958618
Step: 134, Loss: 2.383899688720703
Step: 135, Loss: 6.39674711227417
Step: 136, Loss: 2.967999219894409
Step: 137, Loss: 2.813778877258301
Step: 138, Loss: 2.9109272956848145
Step: 139, Loss: 1.7472333908081055
Step: 140, Loss: 3.1608827114105225
Step: 141, Loss: 1.0544819831848145
Step: 142, Loss: 2.3558197021484375
Step: 143, Loss: 2.3983211517333984
Step: 144, Loss: 1.8673053979873657
Step: 145, Loss: 2.4176082611083984
Step: 146, Loss: 3.289889335632324
Step: 147, Loss: 4.212676525115967
Step: 148, Loss: 2.6973583698272705
Step: 149, Loss: 4.61305046081543
Step: 150, Loss: 4.637548446655273
Step: 151, Loss: 2.8301429748535156
Step: 152, Loss: 5.556556701660156
Step: 153, Loss: 13.925884246826172
Step: 154, Loss: 4.178422451019287
Step: 155, Loss: 3.8447158336639404
Step: 156, Loss: 2.037285327911377
Step: 157, Loss: 1.205180048942566
Step: 158, Loss: 5.6282806396484375
Step: 159, Loss: 5.287210464477539
Step: 160, Loss: 10.436506271362305
Step: 161, Loss: 5.724642276763916
Step: 162, Loss: 3.7149078845977783
Step: 163, Loss: 4.714932918548584
Step: 164, Loss: 6.670050144195557
Step: 165, Loss: 8.604880332946777
Step: 166, Loss: 13.243617057800293
Step: 167, Loss: 7.936221122741699
Step: 168, Loss: 4.68687105178833
Step: 169, Loss: 7.0619049072265625
Step: 170, Loss: 8.997743606567383
Step: 171, Loss: 3.169102430343628
Step: 172, Loss: 5.577918529510498
Step: 173, Loss: 6.110825061798096
Step: 174, Loss: 7.227429389953613
Step: 175, Loss: 8.287775039672852
Step: 176, Loss: 8.521438598632812
Step: 177, Loss: 8.438573837280273
Step: 178, Loss: 11.93334674835205
Step: 179, Loss: 8.343328475952148
Step: 180, Loss: 6.405550479888916
Step: 181, Loss: 12.6483154296875
Step: 182, Loss: 3.635699987411499
Step: 183, Loss: 3.9352641105651855
Step: 184, Loss: 12.701483726501465
Step: 185, Loss: 6.998861312866211
Step: 186, Loss: 8.597994804382324
Step: 187, Loss: 5.9431376457214355
Step: 188, Loss: 4.318660736083984
Step: 189, Loss: 7.4365620613098145
Step: 190, Loss: 8.140307426452637
Step: 191, Loss: 6.003910541534424
Step: 192, Loss: 3.99176025390625
Step: 193, Loss: 5.359801292419434
Step: 194, Loss: 9.447336196899414
Step: 195, Loss: 5.223809719085693
Step: 196, Loss: 4.815363883972168
Step: 197, Loss: 10.233482360839844
Step: 198, Loss: 4.778442859649658
Step: 199, Loss: 1.900307536125183
Step: 200, Loss: 3.0316004753112793
Step: 201, Loss: 3.6780717372894287
Step: 202, Loss: 4.108208179473877
Step: 203, Loss: 5.469335556030273
Step: 204, Loss: 7.117820739746094
Step: 205, Loss: 5.40766716003418
Step: 206, Loss: 3.960435628890991
Step: 207, Loss: 5.345149517059326
Step: 208, Loss: 3.4489219188690186
Step: 209, Loss: 7.535974502563477
Step: 210, Loss: 4.361727714538574
Step: 211, Loss: 5.378649711608887
Step: 212, Loss: 4.514479637145996
Step: 213, Loss: 5.735114097595215
Step: 214, Loss: 3.8824026584625244
Step: 215, Loss: 3.7669599056243896
Step: 216, Loss: 3.461801052093506
Step: 217, Loss: 1.595298171043396
Step: 218, Loss: 4.6261982917785645
Step: 219, Loss: 3.850564479827881
Step: 220, Loss: 3.700470447540283
Step: 221, Loss: 12.770827293395996
Step: 222, Loss: 3.766230344772339
Step: 223, Loss: 6.947326183319092
Step: 224, Loss: 7.4838056564331055
Step: 225, Loss: 4.480201721191406
Step: 226, Loss: 2.8834736347198486
Step: 227, Loss: 4.893711090087891
Step: 228, Loss: 4.667180061340332
Step: 229, Loss: 3.890939474105835
Step: 230, Loss: 7.181168079376221
Step: 231, Loss: 3.467895030975342
Step: 232, Loss: 5.736648082733154
Step: 233, Loss: 2.2332468032836914
Step: 234, Loss: 2.195847749710083
Step: 235, Loss: 3.1742653846740723
Step: 236, Loss: 4.419005870819092
Step: 237, Loss: 1.0809407234191895
Step: 238, Loss: 3.3777599334716797
Step: 239, Loss: 4.283537864685059
Step: 240, Loss: 2.141744375228882
Step: 241, Loss: 14.529740333557129
Step: 242, Loss: 6.384852886199951
Step: 243, Loss: 2.762474536895752
Step: 244, Loss: 3.3239123821258545
Step: 245, Loss: 2.630713701248169
Step: 246, Loss: 1.63019597530365
Step: 247, Loss: 4.424744129180908
Step: 248, Loss: 2.073302984237671
Step: 249, Loss: 2.7816972732543945
Step: 250, Loss: 2.7559168338775635
Step: 251, Loss: 2.8431150913238525
Step: 252, Loss: 3.401522636413574
Step: 253, Loss: 2.686040163040161
Step: 254, Loss: 1.810484528541565
Step: 255, Loss: 1.9027587175369263
Step: 256, Loss: 2.720693588256836
Step: 257, Loss: 1.8346441984176636
Step: 258, Loss: 1.8260226249694824
Step: 259, Loss: 1.0601636171340942
Step: 260, Loss: 1.3819879293441772
Step: 261, Loss: 1.4981331825256348
Step: 262, Loss: 2.900493621826172
Step: 263, Loss: 7.673991680145264
Step: 264, Loss: 3.142596960067749
Step: 265, Loss: 1.8357480764389038
Step: 266, Loss: 1.7224359512329102
Step: 267, Loss: 1.8425564765930176
Step: 268, Loss: 3.8204140663146973
Step: 269, Loss: 2.687727928161621
Step: 270, Loss: 2.9806008338928223
Step: 271, Loss: 4.540009498596191
Step: 272, Loss: 3.538839817047119
Step: 273, Loss: 2.216798782348633
Step: 274, Loss: 2.784271001815796
Step: 275, Loss: 2.6135075092315674
Step: 276, Loss: 1.888803243637085
Step: 277, Loss: 2.107962131500244
Step: 278, Loss: 1.8773140907287598
Step: 279, Loss: 1.2924102544784546
Step: 280, Loss: 2.9818060398101807
Step: 281, Loss: 4.203466415405273
Step: 282, Loss: 1.6900317668914795
Step: 283, Loss: 1.3658562898635864
Step: 284, Loss: 4.8218817710876465
Step: 285, Loss: 2.5285279750823975
Step: 286, Loss: 1.7498408555984497
Step: 287, Loss: 3.711416482925415
Step: 288, Loss: 1.8410909175872803
Step: 289, Loss: 1.4548161029815674
Step: 290, Loss: 1.397107481956482
Step: 291, Loss: 2.1262764930725098
Step: 292, Loss: 2.984584093093872
Step: 293, Loss: 3.657571792602539
Step: 294, Loss: 1.9602912664413452
Step: 295, Loss: 1.5899853706359863
Step: 296, Loss: 2.5903005599975586
Step: 297, Loss: 1.1244105100631714
Step: 298, Loss: 2.340561866760254
Step: 299, Loss: 1.5147076845169067
Step: 300, Loss: 1.1295403242111206
Step: 301, Loss: 1.7890971899032593
Step: 302, Loss: 2.396606922149658
Step: 303, Loss: 1.3907979726791382
Step: 304, Loss: 1.798054575920105
Step: 305, Loss: 2.29421329498291
Step: 306, Loss: 1.499152421951294
Step: 307, Loss: 1.1377217769622803
Step: 308, Loss: 1.3886744976043701
Step: 309, Loss: 1.25346040725708
Step: 310, Loss: 1.437354564666748
Step: 311, Loss: 1.2821943759918213
Step: 312, Loss: 1.6697092056274414
Step: 313, Loss: 2.7898218631744385
Step: 314, Loss: 1.0835731029510498
Step: 315, Loss: 1.6484291553497314
Step: 316, Loss: 1.3037704229354858
Step: 317, Loss: 1.9821672439575195
Step: 318, Loss: 1.4456380605697632
Step: 319, Loss: 1.9153800010681152
Step: 320, Loss: 2.2063517570495605
Step: 321, Loss: 0.9682664275169373
Step: 322, Loss: 1.1018950939178467
Step: 323, Loss: 1.1173629760742188
Step: 324, Loss: 1.5500805377960205
Step: 325, Loss: 2.168320655822754
Step: 326, Loss: 2.3199315071105957
Step: 327, Loss: 1.478356957435608
Step: 328, Loss: 1.1821123361587524
Step: 329, Loss: 2.472963571548462
Step: 330, Loss: 2.4855778217315674
Step: 331, Loss: 1.6082450151443481
Step: 332, Loss: 0.9141865372657776
Step: 333, Loss: 2.1185152530670166
Step: 334, Loss: 1.0241820812225342
Step: 335, Loss: 1.1632853746414185
Step: 336, Loss: 1.319069504737854
Step: 337, Loss: 1.3184289932250977
Step: 338, Loss: 2.7274134159088135
Step: 339, Loss: 2.033761501312256
Step: 340, Loss: 1.3483737707138062
Step: 341, Loss: 1.4507789611816406
Step: 342, Loss: 2.827008008956909
Step: 343, Loss: 1.9544395208358765
Step: 344, Loss: 1.392008900642395
Step: 345, Loss: 1.9510318040847778
Step: 346, Loss: 1.815039873123169
Step: 347, Loss: 0.983176589012146
Step: 348, Loss: 2.0920729637145996
Step: 349, Loss: 1.169255018234253
Step: 350, Loss: 0.9724417328834534
Step: 351, Loss: 1.3186511993408203
Step: 352, Loss: 1.9106848239898682
Step: 353, Loss: 1.9222434759140015
Step: 354, Loss: 1.6914039850234985
Step: 355, Loss: 1.252498984336853
Step: 356, Loss: 1.4097962379455566
Step: 357, Loss: 1.1764445304870605
Step: 358, Loss: 2.030137538909912
Step: 359, Loss: 1.7333494424819946
Step: 360, Loss: 1.1223642826080322
Step: 361, Loss: 1.2658896446228027
Step: 362, Loss: 1.0109158754348755
Step: 363, Loss: 1.206589937210083
Step: 364, Loss: 0.8720465898513794
Step: 365, Loss: 1.3656260967254639
Step: 366, Loss: 1.4353564977645874
Step: 367, Loss: 1.291232705116272
Step: 368, Loss: 1.085328459739685
Step: 369, Loss: 2.0569567680358887
Step: 370, Loss: 1.7116235494613647
Step: 371, Loss: 2.5168957710266113
Step: 372, Loss: 1.807041883468628
Step: 373, Loss: 1.1261646747589111
Step: 374, Loss: 2.0874156951904297
Step: 375, Loss: 2.3792991638183594
Step: 376, Loss: 1.786696434020996
Step: 377, Loss: 3.595545530319214
Step: 378, Loss: 1.6513311862945557
Step: 379, Loss: 2.4386610984802246
Step: 380, Loss: 1.7568832635879517
Step: 381, Loss: 1.538176417350769
Step: 382, Loss: 1.8404738903045654
Step: 383, Loss: 1.777677297592163
Step: 384, Loss: 1.1093121767044067
Step: 385, Loss: 1.2882392406463623
Step: 386, Loss: 1.208402395248413
Step: 387, Loss: 1.4080746173858643
Step: 388, Loss: 2.429436445236206
Step: 389, Loss: 1.409292221069336
Step: 390, Loss: 2.0832605361938477
Step: 391, Loss: 1.1472654342651367
Step: 392, Loss: 1.6585981845855713
Step: 393, Loss: 1.1378731727600098
Step: 394, Loss: 1.8888604640960693
Step: 395, Loss: 1.0515673160552979
Step: 396, Loss: 0.996716320514679
Step: 397, Loss: 1.133567452430725
Step: 398, Loss: 1.3120478391647339
Step: 399, Loss: 1.4506057500839233
Step: 400, Loss: 1.176035761833191
Step: 401, Loss: 1.28220534324646
Step: 402, Loss: 1.2431660890579224
Step: 403, Loss: 1.0260980129241943
Step: 404, Loss: 1.1624268293380737
Step: 405, Loss: 1.2509982585906982
Step: 406, Loss: 1.2081024646759033
Step: 407, Loss: 1.1931002140045166
Step: 408, Loss: 1.4044941663742065
Step: 409, Loss: 2.237825393676758
Step: 410, Loss: 1.0777959823608398
Step: 411, Loss: 1.1874440908432007
Step: 412, Loss: 0.9044498801231384
Step: 413, Loss: 1.226548194885254
Step: 414, Loss: 1.2450947761535645
Step: 415, Loss: 1.3595268726348877
Step: 416, Loss: 1.063979983329773
Step: 417, Loss: 1.876198172569275
Step: 418, Loss: 2.070563554763794
Step: 419, Loss: 1.1883405447006226
Step: 420, Loss: 1.94117271900177
Step: 421, Loss: 1.632832646369934
Step: 422, Loss: 1.420695424079895
Step: 423, Loss: 1.6565310955047607
Step: 424, Loss: 1.1106464862823486
Step: 425, Loss: 1.8436468839645386
Step: 426, Loss: 2.272237777709961
Step: 427, Loss: 1.5965956449508667
Step: 428, Loss: 2.190345048904419
Step: 429, Loss: 1.0120667219161987
Step: 430, Loss: 1.4478408098220825
Step: 431, Loss: 2.384023666381836
Step: 432, Loss: 3.6585981845855713
Step: 433, Loss: 1.4405653476715088
Step: 434, Loss: 4.6167120933532715
Step: 435, Loss: 1.490243673324585
Step: 436, Loss: 1.8094053268432617
Step: 437, Loss: 1.5403167009353638
Step: 438, Loss: 1.8519219160079956
Step: 439, Loss: 1.1591707468032837
Step: 440, Loss: 2.267051935195923
Step: 441, Loss: 1.025639533996582
Step: 442, Loss: 1.4064807891845703
Step: 443, Loss: 1.4950826168060303
Step: 444, Loss: 1.7414876222610474
Step: 445, Loss: 1.0223554372787476
Step: 446, Loss: 1.6488653421401978
Step: 447, Loss: 1.2685432434082031
Step: 448, Loss: 1.7783406972885132
Step: 449, Loss: 2.0522618293762207
Step: 450, Loss: 2.18302059173584
Step: 451, Loss: 2.322730541229248
Step: 452, Loss: 2.322481870651245
Step: 453, Loss: 1.374436616897583
Step: 454, Loss: 1.6382228136062622
Step: 455, Loss: 1.1878927946090698
Step: 456, Loss: 1.2899993658065796
Step: 457, Loss: 0.9792844653129578
Step: 458, Loss: 1.3564013242721558
Step: 459, Loss: 2.5902962684631348
Step: 460, Loss: 1.1672379970550537
Step: 461, Loss: 1.0168551206588745
Step: 462, Loss: 1.3473248481750488
Step: 463, Loss: 1.2240996360778809
Step: 464, Loss: 1.3229796886444092
Step: 465, Loss: 0.9595181941986084
Step: 466, Loss: 1.1917973756790161
Step: 467, Loss: 1.3378987312316895
Step: 468, Loss: 2.0101382732391357
Step: 469, Loss: 0.9713407754898071
Step: 470, Loss: 1.6531226634979248
Step: 471, Loss: 1.1512374877929688
Step: 472, Loss: 1.3342266082763672
Step: 473, Loss: 1.1141818761825562
Step: 474, Loss: 1.150233268737793
Step: 475, Loss: 1.893044352531433
Step: 476, Loss: 1.1744017601013184
Step: 477, Loss: 1.1588683128356934
Step: 478, Loss: 0.887154757976532
Step: 479, Loss: 1.7836202383041382
Step: 480, Loss: 2.724578380584717
Step: 481, Loss: 2.239250659942627
Step: 482, Loss: 0.9007441997528076
Step: 483, Loss: 1.280009150505066
Step: 484, Loss: 2.297295331954956
Step: 485, Loss: 1.9580607414245605
Step: 486, Loss: 1.8486745357513428
Step: 487, Loss: 1.336192011833191
Step: 488, Loss: 1.6512473821640015
Step: 489, Loss: 1.7344461679458618
Step: 490, Loss: 1.61509370803833
Step: 491, Loss: 0.95115065574646
Step: 492, Loss: 1.3539379835128784
Step: 493, Loss: 1.0355839729309082
Step: 494, Loss: 1.2598415613174438
Step: 495, Loss: 1.0739480257034302
Step: 496, Loss: 1.1434381008148193
Step: 497, Loss: 1.9529880285263062
Step: 498, Loss: 1.0311590433120728
Step: 499, Loss: 1.5103585720062256
Step: 500, Loss: 1.0141041278839111
Step: 501, Loss: 1.6501513719558716
Step: 502, Loss: 2.070044994354248
Step: 503, Loss: 2.229675054550171
Step: 504, Loss: 1.8639214038848877
Step: 505, Loss: 1.030006766319275
Step: 506, Loss: 1.0017610788345337
Step: 507, Loss: 1.7338110208511353
Step: 508, Loss: 1.1001875400543213
Step: 509, Loss: 1.4298490285873413
Step: 510, Loss: 0.9573869109153748
Step: 511, Loss: 0.9004384875297546
Step: 512, Loss: 2.0759475231170654
Step: 513, Loss: 1.3005956411361694
Step: 514, Loss: 1.0631672143936157
Step: 515, Loss: 1.5157464742660522
Step: 516, Loss: 1.0387510061264038
Step: 517, Loss: 0.9939854741096497
Step: 518, Loss: 0.8690184950828552
Step: 519, Loss: 1.2205426692962646
Step: 520, Loss: 1.1467750072479248
Step: 521, Loss: 1.1792891025543213
Step: 522, Loss: 1.004142165184021
Step: 523, Loss: 1.0683046579360962
Step: 524, Loss: 0.9895802140235901
Step: 525, Loss: 0.9757773876190186
Step: 526, Loss: 1.4489291906356812
Step: 527, Loss: 1.6832910776138306
Step: 528, Loss: 1.517108678817749
Step: 529, Loss: 1.037533164024353
Step: 530, Loss: 1.1048195362091064
Step: 531, Loss: 1.13180410861969
Step: 532, Loss: 1.3394215106964111
Step: 533, Loss: 0.9852888584136963
Step: 534, Loss: 1.0183230638504028
Step: 535, Loss: 1.008494257926941
Step: 536, Loss: 1.0493532419204712
Step: 537, Loss: 1.0668193101882935
Step: 538, Loss: 0.9405550360679626
Step: 539, Loss: 1.062345266342163
Step: 540, Loss: 1.0194820165634155
Step: 541, Loss: 0.9750699996948242
Step: 542, Loss: 1.0301721096038818
Step: 543, Loss: 1.380625605583191
Step: 544, Loss: 1.119646668434143
Step: 545, Loss: 1.5451252460479736
Step: 546, Loss: 1.140471339225769
Step: 547, Loss: 1.2963699102401733
Step: 548, Loss: 1.1363086700439453
Step: 549, Loss: 1.1105302572250366
Step: 550, Loss: 1.1404658555984497
Step: 551, Loss: 1.0780742168426514
Step: 552, Loss: 1.0505478382110596
Step: 553, Loss: 1.1124109029769897
Step: 554, Loss: 1.0574817657470703
Step: 555, Loss: 0.8910154700279236
Step: 556, Loss: 1.0445481538772583
Step: 557, Loss: 1.168996810913086
Step: 558, Loss: 0.8245542049407959
Step: 559, Loss: 0.8828834295272827
Step: 560, Loss: 1.118599772453308
Step: 561, Loss: 1.0641392469406128
Step: 562, Loss: 1.5114258527755737
Step: 563, Loss: 1.1972604990005493
Step: 564, Loss: 0.9853112101554871
Step: 565, Loss: 1.1927343606948853
Step: 566, Loss: 1.3928589820861816
Step: 567, Loss: 1.5588089227676392
Step: 568, Loss: 2.133051633834839
Step: 569, Loss: 1.231630802154541
Step: 570, Loss: 1.228177547454834
Step: 571, Loss: 0.9517232179641724
Step: 572, Loss: 1.2590998411178589
Step: 573, Loss: 1.5822794437408447
Step: 574, Loss: 1.301405668258667
Step: 575, Loss: 0.9049045443534851
Step: 576, Loss: 0.9085583686828613
Step: 577, Loss: 1.3192648887634277
Step: 578, Loss: 1.1747885942459106
Step: 579, Loss: 0.9009173512458801
Step: 580, Loss: 0.9051975607872009
Step: 581, Loss: 0.9200924038887024
Step: 582, Loss: 0.9676899313926697
Step: 583, Loss: 1.2843400239944458
Step: 584, Loss: 1.0010108947753906
Step: 585, Loss: 1.2784229516983032
Step: 586, Loss: 0.8512206077575684
Step: 587, Loss: 1.1722698211669922
Step: 588, Loss: 1.0730934143066406
Step: 589, Loss: 0.990251362323761
Step: 590, Loss: 1.0794868469238281
Step: 591, Loss: 0.8968948721885681
Step: 592, Loss: 0.8744591474533081
Step: 593, Loss: 1.6125290393829346
Step: 594, Loss: 0.9925470352172852
Step: 595, Loss: 0.8311489820480347
Step: 596, Loss: 1.0039317607879639
Step: 597, Loss: 0.9902017116546631
Step: 598, Loss: 0.770991861820221
Step: 599, Loss: 0.8996947407722473
Step: 600, Loss: 1.1849912405014038
Step: 601, Loss: 1.4257832765579224
Step: 602, Loss: 1.4751325845718384
Step: 603, Loss: 0.9038892984390259
Step: 604, Loss: 1.328387975692749
Step: 605, Loss: 0.9187624454498291
Step: 606, Loss: 1.0646611452102661
Step: 607, Loss: 1.2174657583236694
Step: 608, Loss: 1.1464301347732544
Step: 609, Loss: 1.0076631307601929
Step: 610, Loss: 1.007638692855835
Step: 611, Loss: 0.9587489366531372
Step: 612, Loss: 1.0983935594558716
Step: 613, Loss: 1.0905874967575073
Step: 614, Loss: 1.0007991790771484
Step: 615, Loss: 0.9985526204109192
Step: 616, Loss: 1.1266088485717773
Step: 617, Loss: 1.1062965393066406
Step: 618, Loss: 1.237035870552063
Step: 619, Loss: 0.9904711842536926
Step: 620, Loss: 0.9303345084190369
Step: 621, Loss: 0.9244275093078613
Step: 622, Loss: 1.0725144147872925
Step: 623, Loss: 0.9596936702728271
Step: 624, Loss: 1.228554368019104
Step: 625, Loss: 0.9605626463890076
Step: 626, Loss: 1.0928163528442383
Step: 627, Loss: 0.9701015949249268
Step: 628, Loss: 1.0169259309768677
Step: 629, Loss: 1.146111249923706
Step: 630, Loss: 1.0400911569595337
Step: 631, Loss: 1.0646474361419678
Step: 632, Loss: 0.9267011284828186
Step: 633, Loss: 1.0040929317474365
Step: 634, Loss: 1.065703272819519
Step: 635, Loss: 0.9731981158256531
Step: 636, Loss: 1.2739498615264893
Step: 637, Loss: 1.234264612197876
Step: 638, Loss: 0.9434616565704346
Step: 639, Loss: 1.48660409450531
Step: 640, Loss: 1.313197135925293
Step: 641, Loss: 1.0298614501953125
Step: 642, Loss: 0.883029043674469
Step: 643, Loss: 0.9813626408576965
Step: 644, Loss: 1.117565631866455
Step: 645, Loss: 0.9653069376945496
Step: 646, Loss: 0.8933861255645752
Step: 647, Loss: 1.0035253763198853
Step: 648, Loss: 1.2080719470977783
Step: 649, Loss: 1.8918005228042603
Step: 650, Loss: 1.221759557723999
Step: 651, Loss: 1.228284478187561
Step: 652, Loss: 1.2551153898239136
Step: 653, Loss: 1.2694687843322754
Step: 654, Loss: 0.9388618469238281
Step: 655, Loss: 1.12558913230896
Step: 656, Loss: 1.6817535161972046
Step: 657, Loss: 1.1851776838302612
Step: 658, Loss: 0.992555558681488
Step: 659, Loss: 1.136052131652832
Step: 660, Loss: 1.1547373533248901
Step: 661, Loss: 1.2250138521194458
Step: 662, Loss: 1.6726888418197632
Step: 663, Loss: 1.665394902229309
Step: 664, Loss: 1.0109527111053467
Step: 665, Loss: 0.9751286506652832
Step: 666, Loss: 1.1085331439971924
Step: 667, Loss: 1.054276466369629
Step: 668, Loss: 1.107330560684204
Step: 669, Loss: 0.906989336013794
Step: 670, Loss: 0.9822766184806824
Step: 671, Loss: 1.211846947669983
Step: 672, Loss: 0.8160181045532227
Step: 673, Loss: 1.1636909246444702
Step: 674, Loss: 0.8231426477432251
Step: 675, Loss: 1.0599379539489746
Step: 676, Loss: 0.8495544791221619
Step: 677, Loss: 1.3205090761184692
Step: 678, Loss: 1.0493278503417969
Step: 679, Loss: 1.0352293252944946
Step: 680, Loss: 0.92411869764328
Step: 681, Loss: 1.2340307235717773
Step: 682, Loss: 1.3866620063781738
Step: 683, Loss: 1.0097780227661133
Step: 684, Loss: 0.9256247282028198
Step: 685, Loss: 1.0185500383377075
Step: 686, Loss: 1.1651502847671509
Step: 687, Loss: 0.9437031745910645
Step: 688, Loss: 0.9600377678871155
Step: 689, Loss: 1.382363200187683
Step: 690, Loss: 1.1713289022445679
Step: 691, Loss: 1.1111727952957153
Step: 692, Loss: 0.9739564657211304
Step: 693, Loss: 0.8843884468078613
Step: 694, Loss: 1.037155270576477
Step: 695, Loss: 1.4279193878173828
Step: 696, Loss: 1.0878163576126099
Step: 697, Loss: 1.1647188663482666
Step: 698, Loss: 1.0141198635101318
Step: 699, Loss: 1.2220416069030762
Step: 700, Loss: 1.7373312711715698
Step: 701, Loss: 1.1904317140579224
Step: 702, Loss: 1.0995231866836548
Step: 703, Loss: 0.9954006671905518
Step: 704, Loss: 1.229640007019043
Step: 705, Loss: 1.6407161951065063
Step: 706, Loss: 0.9671283960342407
Step: 707, Loss: 0.9671892523765564
Step: 708, Loss: 0.95945143699646
Step: 709, Loss: 0.8817459344863892
Step: 710, Loss: 0.8574462532997131
Step: 711, Loss: 1.005836009979248
Step: 712, Loss: 1.180617094039917
Step: 713, Loss: 0.9692159295082092
Step: 714, Loss: 1.4199899435043335
Step: 715, Loss: 1.230049729347229
Step: 716, Loss: 0.8709293603897095
Step: 717, Loss: 1.0483161211013794
Step: 718, Loss: 1.2784593105316162
Step: 719, Loss: 0.8932386040687561
Step: 720, Loss: 1.085216999053955
Step: 721, Loss: 1.1876051425933838
Step: 722, Loss: 1.1420344114303589
Step: 723, Loss: 1.1620056629180908
Step: 724, Loss: 1.0132628679275513
Step: 725, Loss: 1.1121857166290283
Step: 726, Loss: 1.1872498989105225
Step: 727, Loss: 0.9097075462341309
Step: 728, Loss: 1.2430498600006104
Step: 729, Loss: 1.0402456521987915
Step: 730, Loss: 0.8875462412834167
Step: 731, Loss: 1.096135139465332
Step: 732, Loss: 0.9370454549789429
Step: 733, Loss: 0.9579076766967773
Step: 734, Loss: 1.0836879014968872
Step: 735, Loss: 0.9381175637245178
Step: 736, Loss: 1.3881008625030518
Step: 737, Loss: 0.9561418294906616
Step: 738, Loss: 1.041532278060913
Step: 739, Loss: 1.036586046218872
Step: 740, Loss: 1.0209702253341675
Step: 741, Loss: 1.1230218410491943
Step: 742, Loss: 0.8458488583564758
Step: 743, Loss: 0.9003409147262573
Step: 744, Loss: 1.1451536417007446
Step: 745, Loss: 0.9323437809944153
Step: 746, Loss: 0.9090273976325989
Step: 747, Loss: 1.0156606435775757
Step: 748, Loss: 0.9858978390693665
Step: 749, Loss: 1.0176939964294434
Step: 750, Loss: 1.1634776592254639
Step: 751, Loss: 1.2923849821090698
Step: 752, Loss: 1.0114392042160034
Step: 753, Loss: 1.0148537158966064
Step: 754, Loss: 1.0960922241210938
Step: 755, Loss: 0.945057213306427
Step: 756, Loss: 0.9848716855049133
Step: 757, Loss: 0.939226508140564
Step: 758, Loss: 0.9869997501373291
Step: 759, Loss: 0.9378076791763306
Step: 760, Loss: 1.021173357963562
Step: 761, Loss: 1.262459397315979
Step: 762, Loss: 1.2049989700317383
Step: 763, Loss: 0.8212737441062927
Step: 764, Loss: 0.9058179259300232
Step: 765, Loss: 0.805427610874176
Step: 766, Loss: 0.9655129313468933
Step: 767, Loss: 1.154533863067627
Step: 768, Loss: 0.8861809372901917
Step: 769, Loss: 0.9910244941711426
Step: 770, Loss: 1.175093650817871
Step: 771, Loss: 1.0242257118225098
Step: 772, Loss: 0.9277782440185547
Step: 773, Loss: 1.3784085512161255
Step: 774, Loss: 0.9043805003166199
Step: 775, Loss: 0.8706228137016296
Step: 776, Loss: 0.9137008786201477
Step: 777, Loss: 1.1387661695480347
Step: 778, Loss: 1.1117632389068604
Step: 779, Loss: 0.9371840357780457
Step: 780, Loss: 1.0314987897872925
Step: 781, Loss: 1.8036311864852905
Step: 782, Loss: 1.4411802291870117
Step: 783, Loss: 1.156874656677246
Step: 784, Loss: 1.0363438129425049
Step: 785, Loss: 1.0087099075317383
Step: 786, Loss: 0.855559766292572
Step: 787, Loss: 1.4134373664855957
Step: 788, Loss: 1.1942356824874878
Step: 789, Loss: 1.0693117380142212
Step: 790, Loss: 0.8138003349304199
Step: 791, Loss: 1.1278047561645508
Step: 792, Loss: 1.3373043537139893
Step: 793, Loss: 0.9189659953117371
Step: 794, Loss: 0.8900984525680542
Step: 795, Loss: 1.180484652519226
Step: 796, Loss: 1.3559914827346802
Step: 797, Loss: 1.165669322013855
Step: 798, Loss: 1.3257704973220825
Step: 799, Loss: 1.438359022140503
Step: 800, Loss: 1.444698691368103
Step: 801, Loss: 1.5033560991287231
Step: 802, Loss: 0.9634712934494019
Step: 803, Loss: 0.9275635480880737
Step: 804, Loss: 1.0077898502349854
Step: 805, Loss: 1.0341038703918457
Step: 806, Loss: 0.9228997230529785
Step: 807, Loss: 0.9365344643592834
Step: 808, Loss: 0.9097099304199219
Step: 809, Loss: 1.1074047088623047
Step: 810, Loss: 0.9848609566688538
Step: 811, Loss: 0.992733895778656
Step: 812, Loss: 0.9239960312843323
Step: 813, Loss: 1.1812833547592163
Step: 814, Loss: 1.0829757452011108
Step: 815, Loss: 1.0726532936096191
Step: 816, Loss: 1.0706758499145508
Step: 817, Loss: 0.8311644792556763
Step: 818, Loss: 0.9951549768447876
Step: 819, Loss: 1.3683302402496338
Step: 820, Loss: 1.2355479001998901
Step: 821, Loss: 1.1072139739990234
Step: 822, Loss: 1.18113374710083
Step: 823, Loss: 1.065762996673584
Step: 824, Loss: 0.9838959574699402
Step: 825, Loss: 0.9229940176010132
Step: 826, Loss: 1.267417073249817
Step: 827, Loss: 0.8398277163505554
Step: 828, Loss: 1.3085300922393799
Step: 829, Loss: 1.0268890857696533
Step: 830, Loss: 0.9072145223617554
Step: 831, Loss: 0.9330001473426819
Step: 832, Loss: 0.9876440763473511
Step: 833, Loss: 1.00520658493042
Step: 834, Loss: 1.2017102241516113
Step: 835, Loss: 1.0803550481796265
Step: 836, Loss: 1.1030306816101074
Step: 837, Loss: 1.3822154998779297
Step: 838, Loss: 1.1857644319534302
Step: 839, Loss: 1.3753548860549927
Step: 840, Loss: 0.944552481174469
Step: 841, Loss: 1.1351805925369263
Step: 842, Loss: 1.4339412450790405
Step: 843, Loss: 1.2034343481063843
Step: 844, Loss: 1.1493828296661377
Step: 845, Loss: 1.2299370765686035
Step: 846, Loss: 1.0914267301559448
Step: 847, Loss: 1.3326894044876099
Step: 848, Loss: 0.9084435701370239
Step: 849, Loss: 1.3724186420440674
Step: 850, Loss: 1.323051929473877
Step: 851, Loss: 0.935142457485199
Step: 852, Loss: 1.09468412399292
Step: 853, Loss: 1.4029866456985474
Step: 854, Loss: 1.8196885585784912
Step: 855, Loss: 1.3373558521270752
Step: 856, Loss: 1.0823051929473877
Step: 857, Loss: 1.1088135242462158
Step: 858, Loss: 1.3765381574630737
Step: 859, Loss: 0.9093050956726074
Step: 860, Loss: 1.3859260082244873
Step: 861, Loss: 1.9008946418762207
Step: 862, Loss: 1.1186296939849854
Step: 863, Loss: 0.8601940870285034
Step: 864, Loss: 0.9031789302825928
Step: 865, Loss: 0.905063271522522
Step: 866, Loss: 1.695857286453247
Step: 867, Loss: 1.058953046798706
Step: 868, Loss: 0.92292320728302
Step: 869, Loss: 1.006582498550415
Step: 870, Loss: 0.9517637491226196
Step: 871, Loss: 1.0229558944702148
Step: 872, Loss: 1.2935103178024292
Step: 873, Loss: 1.2695176601409912
Step: 874, Loss: 1.0498391389846802
Step: 875, Loss: 0.9334248304367065
Step: 876, Loss: 1.196431040763855
Step: 877, Loss: 1.0302380323410034
Step: 878, Loss: 1.0757310390472412
Step: 879, Loss: 1.074587345123291
Step: 880, Loss: 1.5840736627578735
Step: 881, Loss: 1.2876235246658325
Step: 882, Loss: 1.0309492349624634
Step: 883, Loss: 0.9333975315093994
Step: 884, Loss: 0.9490947127342224
Step: 885, Loss: 1.6755448579788208
Step: 886, Loss: 1.2089442014694214
Step: 887, Loss: 0.9371276497840881
Step: 888, Loss: 0.8850806951522827
Step: 889, Loss: 0.9522886276245117
Step: 890, Loss: 0.8365033268928528
Step: 891, Loss: 0.9680601954460144
Step: 892, Loss: 0.9006853103637695
Step: 893, Loss: 1.4182548522949219
Step: 894, Loss: 1.2463281154632568
Step: 895, Loss: 0.9949823617935181
Step: 896, Loss: 1.1145215034484863
Step: 897, Loss: 0.9585007429122925
Step: 898, Loss: 0.9030323028564453
Step: 899, Loss: 1.1149802207946777
Step: 900, Loss: 0.856562077999115
Step: 901, Loss: 1.1625299453735352
Step: 902, Loss: 1.0431792736053467
Step: 903, Loss: 0.8814777135848999
Step: 904, Loss: 1.2269636392593384
Step: 905, Loss: 0.9973665475845337
Step: 906, Loss: 0.8819596767425537
Step: 907, Loss: 0.9760326147079468
Step: 908, Loss: 1.6662217378616333
Step: 909, Loss: 1.8749327659606934
Step: 910, Loss: 0.9048961400985718
Step: 911, Loss: 1.3797253370285034
Step: 912, Loss: 1.0249300003051758
Step: 913, Loss: 1.1566845178604126
Step: 914, Loss: 1.1755765676498413
Step: 915, Loss: 1.6229846477508545
Step: 916, Loss: 1.3780238628387451
Step: 917, Loss: 1.024865984916687
Step: 918, Loss: 0.8798532485961914
Step: 919, Loss: 0.8436480760574341
Output File: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-19-sub_1/003_Oct-19-2024_10:36_PM/training_loss_curve.png
Training loss curve saved to /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-19-sub_1/003_Oct-19-2024_10:36_PM/training_loss_curve.png
Total Completion Time: 68.63 minutes. (1.14 hours) 
