Number of GPUs available: 2
Logs directory: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-21/sub-1/006_Oct-21-2024_02:52_PM
/home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-21/sub-1/006_Oct-21-2024_02:52_PM
> training arguments:
>>> rand_seed: 8
>>> model_name: mmfusion
>>> dataset: mvsa-mts-1000
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f2177441c60>
>>> learning_rate: 0.0001
>>> dropout_rate: 0.5
>>> num_epoch: 10
>>> batch_size: 64
>>> log_step: 30
>>> max_seq_len: 64
>>> polarities_dim: 3
>>> clip_grad: 5.0
>>> path_image: ./Datasets/MVSA-MTS/images-indexed
>>> crop_size: 224
>>> n_head: 8
>>> common_dim: 512
>>> num_classes: 3
>>> model_class: <class 'models.mmfusion.MMFUSION'>
Preparing mvsa-mts-1000 dataset...
-------------- Loading Datasets/MVSA-MTS/mvsa-mts-1000/train.tsv ---------------
Time taken to load Datasets/MVSA-MTS/mvsa-mts-1000/train.tsv: 15.79 seconds (0.26 minutes)
The number of problematic samples: 69
-------------- Loading Datasets/MVSA-MTS/mvsa-mts-1000/val.tsv ---------------
Time taken to load Datasets/MVSA-MTS/mvsa-mts-1000/val.tsv: 2.11 seconds (0.04 minutes)
The number of problematic samples: 10
-------------- Loading Datasets/MVSA-MTS/mvsa-mts-1000/test.tsv ---------------
Time taken to load Datasets/MVSA-MTS/mvsa-mts-1000/test.tsv: 1.79 seconds (0.03 minutes)
The number of problematic samples: 6
Total Training Samples: 1000
Number of Training Samples: 800
Number of Development Samples: 100
Number of Test Samples: 100
Number of unique sentiment classes: 3
building model
Using 2 GPUs
n_trainable_params: 43763715, n_nontrainable_params: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
Batch 0 completed in 3.51 seconds (0.06 minutes)
max_dev_f1: 0, max_test_f1: 0
loss: 1.097184, dev_acc: 42.00% (0.420000), dev_f1: 19.72% (0.197183), test_acc: 48.00% (0.480000), test_f1: 21.62% (0.216216)
Epoch 0 completed in 19.27 seconds (0.32 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
Batch 0 completed in 1.06 seconds (0.02 minutes)
max_dev_f1: 0.19718309859154928, max_test_f1: 0.21621621621621623
loss: 0.903914, dev_acc: 43.00% (0.430000), dev_f1: 36.44% (0.364435), test_acc: 37.00% (0.370000), test_f1: 30.68% (0.306751)
Epoch 1 completed in 16.56 seconds (0.28 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
Batch 0 completed in 1.02 seconds (0.02 minutes)
max_dev_f1: 0.3644349477682811, max_test_f1: 0.30675135262291225
loss: 0.860760, dev_acc: 46.00% (0.460000), dev_f1: 37.39% (0.373887), test_acc: 49.00% (0.490000), test_f1: 35.40% (0.354014)
Epoch 2 completed in 16.12 seconds (0.27 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
Batch 0 completed in 1.05 seconds (0.02 minutes)
max_dev_f1: 0.3738873833182776, max_test_f1: 0.35401439872984586
loss: 0.770011, dev_acc: 48.00% (0.480000), dev_f1: 39.54% (0.395437), test_acc: 51.00% (0.510000), test_f1: 36.12% (0.361189)
Epoch 3 completed in 16.34 seconds (0.27 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
Batch 0 completed in 1.01 seconds (0.02 minutes)
max_dev_f1: 0.3954369769972607, max_test_f1: 0.36118892001244945
loss: 0.670300, dev_acc: 49.00% (0.490000), dev_f1: 46.95% (0.469508), test_acc: 44.00% (0.440000), test_f1: 38.65% (0.386515)
Epoch 4 completed in 16.38 seconds (0.27 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
Batch 0 completed in 0.99 seconds (0.02 minutes)
loss: 0.678696, dev_acc: 44.00% (0.440000), dev_f1: 36.27% (0.362670), test_acc: 52.00% (0.520000), test_f1: 43.23% (0.432309)
Epoch 5 completed in 16.24 seconds (0.27 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
Batch 0 completed in 1.01 seconds (0.02 minutes)
loss: 0.414191, dev_acc: 47.00% (0.470000), dev_f1: 39.52% (0.395211), test_acc: 48.00% (0.480000), test_f1: 37.68% (0.376823)
Epoch 6 completed in 15.88 seconds (0.26 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 7
Batch 0 completed in 0.99 seconds (0.02 minutes)
loss: 0.351940, dev_acc: 44.00% (0.440000), dev_f1: 39.77% (0.397687), test_acc: 46.00% (0.460000), test_f1: 38.61% (0.386148)
Epoch 7 completed in 15.87 seconds (0.26 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 8
Batch 0 completed in 1.00 seconds (0.02 minutes)
loss: 0.212152, dev_acc: 38.00% (0.380000), dev_f1: 37.65% (0.376538), test_acc: 36.00% (0.360000), test_f1: 33.34% (0.333379)
Epoch 8 completed in 16.30 seconds (0.27 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 9
Batch 0 completed in 1.04 seconds (0.02 minutes)
loss: 0.188244, dev_acc: 49.00% (0.490000), dev_f1: 41.31% (0.413090), test_acc: 49.00% (0.490000), test_f1: 37.79% (0.377913)
Epoch 9 completed in 15.93 seconds (0.27 minutes)
Max dev F1: 46.95% (0.469508), Max test F1: 38.65% (0.386515)
Reading TensorBoard loss at each epoch:
Available tags: {'images': [], 'audio': [], 'histograms': [], 'scalars': ['Loss/train', 'Loss/val'], 'distributions': [], 'tensors': [], 'graph': False, 'meta_graph': False, 'run_metadata': []}
Step: 1, Loss: 1.097184419631958
Step: 2, Loss: 1.0836831331253052
Step: 3, Loss: 1.0375189781188965
Step: 4, Loss: 1.0360020399093628
Step: 5, Loss: 1.0933680534362793
Step: 6, Loss: 1.0933456420898438
Step: 7, Loss: 0.9598006010055542
Step: 8, Loss: 1.1190675497055054
Step: 9, Loss: 1.029409646987915
Step: 10, Loss: 0.8700131773948669
Step: 11, Loss: 1.048237919807434
Step: 12, Loss: 1.0712777376174927
Step: 13, Loss: 1.0499924421310425
Step: 14, Loss: 0.9039137363433838
Step: 15, Loss: 0.9544752240180969
Step: 16, Loss: 1.0084354877471924
Step: 17, Loss: 0.8990861773490906
Step: 18, Loss: 0.9482133388519287
Step: 19, Loss: 0.9299740791320801
Step: 20, Loss: 0.9782055616378784
Step: 21, Loss: 0.9314735531806946
Step: 22, Loss: 0.9526613354682922
Step: 23, Loss: 0.8459600210189819
Step: 24, Loss: 1.0360758304595947
Step: 25, Loss: 0.951697587966919
Step: 26, Loss: 1.0109224319458008
Step: 27, Loss: 0.8607602715492249
Step: 28, Loss: 0.8246579766273499
Step: 29, Loss: 0.7104506492614746
Step: 30, Loss: 0.8988372683525085
Step: 31, Loss: 1.0083540678024292
Step: 32, Loss: 0.8013876676559448
Step: 33, Loss: 0.8293541073799133
Step: 34, Loss: 0.832866907119751
Step: 35, Loss: 0.9980760216712952
Step: 36, Loss: 0.8650748133659363
Step: 37, Loss: 0.9428558945655823
Step: 38, Loss: 0.7958289980888367
Step: 39, Loss: 0.9941726922988892
Step: 40, Loss: 0.7700108289718628
Step: 41, Loss: 0.6856300234794617
Step: 42, Loss: 0.7368721961975098
Step: 43, Loss: 0.8000147938728333
Step: 44, Loss: 0.8143211007118225
Step: 45, Loss: 0.9445974230766296
Step: 46, Loss: 0.8248026371002197
Step: 47, Loss: 0.8057822585105896
Step: 48, Loss: 0.6903099417686462
Step: 49, Loss: 0.6935956478118896
Step: 50, Loss: 0.7425155639648438
Step: 51, Loss: 0.7925919890403748
Step: 52, Loss: 0.6894477009773254
Step: 53, Loss: 0.670299768447876
Step: 54, Loss: 0.7600675225257874
Step: 55, Loss: 0.6265062689781189
Step: 56, Loss: 0.5542915463447571
Step: 57, Loss: 0.6278043985366821
Step: 58, Loss: 0.676383376121521
Step: 59, Loss: 0.7291440963745117
Step: 60, Loss: 0.7494751811027527
Step: 61, Loss: 0.611192524433136
Step: 62, Loss: 0.7744189500808716
Step: 63, Loss: 0.6831186413764954
Step: 64, Loss: 0.8340233564376831
Step: 65, Loss: 0.7128011584281921
Step: 66, Loss: 0.678695797920227
Step: 67, Loss: 0.5860272645950317
Step: 68, Loss: 0.4730934500694275
Step: 69, Loss: 0.38336417078971863
Step: 70, Loss: 0.4644162654876709
Step: 71, Loss: 0.7095398902893066
Step: 72, Loss: 0.7099684476852417
Step: 73, Loss: 0.6696506142616272
Step: 74, Loss: 0.5580213069915771
Step: 75, Loss: 0.6264340281486511
Step: 76, Loss: 0.6907539963722229
Step: 77, Loss: 0.6385496258735657
Step: 78, Loss: 0.5651440024375916
Step: 79, Loss: 0.4141913652420044
Step: 80, Loss: 0.4370633065700531
Step: 81, Loss: 0.40110093355178833
Step: 82, Loss: 0.32253497838974
Step: 83, Loss: 0.5873265862464905
Step: 84, Loss: 0.5529528260231018
Step: 85, Loss: 0.31362923979759216
Step: 86, Loss: 0.43023356795310974
Step: 87, Loss: 0.4920286536216736
Step: 88, Loss: 0.5000689625740051
Step: 89, Loss: 0.4857873320579529
Step: 90, Loss: 0.4811919629573822
Step: 91, Loss: 0.3932080864906311
Step: 92, Loss: 0.35194018483161926
Step: 93, Loss: 0.32320407032966614
Step: 94, Loss: 0.2581040859222412
Step: 95, Loss: 0.34087643027305603
Step: 96, Loss: 0.3998218774795532
Step: 97, Loss: 0.3473837971687317
Step: 98, Loss: 0.5565810203552246
Step: 99, Loss: 0.49022147059440613
Step: 100, Loss: 0.2549053132534027
Step: 101, Loss: 0.3997693359851837
Step: 102, Loss: 0.5244025588035583
Step: 103, Loss: 0.7138879299163818
Step: 104, Loss: 0.2638479173183441
Step: 105, Loss: 0.21215234696865082
Step: 106, Loss: 0.3521197438240051
Step: 107, Loss: 0.2897613048553467
Step: 108, Loss: 0.23120704293251038
Step: 109, Loss: 0.2999955117702484
Step: 110, Loss: 0.22852514684200287
Step: 111, Loss: 0.30590391159057617
Step: 112, Loss: 0.26392754912376404
Step: 113, Loss: 0.38623812794685364
Step: 114, Loss: 0.3820717930793762
Step: 115, Loss: 0.3521711230278015
Step: 116, Loss: 0.26810041069984436
Step: 117, Loss: 0.7279536128044128
Step: 118, Loss: 0.18824441730976105
Step: 119, Loss: 0.2306382954120636
Step: 120, Loss: 0.17530223727226257
Step: 121, Loss: 0.248497873544693
Step: 122, Loss: 0.21338850259780884
Step: 123, Loss: 0.219841867685318
Step: 124, Loss: 0.22522321343421936
Step: 125, Loss: 0.1528133898973465
Step: 126, Loss: 0.31053170561790466
Step: 127, Loss: 0.26929351687431335
Step: 128, Loss: 0.44153639674186707
Step: 129, Loss: 0.30494141578674316
Step: 130, Loss: 0.3265627324581146
Output File: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-21/sub-1/006_Oct-21-2024_02:52_PM/trainval_loss_curves.png
Training and validation loss curves saved to /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-21/sub-1/006_Oct-21-2024_02:52_PM/trainval_loss_curves.png
Total Completion Time: 3.40 minutes. (0.06 hours) 
