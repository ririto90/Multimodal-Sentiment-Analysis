SLURM Job ID: 19387087
Number of GPUs available: 1
Logs directory: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-22/sub-1/006_Oct-22-2024_10:57_AM
> training arguments:
>>> rand_seed: 8
>>> model_name: mfcchfusion2
>>> dataset: mvsa-mts-1000
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f496d50d580>
>>> learning_rate: 0.0001
>>> dropout_rate: 0.5
>>> num_epoch: 10
>>> batch_size: 64
>>> log_step: 60
>>> max_seq_len: 64
>>> polarities_dim: 3
>>> clip_grad: 5.0
>>> path_image: ./Datasets/MVSA-MTS/images-indexed
>>> crop_size: 224
>>> n_head: 8
>>> common_dim: 1024
>>> num_classes: 3
>>> log_dir: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-22/sub-1/006_Oct-22-2024_10:57_AM
>>> model_class: <class 'models.mfcchfusion2.MFCCHFUSION2'>
Preparing mvsa-mts-1000 dataset...
-------------- Loading Datasets/MVSA-MTS/mvsa-mts-1000/train.tsv ---------------
Time taken to load Datasets/MVSA-MTS/mvsa-mts-1000/train.tsv: 2.94 seconds (0.05 minutes)
The number of problematic samples: 69
-------------- Loading Datasets/MVSA-MTS/mvsa-mts-1000/val.tsv ---------------
Time taken to load Datasets/MVSA-MTS/mvsa-mts-1000/val.tsv: 0.38 seconds (0.01 minutes)
The number of problematic samples: 10
-------------- Loading Datasets/MVSA-MTS/mvsa-mts-1000/test.tsv ---------------
Time taken to load Datasets/MVSA-MTS/mvsa-mts-1000/test.tsv: 0.37 seconds (0.01 minutes)
The number of problematic samples: 6
Total Training Samples: 1000
Number of Training Samples: 800
Number of Development Samples: 100
Number of Test Samples: 100
Number of unique sentiment classes: 3
Building model
n_trainable_params: 282391715, n_nontrainable_params: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
Batch 0 completed in 1.37 seconds (0.02 minutes)
New best dev_f1: 0.226633 (previous best: 0.000000)
loss: 1.097134, dev_acc: 40.00% (0.400000), dev_f1: 22.66% (0.226633), test_acc: 50.00% (0.500000), test_f1: 29.11% (0.291120)
Epoch 0 completed in 9.87 seconds (0.16 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
Batch 0 completed in 0.60 seconds (0.01 minutes)
loss: 0.996799, dev_acc: 42.00% (0.420000), dev_f1: 19.86% (0.198582), test_acc: 48.00% (0.480000), test_f1: 23.61% (0.236117)
Epoch 1 completed in 8.44 seconds (0.14 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
Batch 0 completed in 0.60 seconds (0.01 minutes)
New best dev_f1: 0.353002 (previous best: 0.226633)
loss: 1.052047, dev_acc: 44.00% (0.440000), dev_f1: 35.30% (0.353002), test_acc: 53.00% (0.530000), test_f1: 41.88% (0.418750)
Epoch 2 completed in 8.42 seconds (0.14 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
Batch 0 completed in 0.60 seconds (0.01 minutes)
New best dev_f1: 0.369442 (previous best: 0.353002)
loss: 0.867627, dev_acc: 45.00% (0.450000), dev_f1: 36.94% (0.369442), test_acc: 49.00% (0.490000), test_f1: 33.22% (0.332187)
Epoch 3 completed in 8.53 seconds (0.14 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
Batch 0 completed in 0.60 seconds (0.01 minutes)
New best dev_f1: 0.376285 (previous best: 0.369442)
loss: 0.793929, dev_acc: 45.00% (0.450000), dev_f1: 37.63% (0.376285), test_acc: 45.00% (0.450000), test_f1: 29.30% (0.293023)
Epoch 4 completed in 8.48 seconds (0.14 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
Batch 0 completed in 0.60 seconds (0.01 minutes)
New best dev_f1: 0.444676 (previous best: 0.376285)
loss: 0.763145, dev_acc: 48.00% (0.480000), dev_f1: 44.47% (0.444676), test_acc: 48.00% (0.480000), test_f1: 44.50% (0.445043)
Epoch 5 completed in 8.47 seconds (0.14 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
Batch 0 completed in 0.60 seconds (0.01 minutes)
loss: 0.912699, dev_acc: 51.00% (0.510000), dev_f1: 40.47% (0.404720), test_acc: 45.00% (0.450000), test_f1: 33.31% (0.333066)
Epoch 6 completed in 8.55 seconds (0.14 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 7
Batch 0 completed in 0.61 seconds (0.01 minutes)
loss: 0.722483, dev_acc: 40.00% (0.400000), dev_f1: 30.92% (0.309169), test_acc: 46.00% (0.460000), test_f1: 29.67% (0.296747)
Epoch 7 completed in 8.53 seconds (0.14 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 8
Batch 0 completed in 0.61 seconds (0.01 minutes)
loss: 0.706248, dev_acc: 47.00% (0.470000), dev_f1: 40.00% (0.400000), test_acc: 44.00% (0.440000), test_f1: 31.63% (0.316349)
Epoch 8 completed in 8.48 seconds (0.14 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 9
Batch 0 completed in 0.61 seconds (0.01 minutes)
loss: 0.706160, dev_acc: 46.00% (0.460000), dev_f1: 42.96% (0.429578), test_acc: 47.00% (0.470000), test_f1: 41.36% (0.413617)
Epoch 9 completed in 8.45 seconds (0.14 minutes)
RESULT: Max Dev F1: 0.444676, Max Test F1: 0.445043
Reading TensorBoard loss at each epoch:
Available tags: {'images': [], 'audio': [], 'histograms': [], 'scalars': ['Loss/train', 'Loss/val'], 'distributions': [], 'tensors': [], 'graph': False, 'meta_graph': False, 'run_metadata': []}
Step: 1, Loss: 1.0971338748931885
Step: 2, Loss: 1.0158361196517944
Step: 3, Loss: 1.5899512767791748
Step: 4, Loss: 0.9700495004653931
Step: 5, Loss: 0.966833233833313
Step: 6, Loss: 1.1177316904067993
Step: 7, Loss: 1.047760248184204
Step: 8, Loss: 1.1303105354309082
Step: 9, Loss: 1.1512571573257446
Step: 10, Loss: 1.0823029279708862
Step: 11, Loss: 0.9732760787010193
Step: 12, Loss: 0.9279598593711853
Step: 13, Loss: 1.1546679735183716
Step: 14, Loss: 0.9967992901802063
Step: 15, Loss: 1.1100742816925049
Step: 16, Loss: 1.0402376651763916
Step: 17, Loss: 1.0498814582824707
Step: 18, Loss: 0.937572717666626
Step: 19, Loss: 0.9436759352684021
Step: 20, Loss: 0.9394104480743408
Step: 21, Loss: 1.0523029565811157
Step: 22, Loss: 0.9857213497161865
Step: 23, Loss: 0.8477905988693237
Step: 24, Loss: 0.8821858763694763
Step: 25, Loss: 1.0727015733718872
Step: 26, Loss: 0.8435752391815186
Step: 27, Loss: 1.052046537399292
Step: 28, Loss: 0.9554378390312195
Step: 29, Loss: 0.993052065372467
Step: 30, Loss: 0.8020336627960205
Step: 31, Loss: 1.1667407751083374
Step: 32, Loss: 0.8649401068687439
Step: 33, Loss: 1.0911438465118408
Step: 34, Loss: 0.9774730205535889
Step: 35, Loss: 1.1943751573562622
Step: 36, Loss: 0.8163443803787231
Step: 37, Loss: 0.9131311178207397
Step: 38, Loss: 0.9097036123275757
Step: 39, Loss: 0.9121822714805603
Step: 40, Loss: 0.8676273822784424
Step: 41, Loss: 0.8956613540649414
Step: 42, Loss: 0.851797342300415
Step: 43, Loss: 0.8815603256225586
Step: 44, Loss: 0.8413062691688538
Step: 45, Loss: 0.7308080792427063
Step: 46, Loss: 0.9403533935546875
Step: 47, Loss: 1.0405759811401367
Step: 48, Loss: 0.7881845235824585
Step: 49, Loss: 0.9887391924858093
Step: 50, Loss: 0.9851657152175903
Step: 51, Loss: 0.8906097412109375
Step: 52, Loss: 1.0886121988296509
Step: 53, Loss: 0.7939289212226868
Step: 54, Loss: 0.7713442444801331
Step: 55, Loss: 0.7267498970031738
Step: 56, Loss: 0.8350783586502075
Step: 57, Loss: 0.9891901612281799
Step: 58, Loss: 1.0170930624008179
Step: 59, Loss: 0.84641432762146
Step: 60, Loss: 0.8568180799484253
Step: 61, Loss: 0.8235905766487122
Step: 62, Loss: 0.7976561188697815
Step: 63, Loss: 0.8992261290550232
Step: 64, Loss: 0.9490141868591309
Step: 65, Loss: 0.8165555596351624
Step: 66, Loss: 0.763145387172699
Step: 67, Loss: 0.8071044087409973
Step: 68, Loss: 0.8247635364532471
Step: 69, Loss: 0.6491483449935913
Step: 70, Loss: 0.7806776165962219
Step: 71, Loss: 0.9142312407493591
Step: 72, Loss: 0.6737316250801086
Step: 73, Loss: 1.0089904069900513
Step: 74, Loss: 0.6908151507377625
Step: 75, Loss: 0.5898256301879883
Step: 76, Loss: 0.9236748814582825
Step: 77, Loss: 0.7121575474739075
Step: 78, Loss: 1.1153510808944702
Step: 79, Loss: 0.91269850730896
Step: 80, Loss: 0.9328703284263611
Step: 81, Loss: 0.6551785469055176
Step: 82, Loss: 0.662400484085083
Step: 83, Loss: 0.6964120864868164
Step: 84, Loss: 0.8051964640617371
Step: 85, Loss: 0.8107239603996277
Step: 86, Loss: 0.8329046964645386
Step: 87, Loss: 0.6052039265632629
Step: 88, Loss: 0.8789441585540771
Step: 89, Loss: 0.7607709169387817
Step: 90, Loss: 0.6376038789749146
Step: 91, Loss: 0.7964149117469788
Step: 92, Loss: 0.7224832773208618
Step: 93, Loss: 0.5028601288795471
Step: 94, Loss: 0.755142331123352
Step: 95, Loss: 0.6911455988883972
Step: 96, Loss: 0.6774331331253052
Step: 97, Loss: 0.48965317010879517
Step: 98, Loss: 0.6549246311187744
Step: 99, Loss: 0.6599022150039673
Step: 100, Loss: 1.1229690313339233
Step: 101, Loss: 0.8716505169868469
Step: 102, Loss: 0.5765774250030518
Step: 103, Loss: 0.6868250966072083
Step: 104, Loss: 0.6063080430030823
Step: 105, Loss: 0.7062480449676514
Step: 106, Loss: 0.6454004645347595
Step: 107, Loss: 0.49524205923080444
Step: 108, Loss: 0.6911152601242065
Step: 109, Loss: 0.7857495546340942
Step: 110, Loss: 0.8612349033355713
Step: 111, Loss: 0.9790952801704407
Step: 112, Loss: 0.6039001941680908
Step: 113, Loss: 0.7451572418212891
Step: 114, Loss: 0.667151689529419
Step: 115, Loss: 0.9232818484306335
Step: 116, Loss: 0.9263695478439331
Step: 117, Loss: 0.7813528180122375
Step: 118, Loss: 0.7061595916748047
Step: 119, Loss: 0.5986328125
Step: 120, Loss: 0.49716368317604065
Step: 121, Loss: 0.3410196602344513
Step: 122, Loss: 0.7386422753334045
Step: 123, Loss: 0.6052061319351196
Step: 124, Loss: 0.7343623638153076
Step: 125, Loss: 0.6331402063369751
Step: 126, Loss: 0.574819028377533
Step: 127, Loss: 0.574116051197052
Step: 128, Loss: 0.6258830428123474
Step: 129, Loss: 0.66695636510849
Step: 130, Loss: 0.7244431376457214
Output File: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-22/sub-1/006_Oct-22-2024_10:57_AM/trainval_loss_curves.png
Training and validation loss curves saved to /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-22/sub-1/006_Oct-22-2024_10:57_AM/trainval_loss_curves.png
Total Completion Time: 1.76 minutes. (0.03 hours) 
