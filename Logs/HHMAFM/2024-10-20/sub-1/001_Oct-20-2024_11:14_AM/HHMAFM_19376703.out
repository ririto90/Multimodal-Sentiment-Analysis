Number of GPUs available: 2
Logs directory: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-20/001_Oct-20-2024_11:14_AM
/home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-20/001_Oct-20-2024_11:14_AM
> training arguments:
>>> rand_seed: 8
>>> model_name: mfcchfusion
>>> dataset: mvsa-mts
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f670dd69a80>
>>> learning_rate: 0.001
>>> dropout_rate: 0.5
>>> num_epoch: 10
>>> batch_size: 128
>>> log_step: 20
>>> max_seq_len: 64
>>> polarities_dim: 3
>>> clip_grad: 5.0
>>> path_image: ./Datasets/MVSA-MTS/images-indexed
>>> crop_size: 224
>>> roberta_text_feature_dim: 768
>>> roberta_topic_feature_dim: 50
>>> resnet_feature_dim: 2048
>>> densenet_feature_dim: 1024
>>> common_dim: 512
>>> num_classes: 3
>>> model_class: <class 'models.mfcchfusion.MFCCHFUSION'>
Preparing mvsa-mts dataset...
-------------- Loading Datasets/MVSA-MTS/mvsa-mts/train.tsv ---------------
Time taken to load Datasets/MVSA-MTS/mvsa-mts/train.tsv: 276.24 seconds (4.60 minutes)
The number of problematic samples: 402
-------------- Loading Datasets/MVSA-MTS/mvsa-mts/val.tsv ---------------
Time taken to load Datasets/MVSA-MTS/mvsa-mts/val.tsv: 90.46 seconds (1.51 minutes)
The number of problematic samples: 136
-------------- Loading Datasets/MVSA-MTS/mvsa-mts/test.tsv ---------------
Time taken to load Datasets/MVSA-MTS/mvsa-mts/test.tsv: 90.47 seconds (1.51 minutes)
The number of problematic samples: 142
Total Training Samples: 19600
Number of Training Samples: 11760
Number of Development Samples: 3920
Number of Test Samples: 3920
Number of unique sentiment classes: 3
building model
Using 2 GPUs
n_trainable_params: 7600131, n_nontrainable_params: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
Batch 0 completed in 4.66 seconds (0.08 minutes)
max_dev_f1: 0, max_test_f1: 0
loss: 2.847349, dev_acc: 47.83% (0.478316), dev_f1: 32.23% (0.322269), test_acc: 44.21% (0.442092), test_f1: 30.61% (0.306133)
Batch 20 completed in 1.22 seconds (0.02 minutes)
max_dev_f1: 0.3222688095899805, max_test_f1: 0.30613323597146547
loss: 9.685472, dev_acc: 44.29% (0.442857), dev_f1: 33.30% (0.333000), test_acc: 39.34% (0.393367), test_f1: 31.71% (0.317133)
Batch 40 completed in 1.22 seconds (0.02 minutes)
loss: 16.674614, dev_acc: 40.15% (0.401531), dev_f1: 31.18% (0.311786), test_acc: 41.56% (0.415561), test_f1: 31.42% (0.314243)
Batch 60 completed in 1.22 seconds (0.02 minutes)
loss: 24.971918, dev_acc: 40.61% (0.406122), dev_f1: 22.09% (0.220862), test_acc: 37.83% (0.378316), test_f1: 24.75% (0.247473)
Batch 80 completed in 1.23 seconds (0.02 minutes)
loss: 31.279181, dev_acc: 44.77% (0.447704), dev_f1: 30.82% (0.308166), test_acc: 42.86% (0.428571), test_f1: 31.04% (0.310408)
Epoch 0 completed in 355.84 seconds (5.93 minutes), avg loss: 17.320460
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
Batch 0 completed in 1.22 seconds (0.02 minutes)
loss: 18.498644, dev_acc: 46.12% (0.461224), dev_f1: 31.83% (0.318342), test_acc: 45.08% (0.450765), test_f1: 31.03% (0.310324)
Batch 20 completed in 1.23 seconds (0.02 minutes)
loss: 38.022823, dev_acc: 38.65% (0.386480), dev_f1: 25.13% (0.251275), test_acc: 39.34% (0.393367), test_f1: 24.34% (0.243427)
Batch 40 completed in 1.23 seconds (0.02 minutes)
loss: 10.755341, dev_acc: 51.05% (0.510459), dev_f1: 29.56% (0.295604), test_acc: 50.33% (0.503316), test_f1: 31.13% (0.311289)
Batch 60 completed in 1.23 seconds (0.02 minutes)
loss: 37.661682, dev_acc: 40.15% (0.401531), dev_f1: 19.10% (0.190996), test_acc: 38.78% (0.387755), test_f1: 18.63% (0.186275)
Batch 80 completed in 1.23 seconds (0.02 minutes)
loss: 9.719868, dev_acc: 50.54% (0.505357), dev_f1: 29.79% (0.297867), test_acc: 50.51% (0.505102), test_f1: 30.85% (0.308468)
Epoch 1 completed in 355.17 seconds (5.92 minutes), avg loss: 20.297554
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
Batch 0 completed in 1.23 seconds (0.02 minutes)
loss: 12.473095, dev_acc: 46.28% (0.462755), dev_f1: 31.96% (0.319572), test_acc: 42.98% (0.429847), test_f1: 33.27% (0.332711)
Batch 20 completed in 1.23 seconds (0.02 minutes)
loss: 9.945566, dev_acc: 51.05% (0.510459), dev_f1: 24.30% (0.242981), test_acc: 49.87% (0.498724), test_f1: 26.56% (0.265647)
Batch 40 completed in 1.23 seconds (0.02 minutes)
loss: 7.554340, dev_acc: 36.79% (0.367857), dev_f1: 30.50% (0.305033), test_acc: 39.18% (0.391837), test_f1: 31.79% (0.317913)
Batch 60 completed in 1.22 seconds (0.02 minutes)
loss: 11.238467, dev_acc: 42.86% (0.428571), dev_f1: 28.32% (0.283224), test_acc: 41.76% (0.417602), test_f1: 27.30% (0.272950)
Batch 80 completed in 1.28 seconds (0.02 minutes)
loss: 19.304785, dev_acc: 52.91% (0.529082), dev_f1: 23.07% (0.230675), test_acc: 53.78% (0.537755), test_f1: 23.31% (0.233134)
Epoch 2 completed in 357.43 seconds (5.96 minutes), avg loss: 12.830008
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
Batch 0 completed in 1.23 seconds (0.02 minutes)
loss: 6.881802, dev_acc: 50.36% (0.503571), dev_f1: 30.34% (0.303395), test_acc: 53.29% (0.532908), test_f1: 27.01% (0.270126)
Batch 20 completed in 1.22 seconds (0.02 minutes)
loss: 4.012754, dev_acc: 52.55% (0.525510), dev_f1: 25.45% (0.254504), test_acc: 53.65% (0.536480), test_f1: 24.34% (0.243423)
Batch 40 completed in 1.23 seconds (0.02 minutes)
loss: 6.529019, dev_acc: 47.70% (0.477041), dev_f1: 32.47% (0.324661), test_acc: 44.67% (0.446684), test_f1: 33.39% (0.333944)
Batch 60 completed in 1.22 seconds (0.02 minutes)
loss: 7.063947, dev_acc: 43.55% (0.435459), dev_f1: 28.82% (0.288212), test_acc: 42.60% (0.426020), test_f1: 29.16% (0.291611)
Batch 80 completed in 1.23 seconds (0.02 minutes)
loss: 3.588996, dev_acc: 41.51% (0.415051), dev_f1: 23.61% (0.236121), test_acc: 40.23% (0.402296), test_f1: 23.03% (0.230314)
Epoch 3 completed in 357.75 seconds (5.96 minutes), avg loss: 6.094452
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
Batch 0 completed in 1.22 seconds (0.02 minutes)
loss: 1.597102, dev_acc: 52.04% (0.520408), dev_f1: 27.09% (0.270877), test_acc: 52.96% (0.529592), test_f1: 25.72% (0.257236)
Batch 20 completed in 1.23 seconds (0.02 minutes)
loss: 14.814699, dev_acc: 44.85% (0.448469), dev_f1: 32.06% (0.320609), test_acc: 46.86% (0.468622), test_f1: 32.31% (0.323150)
Batch 40 completed in 1.23 seconds (0.02 minutes)
loss: 3.182002, dev_acc: 43.85% (0.438520), dev_f1: 29.25% (0.292505), test_acc: 42.60% (0.426020), test_f1: 29.15% (0.291494)
Batch 60 completed in 1.23 seconds (0.02 minutes)
loss: 16.435715, dev_acc: 47.73% (0.477296), dev_f1: 32.77% (0.327717), test_acc: 44.36% (0.443622), test_f1: 30.59% (0.305903)
Batch 80 completed in 1.22 seconds (0.02 minutes)
loss: 6.605509, dev_acc: 46.07% (0.460714), dev_f1: 31.67% (0.316677), test_acc: 46.61% (0.466071), test_f1: 31.09% (0.310899)
Epoch 4 completed in 358.14 seconds (5.97 minutes), avg loss: 7.033885
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
Batch 0 completed in 1.23 seconds (0.02 minutes)
loss: 7.073168, dev_acc: 46.15% (0.461480), dev_f1: 31.58% (0.315755), test_acc: 47.76% (0.477551), test_f1: 31.92% (0.319182)
Batch 20 completed in 1.23 seconds (0.02 minutes)
loss: 27.613544, dev_acc: 46.20% (0.461990), dev_f1: 25.07% (0.250722), test_acc: 46.76% (0.467602), test_f1: 25.33% (0.253291)
Batch 40 completed in 1.23 seconds (0.02 minutes)
loss: 48.780807, dev_acc: 42.88% (0.428827), dev_f1: 29.40% (0.294045), test_acc: 42.53% (0.425255), test_f1: 31.23% (0.312299)
Batch 60 completed in 1.23 seconds (0.02 minutes)
loss: 5.986445, dev_acc: 36.71% (0.367092), dev_f1: 29.78% (0.297835), test_acc: 36.96% (0.369643), test_f1: 30.15% (0.301460)
Batch 80 completed in 1.23 seconds (0.02 minutes)
loss: 5.940506, dev_acc: 44.08% (0.440816), dev_f1: 31.54% (0.315399), test_acc: 43.70% (0.436990), test_f1: 30.38% (0.303780)
Epoch 5 completed in 357.75 seconds (5.96 minutes), avg loss: 12.732081
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
Batch 0 completed in 1.23 seconds (0.02 minutes)
loss: 7.989135, dev_acc: 51.40% (0.514031), dev_f1: 23.83% (0.238321), test_acc: 53.11% (0.531122), test_f1: 23.80% (0.238012)
Batch 20 completed in 1.22 seconds (0.02 minutes)
loss: 12.580496, dev_acc: 40.61% (0.406122), dev_f1: 20.99% (0.209928), test_acc: 42.47% (0.424745), test_f1: 27.52% (0.275190)
Batch 40 completed in 1.22 seconds (0.02 minutes)
loss: 3.627869, dev_acc: 44.67% (0.446684), dev_f1: 25.61% (0.256128), test_acc: 49.46% (0.494643), test_f1: 29.85% (0.298471)
Batch 60 completed in 1.23 seconds (0.02 minutes)
loss: 7.779277, dev_acc: 41.86% (0.418622), dev_f1: 25.61% (0.256108), test_acc: 41.30% (0.413010), test_f1: 26.41% (0.264114)
Batch 80 completed in 1.23 seconds (0.02 minutes)
loss: 5.335253, dev_acc: 43.32% (0.433163), dev_f1: 29.35% (0.293512), test_acc: 43.42% (0.434184), test_f1: 29.66% (0.296571)
Epoch 6 completed in 357.41 seconds (5.96 minutes), avg loss: 8.371630
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 7
Batch 0 completed in 1.23 seconds (0.02 minutes)
loss: 5.542206, dev_acc: 21.86% (0.218622), dev_f1: 18.81% (0.188141), test_acc: 31.63% (0.316327), test_f1: 25.86% (0.258585)
Batch 20 completed in 1.22 seconds (0.02 minutes)
loss: 7.518241, dev_acc: 51.15% (0.511480), dev_f1: 29.59% (0.295926), test_acc: 52.96% (0.529592), test_f1: 26.55% (0.265506)
Batch 40 completed in 1.22 seconds (0.02 minutes)
loss: 4.441401, dev_acc: 48.11% (0.481122), dev_f1: 32.24% (0.322427), test_acc: 49.49% (0.494898), test_f1: 31.64% (0.316445)
Batch 60 completed in 1.22 seconds (0.02 minutes)
loss: 9.586157, dev_acc: 40.15% (0.401531), dev_f1: 19.10% (0.190996), test_acc: 38.78% (0.387755), test_f1: 18.63% (0.186275)
Batch 80 completed in 1.27 seconds (0.02 minutes)
loss: 14.452815, dev_acc: 44.11% (0.441071), dev_f1: 28.91% (0.289103), test_acc: 40.71% (0.407143), test_f1: 26.72% (0.267222)
Epoch 7 completed in 357.11 seconds (5.95 minutes), avg loss: 8.576570
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 8
Batch 0 completed in 1.23 seconds (0.02 minutes)
loss: 4.940629, dev_acc: 47.30% (0.472959), dev_f1: 31.85% (0.318499), test_acc: 48.49% (0.484949), test_f1: 31.17% (0.311726)
Batch 20 completed in 1.22 seconds (0.02 minutes)
loss: 13.525240, dev_acc: 51.56% (0.515561), dev_f1: 25.68% (0.256770), test_acc: 52.02% (0.520153), test_f1: 26.21% (0.262095)
Batch 40 completed in 1.23 seconds (0.02 minutes)
loss: 8.208933, dev_acc: 52.91% (0.529082), dev_f1: 23.07% (0.230675), test_acc: 53.65% (0.536480), test_f1: 24.34% (0.243423)
Batch 60 completed in 1.22 seconds (0.02 minutes)
loss: 5.358899, dev_acc: 48.95% (0.489541), dev_f1: 28.03% (0.280251), test_acc: 50.61% (0.506122), test_f1: 26.88% (0.268822)
Batch 80 completed in 1.23 seconds (0.02 minutes)
loss: 5.427953, dev_acc: 42.83% (0.428316), dev_f1: 27.91% (0.279124), test_acc: 45.59% (0.455867), test_f1: 31.02% (0.310183)
Epoch 8 completed in 357.60 seconds (5.96 minutes), avg loss: 7.468639
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 9
Batch 0 completed in 1.22 seconds (0.02 minutes)
loss: 3.775224, dev_acc: 47.53% (0.475255), dev_f1: 31.04% (0.310430), test_acc: 49.39% (0.493878), test_f1: 34.39% (0.343912)
Batch 20 completed in 1.23 seconds (0.02 minutes)
loss: 2.280856, dev_acc: 27.98% (0.279847), dev_f1: 26.37% (0.263716), test_acc: 21.22% (0.212245), test_f1: 19.73% (0.197285)
Batch 40 completed in 1.66 seconds (0.03 minutes)
loss: 3.312022, dev_acc: 51.79% (0.517857), dev_f1: 27.58% (0.275813), test_acc: 51.38% (0.513776), test_f1: 26.92% (0.269216)
Batch 60 completed in 1.23 seconds (0.02 minutes)
loss: 7.469521, dev_acc: 45.10% (0.451020), dev_f1: 30.10% (0.300978), test_acc: 48.57% (0.485714), test_f1: 26.08% (0.260758)
Batch 80 completed in 1.23 seconds (0.02 minutes)
loss: 3.818406, dev_acc: 52.24% (0.522449), dev_f1: 26.96% (0.269555), test_acc: 53.09% (0.530867), test_f1: 25.47% (0.254742)
Epoch 9 completed in 357.85 seconds (5.96 minutes), avg loss: 6.371532
Max dev F1: 33.30% (0.333000), Max test F1: 31.71% (0.317133)
Reading TensorBoard loss at each epoch:
Available tags: {'images': [], 'audio': [], 'histograms': [], 'scalars': ['Loss/train', 'Loss/epoch'], 'distributions': [], 'tensors': [], 'graph': False, 'meta_graph': False, 'run_metadata': []}
Step: 0, Loss: 2.8473494052886963
Step: 1, Loss: 4.519845485687256
Step: 2, Loss: 27.0120849609375
Step: 3, Loss: 22.012283325195312
Step: 4, Loss: 9.34809684753418
Step: 5, Loss: 22.31204605102539
Step: 6, Loss: 17.014785766601562
Step: 7, Loss: 20.83237075805664
Step: 8, Loss: 7.8638458251953125
Step: 9, Loss: 7.84114408493042
Step: 10, Loss: 6.350277900695801
Step: 11, Loss: 14.252642631530762
Step: 12, Loss: 17.153017044067383
Step: 13, Loss: 5.352967262268066
Step: 14, Loss: 9.534116744995117
Step: 15, Loss: 7.350788593292236
Step: 16, Loss: 7.765130996704102
Step: 17, Loss: 16.676137924194336
Step: 18, Loss: 35.639102935791016
Step: 19, Loss: 14.78070068359375
Step: 20, Loss: 9.68547248840332
Step: 21, Loss: 10.339434623718262
Step: 22, Loss: 11.408356666564941
Step: 23, Loss: 10.492131233215332
Step: 24, Loss: 13.818048477172852
Step: 25, Loss: 9.350661277770996
Step: 26, Loss: 7.790624141693115
Step: 27, Loss: 8.695556640625
Step: 28, Loss: 9.132893562316895
Step: 29, Loss: 18.517641067504883
Step: 30, Loss: 13.21483325958252
Step: 31, Loss: 22.300823211669922
Step: 32, Loss: 17.639455795288086
Step: 33, Loss: 9.540006637573242
Step: 34, Loss: 13.25378131866455
Step: 35, Loss: 17.212583541870117
Step: 36, Loss: 5.120772361755371
Step: 37, Loss: 18.879627227783203
Step: 38, Loss: 15.252742767333984
Step: 39, Loss: 7.042067050933838
Step: 40, Loss: 16.67461395263672
Step: 41, Loss: 11.238090515136719
Step: 42, Loss: 10.235029220581055
Step: 43, Loss: 10.352871894836426
Step: 44, Loss: 10.279492378234863
Step: 45, Loss: 12.025094032287598
Step: 46, Loss: 11.883440017700195
Step: 47, Loss: 7.766550064086914
Step: 48, Loss: 9.45766830444336
Step: 49, Loss: 5.807873725891113
Step: 50, Loss: 15.45948600769043
Step: 51, Loss: 28.369293212890625
Step: 52, Loss: 9.329684257507324
Step: 53, Loss: 13.97940731048584
Step: 54, Loss: 25.44404411315918
Step: 55, Loss: 11.9578857421875
Step: 56, Loss: 12.6807279586792
Step: 57, Loss: 24.249500274658203
Step: 58, Loss: 13.90488052368164
Step: 59, Loss: 12.096868515014648
Step: 60, Loss: 24.9719181060791
Step: 61, Loss: 62.018821716308594
Step: 62, Loss: 41.88541030883789
Step: 63, Loss: 12.95166015625
Step: 64, Loss: 15.451031684875488
Step: 65, Loss: 33.210548400878906
Step: 66, Loss: 43.43768310546875
Step: 67, Loss: 33.072139739990234
Step: 68, Loss: 5.001380443572998
Step: 69, Loss: 20.86648178100586
Step: 70, Loss: 35.81560134887695
Step: 71, Loss: 31.980209350585938
Step: 72, Loss: 14.698025703430176
Step: 73, Loss: 38.12354278564453
Step: 74, Loss: 11.231836318969727
Step: 75, Loss: 11.594808578491211
Step: 76, Loss: 17.184524536132812
Step: 77, Loss: 13.409478187561035
Step: 78, Loss: 4.657349109649658
Step: 79, Loss: 42.98070526123047
Step: 80, Loss: 31.2791805267334
Step: 81, Loss: 35.741920471191406
Step: 82, Loss: 22.658905029296875
Step: 83, Loss: 23.701385498046875
Step: 84, Loss: 26.57935333251953
Step: 85, Loss: 26.793563842773438
Step: 86, Loss: 18.898868560791016
Step: 87, Loss: 41.945499420166016
Step: 88, Loss: 6.9232587814331055
Step: 89, Loss: 8.890121459960938
Step: 90, Loss: 11.359106063842773
Step: 91, Loss: 25.829238891601562
Step: 92, Loss: 18.49864387512207
Step: 93, Loss: 17.411243438720703
Step: 94, Loss: 18.80083656311035
Step: 95, Loss: 19.025146484375
Step: 96, Loss: 27.125463485717773
Step: 97, Loss: 19.01476287841797
Step: 98, Loss: 28.010740280151367
Step: 99, Loss: 16.870891571044922
Step: 100, Loss: 28.046855926513672
Step: 101, Loss: 31.797317504882812
Step: 102, Loss: 24.890743255615234
Step: 103, Loss: 20.074874877929688
Step: 104, Loss: 19.924251556396484
Step: 105, Loss: 27.381418228149414
Step: 106, Loss: 44.265525817871094
Step: 107, Loss: 33.996551513671875
Step: 108, Loss: 24.310136795043945
Step: 109, Loss: 12.484272003173828
Step: 110, Loss: 12.473262786865234
Step: 111, Loss: 23.268234252929688
Step: 112, Loss: 38.022823333740234
Step: 113, Loss: 15.368102073669434
Step: 114, Loss: 13.957015037536621
Step: 115, Loss: 11.44468879699707
Step: 116, Loss: 14.519166946411133
Step: 117, Loss: 26.663196563720703
Step: 118, Loss: 23.2368221282959
Step: 119, Loss: 18.750221252441406
Step: 120, Loss: 17.871761322021484
Step: 121, Loss: 10.840446472167969
Step: 122, Loss: 18.11505126953125
Step: 123, Loss: 31.899459838867188
Step: 124, Loss: 14.932950019836426
Step: 125, Loss: 6.897119998931885
Step: 126, Loss: 12.79358196258545
Step: 127, Loss: 14.124545097351074
Step: 128, Loss: 16.922914505004883
Step: 129, Loss: 18.49298095703125
Step: 130, Loss: 7.729042053222656
Step: 131, Loss: 11.165820121765137
Step: 132, Loss: 10.755340576171875
Step: 133, Loss: 11.713038444519043
Step: 134, Loss: 20.246410369873047
Step: 135, Loss: 4.742863178253174
Step: 136, Loss: 11.439870834350586
Step: 137, Loss: 13.086127281188965
Step: 138, Loss: 14.857612609863281
Step: 139, Loss: 21.145442962646484
Step: 140, Loss: 15.563905715942383
Step: 141, Loss: 6.3384270668029785
Step: 142, Loss: 21.74492835998535
Step: 143, Loss: 16.527679443359375
Step: 144, Loss: 3.9212520122528076
Step: 145, Loss: 6.077349662780762
Step: 146, Loss: 41.73392105102539
Step: 147, Loss: 42.389259338378906
Step: 148, Loss: 20.420907974243164
Step: 149, Loss: 23.756441116333008
Step: 150, Loss: 11.646145820617676
Step: 151, Loss: 41.771141052246094
Step: 152, Loss: 37.66168212890625
Step: 153, Loss: 39.73219299316406
Step: 154, Loss: 18.379776000976562
Step: 155, Loss: 17.733484268188477
Step: 156, Loss: 44.57471466064453
Step: 157, Loss: 32.65899658203125
Step: 158, Loss: 39.01762390136719
Step: 159, Loss: 27.7116641998291
Step: 160, Loss: 8.09390926361084
Step: 161, Loss: 30.425243377685547
Step: 162, Loss: 39.330562591552734
Step: 163, Loss: 19.743261337280273
Step: 164, Loss: 17.981124877929688
Step: 165, Loss: 12.729903221130371
Step: 166, Loss: 26.37383270263672
Step: 167, Loss: 25.083709716796875
Step: 168, Loss: 27.395538330078125
Step: 169, Loss: 27.959508895874023
Step: 170, Loss: 11.030942916870117
Step: 171, Loss: 17.149198532104492
Step: 172, Loss: 9.719867706298828
Step: 173, Loss: 14.631570816040039
Step: 174, Loss: 13.336514472961426
Step: 175, Loss: 23.333208084106445
Step: 176, Loss: 13.215662002563477
Step: 177, Loss: 7.32787561416626
Step: 178, Loss: 17.302568435668945
Step: 179, Loss: 13.905050277709961
Step: 180, Loss: 11.569263458251953
Step: 181, Loss: 8.524896621704102
Step: 182, Loss: 18.370758056640625
Step: 183, Loss: 24.07394027709961
Step: 184, Loss: 12.473094940185547
Step: 185, Loss: 8.45645523071289
Step: 186, Loss: 25.660057067871094
Step: 187, Loss: 29.210058212280273
Step: 188, Loss: 31.866228103637695
Step: 189, Loss: 16.20650863647461
Step: 190, Loss: 8.375372886657715
Step: 191, Loss: 24.887996673583984
Step: 192, Loss: 19.655519485473633
Step: 193, Loss: 35.20566177368164
Step: 194, Loss: 25.25967025756836
Step: 195, Loss: 24.81159782409668
Step: 196, Loss: 26.857826232910156
Step: 197, Loss: 15.919442176818848
Step: 198, Loss: 8.450630187988281
Step: 199, Loss: 16.10293960571289
Step: 200, Loss: 14.275875091552734
Step: 201, Loss: 20.953096389770508
Step: 202, Loss: 15.721623420715332
Step: 203, Loss: 14.743983268737793
Step: 204, Loss: 9.945566177368164
Step: 205, Loss: 17.58704948425293
Step: 206, Loss: 18.008098602294922
Step: 207, Loss: 30.781585693359375
Step: 208, Loss: 10.275186538696289
Step: 209, Loss: 16.29391860961914
Step: 210, Loss: 12.022661209106445
Step: 211, Loss: 22.462696075439453
Step: 212, Loss: 18.758033752441406
Step: 213, Loss: 12.446102142333984
Step: 214, Loss: 9.251769065856934
Step: 215, Loss: 3.3429157733917236
Step: 216, Loss: 10.561441421508789
Step: 217, Loss: 12.863810539245605
Step: 218, Loss: 2.8615729808807373
Step: 219, Loss: 6.027901649475098
Step: 220, Loss: 5.768234729766846
Step: 221, Loss: 3.415416717529297
Step: 222, Loss: 19.52118682861328
Step: 223, Loss: 7.294447898864746
Step: 224, Loss: 7.554340362548828
Step: 225, Loss: 10.142168998718262
Step: 226, Loss: 10.908121109008789
Step: 227, Loss: 11.758750915527344
Step: 228, Loss: 17.37839126586914
Step: 229, Loss: 12.733989715576172
Step: 230, Loss: 20.859859466552734
Step: 231, Loss: 10.270977973937988
Step: 232, Loss: 7.359992027282715
Step: 233, Loss: 11.296792984008789
Step: 234, Loss: 6.628837585449219
Step: 235, Loss: 22.284055709838867
Step: 236, Loss: 13.672277450561523
Step: 237, Loss: 14.682880401611328
Step: 238, Loss: 6.3660969734191895
Step: 239, Loss: 11.429163932800293
Step: 240, Loss: 10.119625091552734
Step: 241, Loss: 6.604960918426514
Step: 242, Loss: 11.807684898376465
Step: 243, Loss: 9.056024551391602
Step: 244, Loss: 11.2384672164917
Step: 245, Loss: 8.501435279846191
Step: 246, Loss: 6.96522855758667
Step: 247, Loss: 7.2405104637146
Step: 248, Loss: 8.499349594116211
Step: 249, Loss: 7.260556221008301
Step: 250, Loss: 6.961417198181152
Step: 251, Loss: 3.837045431137085
Step: 252, Loss: 6.071374893188477
Step: 253, Loss: 9.88900375366211
Step: 254, Loss: 10.817425727844238
Step: 255, Loss: 3.0328900814056396
Step: 256, Loss: 5.508222579956055
Step: 257, Loss: 5.6519927978515625
Step: 258, Loss: 6.089416980743408
Step: 259, Loss: 4.803122043609619
Step: 260, Loss: 4.927542209625244
Step: 261, Loss: 31.856348037719727
Step: 262, Loss: 18.592905044555664
Step: 263, Loss: 23.091224670410156
Step: 264, Loss: 19.304784774780273
Step: 265, Loss: 15.41944694519043
Step: 266, Loss: 13.101435661315918
Step: 267, Loss: 12.706571578979492
Step: 268, Loss: 3.51541805267334
Step: 269, Loss: 7.392446041107178
Step: 270, Loss: 7.461363792419434
Step: 271, Loss: 6.3258376121521
Step: 272, Loss: 6.91466760635376
Step: 273, Loss: 5.211464881896973
Step: 274, Loss: 6.762026786804199
Step: 275, Loss: 7.911553859710693
Step: 276, Loss: 6.881802082061768
Step: 277, Loss: 4.5790205001831055
Step: 278, Loss: 7.25816535949707
Step: 279, Loss: 7.041473388671875
Step: 280, Loss: 8.95425796508789
Step: 281, Loss: 9.032671928405762
Step: 282, Loss: 1.8236249685287476
Step: 283, Loss: 5.936920642852783
Step: 284, Loss: 7.27243709564209
Step: 285, Loss: 9.891745567321777
Step: 286, Loss: 8.506364822387695
Step: 287, Loss: 9.735616683959961
Step: 288, Loss: 11.808454513549805
Step: 289, Loss: 5.377101421356201
Step: 290, Loss: 4.0447773933410645
Step: 291, Loss: 5.981165409088135
Step: 292, Loss: 8.533306121826172
Step: 293, Loss: 6.770820140838623
Step: 294, Loss: 7.526987075805664
Step: 295, Loss: 4.902522087097168
Step: 296, Loss: 4.012753963470459
Step: 297, Loss: 11.458114624023438
Step: 298, Loss: 9.500187873840332
Step: 299, Loss: 18.850130081176758
Step: 300, Loss: 10.175652503967285
Step: 301, Loss: 3.790557384490967
Step: 302, Loss: 2.3278543949127197
Step: 303, Loss: 8.027494430541992
Step: 304, Loss: 8.487296104431152
Step: 305, Loss: 6.935131072998047
Step: 306, Loss: 5.028314590454102
Step: 307, Loss: 8.645462989807129
Step: 308, Loss: 4.5905537605285645
Step: 309, Loss: 5.548603057861328
Step: 310, Loss: 4.698672771453857
Step: 311, Loss: 5.172423362731934
Step: 312, Loss: 2.5981945991516113
Step: 313, Loss: 7.6658549308776855
Step: 314, Loss: 4.107644557952881
Step: 315, Loss: 4.716011047363281
Step: 316, Loss: 6.529019355773926
Step: 317, Loss: 5.505393028259277
Step: 318, Loss: 4.267275810241699
Step: 319, Loss: 3.9129977226257324
Step: 320, Loss: 3.1867308616638184
Step: 321, Loss: 2.728271961212158
Step: 322, Loss: 4.421371936798096
Step: 323, Loss: 5.618472576141357
Step: 324, Loss: 5.439637660980225
Step: 325, Loss: 10.556629180908203
Step: 326, Loss: 5.252052307128906
Step: 327, Loss: 5.154101848602295
Step: 328, Loss: 9.168933868408203
Step: 329, Loss: 12.149306297302246
Step: 330, Loss: 7.7418670654296875
Step: 331, Loss: 5.400230407714844
Step: 332, Loss: 6.722179412841797
Step: 333, Loss: 9.871174812316895
Step: 334, Loss: 7.058681488037109
Step: 335, Loss: 8.660601615905762
Step: 336, Loss: 7.063946723937988
Step: 337, Loss: 5.970041275024414
Step: 338, Loss: 6.729285717010498
Step: 339, Loss: 2.603522539138794
Step: 340, Loss: 2.3497304916381836
Step: 341, Loss: 2.7662134170532227
Step: 342, Loss: 2.9835286140441895
Step: 343, Loss: 3.5171854496002197
Step: 344, Loss: 3.452486038208008
Step: 345, Loss: 9.288634300231934
Step: 346, Loss: 5.284213066101074
Step: 347, Loss: 7.819951057434082
Step: 348, Loss: 2.600421190261841
Step: 349, Loss: 2.859034299850464
Step: 350, Loss: 5.053585052490234
Step: 351, Loss: 6.077638626098633
Step: 352, Loss: 3.542691469192505
Step: 353, Loss: 4.93267297744751
Step: 354, Loss: 4.796112537384033
Step: 355, Loss: 4.4154372215271
Step: 356, Loss: 3.588996410369873
Step: 357, Loss: 5.981756687164307
Step: 358, Loss: 4.659533977508545
Step: 359, Loss: 5.513507843017578
Step: 360, Loss: 5.964030742645264
Step: 361, Loss: 3.9326250553131104
Step: 362, Loss: 5.08144474029541
Step: 363, Loss: 7.2508673667907715
Step: 364, Loss: 1.95211923122406
Step: 365, Loss: 6.773852825164795
Step: 366, Loss: 3.9605348110198975
Step: 367, Loss: 4.382944583892822
Step: 368, Loss: 1.597102403640747
Step: 369, Loss: 7.017804145812988
Step: 370, Loss: 5.964176654815674
Step: 371, Loss: 5.324761867523193
Step: 372, Loss: 3.1297695636749268
Step: 373, Loss: 4.6662116050720215
Step: 374, Loss: 8.460257530212402
Step: 375, Loss: 6.583615303039551
Step: 376, Loss: 4.972573757171631
Step: 377, Loss: 4.739354610443115
Step: 378, Loss: 4.155072212219238
Step: 379, Loss: 6.80645751953125
Step: 380, Loss: 5.915835380554199
Step: 381, Loss: 3.11637806892395
Step: 382, Loss: 3.7690465450286865
Step: 383, Loss: 8.313108444213867
Step: 384, Loss: 11.946282386779785
Step: 385, Loss: 4.7235493659973145
Step: 386, Loss: 4.2946600914001465
Step: 387, Loss: 8.307193756103516
Step: 388, Loss: 14.814699172973633
Step: 389, Loss: 3.2916712760925293
Step: 390, Loss: 5.717287063598633
Step: 391, Loss: 5.566527843475342
Step: 392, Loss: 8.112377166748047
Step: 393, Loss: 5.786340236663818
Step: 394, Loss: 4.219489097595215
Step: 395, Loss: 4.524605751037598
Step: 396, Loss: 1.8274668455123901
Step: 397, Loss: 2.216054677963257
Step: 398, Loss: 4.4512224197387695
Step: 399, Loss: 4.1487531661987305
Step: 400, Loss: 2.5057036876678467
Step: 401, Loss: 2.426717519760132
Step: 402, Loss: 1.5217713117599487
Step: 403, Loss: 3.7963364124298096
Step: 404, Loss: 3.189863681793213
Step: 405, Loss: 5.414670944213867
Step: 406, Loss: 6.954680442810059
Step: 407, Loss: 5.70973014831543
Step: 408, Loss: 3.1820015907287598
Step: 409, Loss: 7.2379279136657715
Step: 410, Loss: 7.440917491912842
Step: 411, Loss: 7.380953788757324
Step: 412, Loss: 5.024564743041992
Step: 413, Loss: 3.787393808364868
Step: 414, Loss: 3.235628843307495
Step: 415, Loss: 1.7655096054077148
Step: 416, Loss: 9.369828224182129
Step: 417, Loss: 7.4061198234558105
Step: 418, Loss: 6.803066730499268
Step: 419, Loss: 7.380350589752197
Step: 420, Loss: 16.238441467285156
Step: 421, Loss: 5.296792030334473
Step: 422, Loss: 9.13432788848877
Step: 423, Loss: 5.46372127532959
Step: 424, Loss: 6.419224739074707
Step: 425, Loss: 5.590743064880371
Step: 426, Loss: 8.265521049499512
Step: 427, Loss: 9.624798774719238
Step: 428, Loss: 16.435714721679688
Step: 429, Loss: 7.877870559692383
Step: 430, Loss: 13.553780555725098
Step: 431, Loss: 2.370651960372925
Step: 432, Loss: 5.160761833190918
Step: 433, Loss: 4.562613010406494
Step: 434, Loss: 19.027883529663086
Step: 435, Loss: 24.352806091308594
Step: 436, Loss: 2.845832586288452
Step: 437, Loss: 13.202115058898926
Step: 438, Loss: 11.315533638000488
Step: 439, Loss: 8.478666305541992
Step: 440, Loss: 6.890552997589111
Step: 441, Loss: 13.85363483428955
Step: 442, Loss: 12.745285034179688
Step: 443, Loss: 15.585101127624512
Step: 444, Loss: 10.403076171875
Step: 445, Loss: 6.377594470977783
Step: 446, Loss: 11.014002799987793
Step: 447, Loss: 9.335249900817871
Step: 448, Loss: 6.605508804321289
Step: 449, Loss: 10.32816219329834
Step: 450, Loss: 7.354782581329346
Step: 451, Loss: 9.402811050415039
Step: 452, Loss: 4.730778217315674
Step: 453, Loss: 8.29135799407959
Step: 454, Loss: 13.901429176330566
Step: 455, Loss: 7.920502662658691
Step: 456, Loss: 5.7537522315979
Step: 457, Loss: 2.106574058532715
Step: 458, Loss: 4.401113033294678
Step: 459, Loss: 4.884868621826172
Step: 460, Loss: 7.0731682777404785
Step: 461, Loss: 7.66506290435791
Step: 462, Loss: 10.29372501373291
Step: 463, Loss: 3.538562297821045
Step: 464, Loss: 11.325324058532715
Step: 465, Loss: 16.208208084106445
Step: 466, Loss: 15.250445365905762
Step: 467, Loss: 12.670345306396484
Step: 468, Loss: 9.666009902954102
Step: 469, Loss: 9.636181831359863
Step: 470, Loss: 7.910333633422852
Step: 471, Loss: 9.896824836730957
Step: 472, Loss: 9.084844589233398
Step: 473, Loss: 7.79077672958374
Step: 474, Loss: 7.906720161437988
Step: 475, Loss: 10.087244033813477
Step: 476, Loss: 19.237581253051758
Step: 477, Loss: 11.790801048278809
Step: 478, Loss: 11.044136047363281
Step: 479, Loss: 26.921472549438477
Step: 480, Loss: 27.613544464111328
Step: 481, Loss: 28.35746955871582
Step: 482, Loss: 19.36063003540039
Step: 483, Loss: 19.079593658447266
Step: 484, Loss: 3.438325881958008
Step: 485, Loss: 10.470680236816406
Step: 486, Loss: 18.092241287231445
Step: 487, Loss: 10.544388771057129
Step: 488, Loss: 7.980393409729004
Step: 489, Loss: 13.404775619506836
Step: 490, Loss: 12.923020362854004
Step: 491, Loss: 8.368849754333496
Step: 492, Loss: 20.512432098388672
Step: 493, Loss: 21.508140563964844
Step: 494, Loss: 7.8371429443359375
Step: 495, Loss: 18.324525833129883
Step: 496, Loss: 25.485660552978516
Step: 497, Loss: 4.283291339874268
Step: 498, Loss: 12.981979370117188
Step: 499, Loss: 5.091344833374023
Step: 500, Loss: 48.78080749511719
Step: 501, Loss: 6.878506183624268
Step: 502, Loss: 8.079538345336914
Step: 503, Loss: 13.189302444458008
Step: 504, Loss: 12.454773902893066
Step: 505, Loss: 13.084179878234863
Step: 506, Loss: 16.9637393951416
Step: 507, Loss: 13.875033378601074
Step: 508, Loss: 42.995216369628906
Step: 509, Loss: 13.004486083984375
Step: 510, Loss: 15.495059967041016
Step: 511, Loss: 11.991656303405762
Step: 512, Loss: 12.05726432800293
Step: 513, Loss: 13.88195514678955
Step: 514, Loss: 16.166627883911133
Step: 515, Loss: 12.568268775939941
Step: 516, Loss: 15.601197242736816
Step: 517, Loss: 18.484981536865234
Step: 518, Loss: 15.780742645263672
Step: 519, Loss: 15.371699333190918
Step: 520, Loss: 5.986445426940918
Step: 521, Loss: 8.851335525512695
Step: 522, Loss: 3.86616849899292
Step: 523, Loss: 31.94684410095215
Step: 524, Loss: 8.177059173583984
Step: 525, Loss: 10.113541603088379
Step: 526, Loss: 5.757645130157471
Step: 527, Loss: 7.727388381958008
Step: 528, Loss: 8.912070274353027
Step: 529, Loss: 5.758946418762207
Step: 530, Loss: 11.060460090637207
Step: 531, Loss: 6.208139896392822
Step: 532, Loss: 7.2906575202941895
Step: 533, Loss: 19.148569107055664
Step: 534, Loss: 14.885512351989746
Step: 535, Loss: 11.199206352233887
Step: 536, Loss: 7.669339656829834
Step: 537, Loss: 5.948800563812256
Step: 538, Loss: 16.200040817260742
Step: 539, Loss: 15.449322700500488
Step: 540, Loss: 5.9405059814453125
Step: 541, Loss: 6.289582252502441
Step: 542, Loss: 14.266103744506836
Step: 543, Loss: 12.416742324829102
Step: 544, Loss: 8.521976470947266
Step: 545, Loss: 5.299017429351807
Step: 546, Loss: 12.73095703125
Step: 547, Loss: 14.79835033416748
Step: 548, Loss: 6.216802597045898
Step: 549, Loss: 1.9472204446792603
Step: 550, Loss: 8.276638984680176
Step: 551, Loss: 5.1288580894470215
Step: 552, Loss: 7.989134788513184
Step: 553, Loss: 6.54457426071167
Step: 554, Loss: 11.381881713867188
Step: 555, Loss: 6.423816680908203
Step: 556, Loss: 6.321891784667969
Step: 557, Loss: 13.020776748657227
Step: 558, Loss: 9.15180492401123
Step: 559, Loss: 12.042318344116211
Step: 560, Loss: 5.261158466339111
Step: 561, Loss: 6.337034702301025
Step: 562, Loss: 9.761481285095215
Step: 563, Loss: 8.793922424316406
Step: 564, Loss: 9.563490867614746
Step: 565, Loss: 12.97607421875
Step: 566, Loss: 17.589401245117188
Step: 567, Loss: 13.402688980102539
Step: 568, Loss: 9.25779914855957
Step: 569, Loss: 6.738827705383301
Step: 570, Loss: 13.525314331054688
Step: 571, Loss: 24.084932327270508
Step: 572, Loss: 12.580495834350586
Step: 573, Loss: 7.430173397064209
Step: 574, Loss: 6.897127628326416
Step: 575, Loss: 9.217816352844238
Step: 576, Loss: 8.078156471252441
Step: 577, Loss: 4.515566349029541
Step: 578, Loss: 5.049652576446533
Step: 579, Loss: 5.62715482711792
Step: 580, Loss: 2.067544937133789
Step: 581, Loss: 3.1159534454345703
Step: 582, Loss: 6.218001842498779
Step: 583, Loss: 2.7884414196014404
Step: 584, Loss: 6.335873603820801
Step: 585, Loss: 3.9907286167144775
Step: 586, Loss: 4.638007640838623
Step: 587, Loss: 14.859084129333496
Step: 588, Loss: 5.104483604431152
Step: 589, Loss: 7.735464096069336
Step: 590, Loss: 6.387659072875977
Step: 591, Loss: 7.074311256408691
Step: 592, Loss: 3.627868890762329
Step: 593, Loss: 3.215449810028076
Step: 594, Loss: 15.515233039855957
Step: 595, Loss: 16.01378631591797
Step: 596, Loss: 12.329784393310547
Step: 597, Loss: 7.910682201385498
Step: 598, Loss: 6.577425956726074
Step: 599, Loss: 10.563859939575195
Step: 600, Loss: 11.810391426086426
Step: 601, Loss: 8.02783203125
Step: 602, Loss: 12.61689281463623
Step: 603, Loss: 22.031707763671875
Step: 604, Loss: 5.6180009841918945
Step: 605, Loss: 14.943405151367188
Step: 606, Loss: 13.961504936218262
Step: 607, Loss: 12.597159385681152
Step: 608, Loss: 9.836200714111328
Step: 609, Loss: 15.045576095581055
Step: 610, Loss: 9.651256561279297
Step: 611, Loss: 7.793784141540527
Step: 612, Loss: 7.779277324676514
Step: 613, Loss: 8.03817081451416
Step: 614, Loss: 8.012829780578613
Step: 615, Loss: 6.112331867218018
Step: 616, Loss: 4.549782752990723
Step: 617, Loss: 6.07271671295166
Step: 618, Loss: 7.276083469390869
Step: 619, Loss: 7.335013389587402
Step: 620, Loss: 7.817492485046387
Step: 621, Loss: 5.720277309417725
Step: 622, Loss: 4.468562126159668
Step: 623, Loss: 9.90062427520752
Step: 624, Loss: 3.433117151260376
Step: 625, Loss: 3.352017402648926
Step: 626, Loss: 6.9320878982543945
Step: 627, Loss: 3.775939702987671
Step: 628, Loss: 4.287864685058594
Step: 629, Loss: 8.585208892822266
Step: 630, Loss: 2.623300313949585
Step: 631, Loss: 4.936849594116211
Step: 632, Loss: 5.33525276184082
Step: 633, Loss: 4.217180252075195
Step: 634, Loss: 6.686594486236572
Step: 635, Loss: 4.535965442657471
Step: 636, Loss: 5.337357044219971
Step: 637, Loss: 5.6254754066467285
Step: 638, Loss: 13.321187019348145
Step: 639, Loss: 8.0760498046875
Step: 640, Loss: 14.141092300415039
Step: 641, Loss: 6.016402721405029
Step: 642, Loss: 7.14053201675415
Step: 643, Loss: 9.179491996765137
Step: 644, Loss: 5.542205810546875
Step: 645, Loss: 18.41010856628418
Step: 646, Loss: 17.21466827392578
Step: 647, Loss: 15.372426986694336
Step: 648, Loss: 11.640891075134277
Step: 649, Loss: 7.87007999420166
Step: 650, Loss: 5.91931676864624
Step: 651, Loss: 11.05536937713623
Step: 652, Loss: 10.353882789611816
Step: 653, Loss: 13.488965034484863
Step: 654, Loss: 12.19968032836914
Step: 655, Loss: 7.538045406341553
Step: 656, Loss: 5.136754035949707
Step: 657, Loss: 3.860368490219116
Step: 658, Loss: 2.9223639965057373
Step: 659, Loss: 7.654138565063477
Step: 660, Loss: 5.602637767791748
Step: 661, Loss: 9.415308952331543
Step: 662, Loss: 8.268208503723145
Step: 663, Loss: 5.284186840057373
Step: 664, Loss: 7.5182414054870605
Step: 665, Loss: 8.727023124694824
Step: 666, Loss: 3.4609861373901367
Step: 667, Loss: 7.610998153686523
Step: 668, Loss: 7.542789936065674
Step: 669, Loss: 5.493926048278809
Step: 670, Loss: 4.265483379364014
Step: 671, Loss: 10.389667510986328
Step: 672, Loss: 3.439042091369629
Step: 673, Loss: 9.396363258361816
Step: 674, Loss: 5.532450199127197
Step: 675, Loss: 14.003926277160645
Step: 676, Loss: 3.645601272583008
Step: 677, Loss: 2.218090534210205
Step: 678, Loss: 9.445530891418457
Step: 679, Loss: 8.007680892944336
Step: 680, Loss: 5.501424312591553
Step: 681, Loss: 9.90157699584961
Step: 682, Loss: 10.07738208770752
Step: 683, Loss: 5.737025260925293
Step: 684, Loss: 4.441401481628418
Step: 685, Loss: 2.6212711334228516
Step: 686, Loss: 12.942195892333984
Step: 687, Loss: 3.7806007862091064
Step: 688, Loss: 5.476748466491699
Step: 689, Loss: 5.877951145172119
Step: 690, Loss: 7.900381565093994
Step: 691, Loss: 15.003440856933594
Step: 692, Loss: 8.221577644348145
Step: 693, Loss: 11.344099998474121
Step: 694, Loss: 4.6003804206848145
Step: 695, Loss: 3.9364304542541504
Step: 696, Loss: 7.327434539794922
Step: 697, Loss: 10.798422813415527
Step: 698, Loss: 10.103301048278809
Step: 699, Loss: 12.205240249633789
Step: 700, Loss: 16.707719802856445
Step: 701, Loss: 11.215815544128418
Step: 702, Loss: 12.388400077819824
Step: 703, Loss: 10.034139633178711
Step: 704, Loss: 9.586156845092773
Step: 705, Loss: 12.894388198852539
Step: 706, Loss: 23.38479232788086
Step: 707, Loss: 15.699231147766113
Step: 708, Loss: 7.172632694244385
Step: 709, Loss: 3.3228321075439453
Step: 710, Loss: 11.028349876403809
Step: 711, Loss: 11.974496841430664
Step: 712, Loss: 4.200195789337158
Step: 713, Loss: 7.744293689727783
Step: 714, Loss: 5.447874546051025
Step: 715, Loss: 6.507388114929199
Step: 716, Loss: 4.669909954071045
Step: 717, Loss: 7.777832508087158
Step: 718, Loss: 3.85180401802063
Step: 719, Loss: 7.197364330291748
Step: 720, Loss: 13.309112548828125
Step: 721, Loss: 12.298341751098633
Step: 722, Loss: 4.500090599060059
Step: 723, Loss: 7.448281288146973
Step: 724, Loss: 14.452815055847168
Step: 725, Loss: 9.664453506469727
Step: 726, Loss: 14.992761611938477
Step: 727, Loss: 7.726408958435059
Step: 728, Loss: 11.511234283447266
Step: 729, Loss: 6.0654120445251465
Step: 730, Loss: 9.902841567993164
Step: 731, Loss: 3.5738792419433594
Step: 732, Loss: 6.587779521942139
Step: 733, Loss: 9.783089637756348
Step: 734, Loss: 5.714618682861328
Step: 735, Loss: 5.461971759796143
Step: 736, Loss: 4.940629482269287
Step: 737, Loss: 7.319939136505127
Step: 738, Loss: 8.107320785522461
Step: 739, Loss: 11.394501686096191
Step: 740, Loss: 10.32857608795166
Step: 741, Loss: 7.6628594398498535
Step: 742, Loss: 6.0295891761779785
Step: 743, Loss: 19.3679256439209
Step: 744, Loss: 10.302680969238281
Step: 745, Loss: 5.80320405960083
Step: 746, Loss: 9.192697525024414
Step: 747, Loss: 11.755755424499512
Step: 748, Loss: 14.051222801208496
Step: 749, Loss: 10.275535583496094
Step: 750, Loss: 3.6273741722106934
Step: 751, Loss: 9.447635650634766
Step: 752, Loss: 7.688816547393799
Step: 753, Loss: 10.99580192565918
Step: 754, Loss: 6.345102310180664
Step: 755, Loss: 6.857546806335449
Step: 756, Loss: 13.525239944458008
Step: 757, Loss: 7.886047840118408
Step: 758, Loss: 10.534745216369629
Step: 759, Loss: 4.835596561431885
Step: 760, Loss: 5.0494256019592285
Step: 761, Loss: 14.72507095336914
Step: 762, Loss: 9.626028060913086
Step: 763, Loss: 5.720629692077637
Step: 764, Loss: 2.1271932125091553
Step: 765, Loss: 4.998589038848877
Step: 766, Loss: 6.992037773132324
Step: 767, Loss: 7.704329490661621
Step: 768, Loss: 7.239580154418945
Step: 769, Loss: 14.033833503723145
Step: 770, Loss: 4.08757209777832
Step: 771, Loss: 2.8592395782470703
Step: 772, Loss: 12.833399772644043
Step: 773, Loss: 6.202952861785889
Step: 774, Loss: 5.165205001831055
Step: 775, Loss: 4.0463690757751465
Step: 776, Loss: 8.208932876586914
Step: 777, Loss: 10.345804214477539
Step: 778, Loss: 4.112058162689209
Step: 779, Loss: 5.466622352600098
Step: 780, Loss: 3.5847384929656982
Step: 781, Loss: 5.542252063751221
Step: 782, Loss: 7.983009338378906
Step: 783, Loss: 5.088685989379883
Step: 784, Loss: 6.003464221954346
Step: 785, Loss: 4.132068157196045
Step: 786, Loss: 6.918832778930664
Step: 787, Loss: 6.8266282081604
Step: 788, Loss: 2.957383632659912
Step: 789, Loss: 2.3454699516296387
Step: 790, Loss: 9.590570449829102
Step: 791, Loss: 7.044093132019043
Step: 792, Loss: 7.6498918533325195
Step: 793, Loss: 3.064490795135498
Step: 794, Loss: 9.469856262207031
Step: 795, Loss: 3.038224458694458
Step: 796, Loss: 5.358898639678955
Step: 797, Loss: 5.337197780609131
Step: 798, Loss: 6.374338150024414
Step: 799, Loss: 6.002790451049805
Step: 800, Loss: 2.2604291439056396
Step: 801, Loss: 4.202265739440918
Step: 802, Loss: 10.235377311706543
Step: 803, Loss: 15.096736907958984
Step: 804, Loss: 8.927876472473145
Step: 805, Loss: 3.206973075866699
Step: 806, Loss: 7.574551105499268
Step: 807, Loss: 9.443365097045898
Step: 808, Loss: 12.538267135620117
Step: 809, Loss: 12.57739543914795
Step: 810, Loss: 7.308723449707031
Step: 811, Loss: 7.207173824310303
Step: 812, Loss: 9.765695571899414
Step: 813, Loss: 3.0556390285491943
Step: 814, Loss: 12.746362686157227
Step: 815, Loss: 10.948335647583008
Step: 816, Loss: 5.427952766418457
Step: 817, Loss: 7.670454502105713
Step: 818, Loss: 8.559798240661621
Step: 819, Loss: 7.7450995445251465
Step: 820, Loss: 9.159490585327148
Step: 821, Loss: 3.073514699935913
Step: 822, Loss: 6.3147687911987305
Step: 823, Loss: 4.943111896514893
Step: 824, Loss: 8.786449432373047
Step: 825, Loss: 6.9379191398620605
Step: 826, Loss: 5.112255573272705
Step: 827, Loss: 2.154716730117798
Step: 828, Loss: 3.775224447250366
Step: 829, Loss: 3.15279221534729
Step: 830, Loss: 1.2975857257843018
Step: 831, Loss: 10.162514686584473
Step: 832, Loss: 3.680345296859741
Step: 833, Loss: 3.948479652404785
Step: 834, Loss: 6.020188331604004
Step: 835, Loss: 2.164374351501465
Step: 836, Loss: 3.784175395965576
Step: 837, Loss: 5.446529865264893
Step: 838, Loss: 2.8110110759735107
Step: 839, Loss: 5.097570896148682
Step: 840, Loss: 3.656348705291748
Step: 841, Loss: 1.2644890546798706
Step: 842, Loss: 5.2124714851379395
Step: 843, Loss: 7.927778720855713
Step: 844, Loss: 6.767916679382324
Step: 845, Loss: 10.783061981201172
Step: 846, Loss: 2.8870351314544678
Step: 847, Loss: 5.879900932312012
Step: 848, Loss: 2.280855894088745
Step: 849, Loss: 20.34710693359375
Step: 850, Loss: 4.107387065887451
Step: 851, Loss: 7.10123348236084
Step: 852, Loss: 8.634885787963867
Step: 853, Loss: 3.969855546951294
Step: 854, Loss: 6.392463684082031
Step: 855, Loss: 5.6838507652282715
Step: 856, Loss: 10.818951606750488
Step: 857, Loss: 7.72430419921875
Step: 858, Loss: 3.874101400375366
Step: 859, Loss: 9.281539916992188
Step: 860, Loss: 14.022783279418945
Step: 861, Loss: 2.7375130653381348
Step: 862, Loss: 3.536530017852783
Step: 863, Loss: 3.3756682872772217
Step: 864, Loss: 5.61270809173584
Step: 865, Loss: 9.169451713562012
Step: 866, Loss: 9.443543434143066
Step: 867, Loss: 5.7983269691467285
Step: 868, Loss: 3.3120224475860596
Step: 869, Loss: 4.805055618286133
Step: 870, Loss: 5.358918190002441
Step: 871, Loss: 9.175086975097656
Step: 872, Loss: 8.34746265411377
Step: 873, Loss: 5.577847957611084
Step: 874, Loss: 5.487809181213379
Step: 875, Loss: 4.757229328155518
Step: 876, Loss: 4.025431156158447
Step: 877, Loss: 3.5274064540863037
Step: 878, Loss: 11.221061706542969
Step: 879, Loss: 6.845735549926758
Step: 880, Loss: 13.187493324279785
Step: 881, Loss: 14.42900276184082
Step: 882, Loss: 8.449718475341797
Step: 883, Loss: 5.800599575042725
Step: 884, Loss: 7.650117874145508
Step: 885, Loss: 10.85667610168457
Step: 886, Loss: 10.096443176269531
Step: 887, Loss: 14.28776741027832
Step: 888, Loss: 7.4695210456848145
Step: 889, Loss: 4.3376665115356445
Step: 890, Loss: 8.203120231628418
Step: 891, Loss: 7.728776931762695
Step: 892, Loss: 5.820361614227295
Step: 893, Loss: 2.733186721801758
Step: 894, Loss: 7.89648962020874
Step: 895, Loss: 3.3915889263153076
Step: 896, Loss: 7.262079238891602
Step: 897, Loss: 1.018323302268982
Step: 898, Loss: 2.368819236755371
Step: 899, Loss: 3.1767542362213135
Step: 900, Loss: 5.820798397064209
Step: 901, Loss: 11.13803482055664
Step: 902, Loss: 5.871169090270996
Step: 903, Loss: 2.4822165966033936
Step: 904, Loss: 4.188076496124268
Step: 905, Loss: 5.929511547088623
Step: 906, Loss: 6.141965389251709
Step: 907, Loss: 6.817450046539307
Step: 908, Loss: 3.818406105041504
Step: 909, Loss: 13.548128128051758
Step: 910, Loss: 19.244834899902344
Step: 911, Loss: 8.888050079345703
Step: 912, Loss: 3.9498634338378906
Step: 913, Loss: 7.404534816741943
Step: 914, Loss: 4.764758110046387
Step: 915, Loss: 3.417625904083252
Step: 916, Loss: 4.12221097946167
Step: 917, Loss: 3.1817626953125
Step: 918, Loss: 1.8712332248687744
Step: 919, Loss: 5.341921329498291
Output File: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-20/001_Oct-20-2024_11:14_AM/training_loss_curve.png
Training loss curve saved to /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/HHMAFM/2024-10-20/001_Oct-20-2024_11:14_AM/training_loss_curve.png
Total Completion Time: 67.50 minutes. (1.12 hours) 
