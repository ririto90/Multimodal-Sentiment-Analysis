> training arguments:
>>> rand_seed: 8
>>> model_name: mmfusion
>>> dataset: mvsa-mts-100
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7fc7b17c67a0>
>>> learning_rate: 0.001
>>> dropout_rate: 0.5
>>> num_epoch: 10
>>> batch_size: 10
>>> log_step: 1
>>> max_seq_len: 64
>>> polarities_dim: 3
>>> clip_grad: 5.0
>>> path_image: ./Datasets/MVSA-MTS/images-indexed
>>> crop_size: 224
>>> roberta_text_feature_dim: 768
>>> roberta_topic_feature_dim: 50
>>> resnet_feature_dim: 2048
>>> densenet_feature_dim: 1024
>>> common_dim: 512
>>> num_classes: 2
>>> model_class: <class 'models.mmfusion.MMFUSION'>
Preparing mvsa-mts-100 dataset...
--------------Datasets/MVSA-MTS/mvsa-mts-100/train.tsv---------------
The number of problematic samples: 5
--------------Datasets/MVSA-MTS/mvsa-mts-100/val.tsv---------------
The number of problematic samples: 1
--------------Datasets/MVSA-MTS/mvsa-mts-100/test.tsv---------------
The number of problematic samples: 1
Total Training Samples: 100
Number of Training Samples: 60
Number of Development Samples: 20
Number of Test Samples: 20
Number of unique sentiment classes: 3
building model
n_trainable_params: 1999875, n_nontrainable_params: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
roberta_text_features shape before projection: torch.Size([10, 768])
roberta_topic_features shape before projection: torch.Size([10, 768])
resnet_features shape before projection: torch.Size([10, 1000])
densenet_features shape before projection: torch.Size([10, 1000])
