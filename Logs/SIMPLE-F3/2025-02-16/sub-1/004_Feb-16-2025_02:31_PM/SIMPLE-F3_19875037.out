SIMPLE-F3_multiattfusion_mvsa-mts-v3_lr0.00005_dr0.1
SLURM Job ID: 19875037
Number of GPUs available: 1
Python PATH: ['/home/rgg2706/Multimodal-Sentiment-Analysis/Models/SIMPLE-F3/src', '/home/rgg2706/Multimodal-Sentiment-Analysis', '/Models/SIMPLE-F3/src', '/.autofs/tools/spack/var/spack/environments/default-nlp-x86_64-24072401/.spack-env/._view/wtxwc3mlkmzy7fbaxlum2674jarpitc2/lib/python311.zip', '/.autofs/tools/spack/var/spack/environments/default-nlp-x86_64-24072401/.spack-env/._view/wtxwc3mlkmzy7fbaxlum2674jarpitc2/lib/python3.11', '/.autofs/tools/spack/var/spack/environments/default-nlp-x86_64-24072401/.spack-env/._view/wtxwc3mlkmzy7fbaxlum2674jarpitc2/lib/python3.11/lib-dynload', '/.autofs/tools/spack/var/spack/environments/default-nlp-x86_64-24072401/.spack-env/._view/wtxwc3mlkmzy7fbaxlum2674jarpitc2/lib/python3.11/site-packages']
Logs directory: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/SIMPLE-F3/2025-02-16/sub-1/004_Feb-16-2025_02:31_PM
> training arguments:
>>> rand_seed: 8
>>> model_fusion: multiattfusion
>>> dataset: mvsa-mts-v3
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f6fec3c9580>
>>> learning_rate: 5e-05
>>> dropout_rate: 0.1
>>> weight_decay: 0.0
>>> num_layers: 3
>>> num_epoch: 25
>>> batch_size: 128
>>> log_step: 60
>>> max_seq_len: 120
>>> polarities_dim: 3
>>> clip_grad: 5.0
>>> path_image: ./images
>>> crop_size: 224
>>> n_head: 8
>>> hidden_dim: 768
>>> num_classes: 3
>>> log_dir: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/SIMPLE-F3/2025-02-16/sub-1/004_Feb-16-2025_02:31_PM
>>> counter: 0
>>> model_class: <class 'models.multiattfusion.MultiAttFusion'>
Loading dataset 'mvsa-mts-v3':
  Train path: Datasets/MVSA-MTS/mvsa-mts-v3/train.tsv
  Validation path: Datasets/MVSA-MTS/mvsa-mts-v3/val.tsv
  Test path: Datasets//MVSA-MTS/mvsa-mts-v3/test.tsv
-------------- Loading Datasets/MVSA-MTS/mvsa-mts-v3/train.tsv ---------------
[DEBUG] index: 706
[DEBUG] raw_text: PC Party, #Youth, #Education,Opportunity,#RenewableResources, Proudly #Canada's PCs #elxn42 http://t.co/NSwTddCHS8
[DEBUG] text_length: 9
[DEBUG] polarity: 2
[DEBUG] first 10 input_ids: [101, 7473, 2283, 1010, 1001, 3360, 1010, 1001, 2495, 1010]
---
[DEBUG] index: 2699
[DEBUG] raw_text: Running through the 6 wit my woes #ComeTogether #BlueJays #inthe6
[DEBUG] text_length: 10
[DEBUG] polarity: 1
[DEBUG] first 10 input_ids: [101, 2770, 2083, 1996, 1020, 15966, 2026, 24185, 2229, 1001]
---
[DEBUG] index: 15657
[DEBUG] raw_text: #TruckTuesday | | support@innovativeautoworx.com | 403.242.2767 | #Trucks #YYC #Calgary | http://t.co/ruwEqCd3LT
[DEBUG] text_length: 12
[DEBUG] polarity: 0
[DEBUG] first 10 input_ids: [101, 1001, 4744, 8525, 2229, 10259, 1064, 1064, 2490, 1030]
---
[DEBUG] index: 13219
[DEBUG] raw_text: I dont even care how ridiculous this looks #OTRAToronto is officially tomorrow and I am more than ready @onedirection
[DEBUG] text_length: 19
[DEBUG] polarity: 0
[DEBUG] first 10 input_ids: [101, 1045, 2123, 2102, 2130, 2729, 2129, 9951, 2023, 3504]
---
[DEBUG] index: 12053
[DEBUG] raw_text: #Automotive alert: Manufacturing Controls... | Nexteer Automotive | #Saginaw, MI #Auto http://t.co/En5uQ7JZDL
[DEBUG] text_length: 12
[DEBUG] polarity: 2
[DEBUG] first 10 input_ids: [101, 1001, 12945, 9499, 1024, 5814, 7711, 1012, 1012, 1012]
---
Time taken to load Datasets/MVSA-MTS/mvsa-mts-v3/train.tsv: 325.59 seconds (5.43 minutes)
Train classes: [0, 1, 2], count=3
[DEBUG] Train label distribution:
{0: 3522, 1: 3468, 2: 6631}
-------------- Loading Datasets/MVSA-MTS/mvsa-mts-v3/val.tsv ---------------
[DEBUG] index: 18681
[DEBUG] raw_text: ***Steven thinking about the life he just left behind with his beloved, Sam. Should he have stayed?...to be continued
[DEBUG] text_length: 19
[DEBUG] polarity: 2
[DEBUG] first 10 input_ids: [101, 1008, 1008, 1008, 7112, 3241, 2055, 1996, 2166, 2002]
---
[DEBUG] index: 16242
[DEBUG] raw_text: Thanks for an amazing summer #yyc,53 organizations engaged youth in 350 projects to contribute 20000 volunteer hours!
[DEBUG] text_length: 17
[DEBUG] polarity: 2
[DEBUG] first 10 input_ids: [101, 4283, 2005, 2019, 6429, 2621, 1001, 1061, 2100, 2278]
---
[DEBUG] index: 9628
[DEBUG] raw_text: HSR fares go up on Tuesday. Tickets (new issue) are $2.15. Don't be overcharged! #HamOnt #HSR https://t.co/zBxyTmcy1o
[DEBUG] text_length: 17
[DEBUG] polarity: 1
[DEBUG] first 10 input_ids: [101, 26236, 2099, 27092, 2175, 2039, 2006, 9857, 1012, 9735]
---
[DEBUG] index: 6350
[DEBUG] raw_text: @Calum5SOS just saw this on my Instagram feed and instantly thought of you #JetBlackHeart #ShesKindaHotVMA
[DEBUG] text_length: 15
[DEBUG] polarity: 0
[DEBUG] first 10 input_ids: [101, 1030, 10250, 2819, 2629, 17063, 2074, 2387, 2023, 2006]
---
[DEBUG] index: 17705
[DEBUG] raw_text: #selfiefornash @Nashgrier You've helped me get through the rough times Nash. I love you ????????
[DEBUG] text_length: 15
[DEBUG] polarity: 1
[DEBUG] first 10 input_ids: [101, 1001, 2969, 2666, 29278, 11649, 2232, 1030, 10594, 16523]
---
Time taken to load Datasets/MVSA-MTS/mvsa-mts-v3/val.tsv: 40.86 seconds (0.68 minutes)
Val classes: [0, 1, 2], count=3
[DEBUG] Val label distribution:
{0: 436, 1: 442, 2: 825}
[DEBUG] Computed class_weights = [1.2891349792480469, 1.3092080354690552, 0.6847132444381714]
-------------- Loading Datasets//MVSA-MTS/mvsa-mts-v3/test.tsv ---------------
[DEBUG] index: 14949
[DEBUG] raw_text: Candid shot at #Montreal @FetishWeekend. #smile latex: @HWD_Latex #iLoveBiancaMondays http://t.co/eDaoHprlRP
[DEBUG] text_length: 10
[DEBUG] polarity: 2
[DEBUG] first 10 input_ids: [101, 27467, 2094, 2915, 2012, 1001, 5548, 1030, 10768, 24788]
---
[DEBUG] index: 9542
[DEBUG] raw_text: #hamont stop by and help out Lynwood Hall raise some founds with a car wash! #lynwoodhallcarwash #machealth
[DEBUG] text_length: 17
[DEBUG] polarity: 0
[DEBUG] first 10 input_ids: [101, 1001, 10654, 12162, 2644, 2011, 1998, 2393, 2041, 1048]
---
[DEBUG] index: 6309
[DEBUG] raw_text: EVEN MY NEICE WANTS TO VOTE #ShesKindaHotVMA
[DEBUG] text_length: 7
[DEBUG] polarity: 2
[DEBUG] first 10 input_ids: [101, 2130, 2026, 11265, 6610, 4122, 2000, 3789, 1001, 2016]
---
[DEBUG] index: 17974
[DEBUG] raw_text: Looks like I'm going alone ????
[DEBUG] text_length: 6
[DEBUG] polarity: 2
[DEBUG] first 10 input_ids: [101, 3504, 2066, 1045, 1005, 1049, 2183, 2894, 1029, 1029]
---
[DEBUG] index: 14882
[DEBUG] raw_text: Here it comes!! @comedynest Sept 24-26 Call 514-932-6378 for reservations! #derekseguin #comedy #montreal #fun
[DEBUG] text_length: 14
[DEBUG] polarity: 2
[DEBUG] first 10 input_ids: [101, 2182, 2009, 3310, 999, 999, 1030, 4038, 5267, 2102]
---
Time taken to load Datasets//MVSA-MTS/mvsa-mts-v3/test.tsv: 40.96 seconds (0.68 minutes)
Test classes: [0, 1, 2], count=3
[DEBUG] Test label distribution:
{0: 450, 1: 431, 2: 822}
[DEBUG] 95th percentile sequence length across all splits: 20.00
Total Training Samples: 17027
Number of Training Samples: 13621
Number of Validation Samples: 1703
Number of Test Samples: 1703
Number of unique sentiment classes: 3
Building model
1
n_trainable_params: 54024195, n_nontrainable_params: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
[DEBUG] Sample predictions in evaluate:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')
[DEBUG] outputs.shape: torch.Size([128, 3])
[DEBUG] Sample of raw logits (first 5):
tensor([[-0.0404,  0.0057, -0.0393],
        [-0.0487,  0.0139, -0.0377],
        [-0.0292, -0.0088, -0.0306],
        [-0.0334,  0.0033, -0.0391],
        [-0.0324, -0.0055, -0.0253]], device='cuda:0',
       grad_fn=<SliceBackward0>)
[DEBUG] Sample of predicted probabilities (first 5):
tensor([[0.3280, 0.3435, 0.3284],
        [0.3251, 0.3461, 0.3287],
        [0.3312, 0.3380, 0.3307],
        [0.3298, 0.3422, 0.3280],
        [0.3296, 0.3385, 0.3319]], device='cuda:0', grad_fn=<SliceBackward0>)
Batch 0 completed in 2.11 seconds (0.04 minutes)
New best val_f1: 0.217563 (previous best: 0.000000)
loss: 1.102292, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 60 completed in 0.82 seconds (0.01 minutes)
New best val_f1: 0.357730 (previous best: 0.217563)
loss: 1.052659, val_acc: 49.62% (0.496183), val_f1: 35.77% (0.357730), test_acc: 50.26% (0.502642), test_f1: 36.31% (0.363063)
Epoch 0 completed in 116.27 seconds (1.94 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.991633, val_acc: 51.03% (0.510276), val_f1: 35.20% (0.352026), test_acc: 49.91% (0.499119), test_f1: 34.73% (0.347300)
Batch 60 completed in 0.83 seconds (0.01 minutes)
New best val_f1: 0.372045 (previous best: 0.357730)
loss: 1.075233, val_acc: 49.56% (0.495596), val_f1: 37.20% (0.372045), test_acc: 49.50% (0.495009), test_f1: 36.94% (0.369356)
Epoch 1 completed in 116.33 seconds (1.94 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
Batch 0 completed in 0.83 seconds (0.01 minutes)
New best val_f1: 0.374622 (previous best: 0.372045)
loss: 0.982495, val_acc: 50.73% (0.507340), val_f1: 37.46% (0.374622), test_acc: 50.26% (0.502642), test_f1: 36.91% (0.369140)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.974680, val_acc: 51.32% (0.513212), val_f1: 36.31% (0.363118), test_acc: 50.91% (0.509102), test_f1: 35.77% (0.357654)
Epoch 2 completed in 117.35 seconds (1.96 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 1.066944, val_acc: 50.85% (0.508514), val_f1: 37.28% (0.372751), test_acc: 50.62% (0.506166), test_f1: 36.51% (0.365058)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.992732, val_acc: 50.44% (0.504404), val_f1: 35.45% (0.354550), test_acc: 51.97% (0.519671), test_f1: 36.89% (0.368908)
Epoch 3 completed in 117.57 seconds (1.96 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.970027, val_acc: 50.03% (0.500294), val_f1: 33.30% (0.333001), test_acc: 51.03% (0.510276), test_f1: 34.39% (0.343852)
Batch 60 completed in 0.83 seconds (0.01 minutes)
New best val_f1: 0.395657 (previous best: 0.374622)
loss: 0.962975, val_acc: 51.03% (0.510276), val_f1: 39.57% (0.395657), test_acc: 49.03% (0.490311), test_f1: 37.30% (0.373037)
Epoch 4 completed in 117.52 seconds (1.96 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.943091, val_acc: 51.44% (0.514386), val_f1: 37.57% (0.375667), test_acc: 51.85% (0.518497), test_f1: 37.65% (0.376455)
Batch 60 completed in 0.82 seconds (0.01 minutes)
New best val_f1: 0.401196 (previous best: 0.395657)
loss: 0.877028, val_acc: 51.50% (0.514974), val_f1: 40.12% (0.401196), test_acc: 51.73% (0.517322), test_f1: 39.42% (0.394202)
Epoch 5 completed in 117.80 seconds (1.96 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
Batch 0 completed in 0.83 seconds (0.01 minutes)
New best val_f1: 0.421267 (previous best: 0.401196)
loss: 0.943070, val_acc: 51.20% (0.512038), val_f1: 42.13% (0.421267), test_acc: 50.68% (0.506753), test_f1: 40.45% (0.404462)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.880690, val_acc: 51.09% (0.510863), val_f1: 37.66% (0.376561), test_acc: 50.73% (0.507340), test_f1: 36.58% (0.365833)
Epoch 6 completed in 117.63 seconds (1.96 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 7
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.910679, val_acc: 51.50% (0.514974), val_f1: 41.27% (0.412688), test_acc: 49.97% (0.499706), test_f1: 38.96% (0.389560)
Batch 60 completed in 0.83 seconds (0.01 minutes)
New best val_f1: 0.436165 (previous best: 0.421267)
loss: 0.872394, val_acc: 51.44% (0.514386), val_f1: 43.62% (0.436165), test_acc: 48.33% (0.483265), test_f1: 39.06% (0.390620)
Epoch 7 completed in 117.61 seconds (1.96 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 8
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.878424, val_acc: 51.26% (0.512625), val_f1: 41.17% (0.411729), test_acc: 51.38% (0.513799), test_f1: 40.35% (0.403510)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.830961, val_acc: 50.21% (0.502055), val_f1: 41.15% (0.411458), test_acc: 49.32% (0.493247), test_f1: 39.23% (0.392324)
Epoch 8 completed in 117.52 seconds (1.96 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 9
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.754419, val_acc: 50.91% (0.509102), val_f1: 43.26% (0.432570), test_acc: 50.85% (0.508514), test_f1: 42.27% (0.422743)
Batch 60 completed in 0.83 seconds (0.01 minutes)
New best val_f1: 0.437966 (previous best: 0.436165)
loss: 0.801227, val_acc: 48.97% (0.489724), val_f1: 43.80% (0.437966), test_acc: 47.80% (0.477980), test_f1: 41.93% (0.419313)
Epoch 9 completed in 117.90 seconds (1.96 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 10
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.789234, val_acc: 48.97% (0.489724), val_f1: 42.51% (0.425112), test_acc: 49.91% (0.499119), test_f1: 42.29% (0.422882)
Batch 60 completed in 0.83 seconds (0.01 minutes)
New best val_f1: 0.438926 (previous best: 0.437966)
loss: 0.766752, val_acc: 48.50% (0.485026), val_f1: 43.89% (0.438926), test_acc: 47.21% (0.472108), test_f1: 42.31% (0.423118)
Epoch 10 completed in 117.48 seconds (1.96 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 11
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.753935, val_acc: 49.32% (0.493247), val_f1: 43.74% (0.437363), test_acc: 48.56% (0.485614), test_f1: 42.26% (0.422624)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.584347, val_acc: 46.39% (0.463887), val_f1: 41.46% (0.414613), test_acc: 47.45% (0.474457), test_f1: 40.60% (0.405970)
Epoch 11 completed in 117.55 seconds (1.96 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 12
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.550764, val_acc: 47.50% (0.475044), val_f1: 41.84% (0.418389), test_acc: 48.09% (0.480916), test_f1: 42.04% (0.420380)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.500993, val_acc: 46.98% (0.469759), val_f1: 43.19% (0.431853), test_acc: 46.68% (0.466823), test_f1: 41.72% (0.417210)
Epoch 12 completed in 115.50 seconds (1.93 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 13
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.551627, val_acc: 45.57% (0.455666), val_f1: 41.68% (0.416786), test_acc: 45.92% (0.459190), test_f1: 40.99% (0.409854)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.389198, val_acc: 45.16% (0.451556), val_f1: 42.27% (0.422711), test_acc: 45.21% (0.452143), test_f1: 41.83% (0.418284)
Epoch 13 completed in 115.26 seconds (1.92 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 14
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.376511, val_acc: 45.74% (0.457428), val_f1: 40.24% (0.402357), test_acc: 47.45% (0.474457), test_f1: 41.86% (0.418628)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.316621, val_acc: 47.21% (0.472108), val_f1: 42.20% (0.421973), test_acc: 47.68% (0.476806), test_f1: 41.98% (0.419819)
Epoch 14 completed in 115.42 seconds (1.92 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 15
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.289616, val_acc: 45.04% (0.450382), val_f1: 41.33% (0.413267), test_acc: 45.57% (0.455666), test_f1: 40.76% (0.407560)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.328963, val_acc: 44.63% (0.446271), val_f1: 41.11% (0.411128), test_acc: 46.98% (0.469759), test_f1: 43.06% (0.430616)
Epoch 15 completed in 115.05 seconds (1.92 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 16
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.416074, val_acc: 47.39% (0.473870), val_f1: 40.06% (0.400623), test_acc: 48.62% (0.486201), test_f1: 40.88% (0.408759)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.197698, val_acc: 43.75% (0.437463), val_f1: 39.78% (0.397783), test_acc: 46.62% (0.466236), test_f1: 42.06% (0.420582)
Epoch 16 completed in 115.10 seconds (1.92 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 17
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.214100, val_acc: 43.63% (0.436289), val_f1: 40.84% (0.408410), test_acc: 46.51% (0.465062), test_f1: 43.46% (0.434574)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.205470, val_acc: 46.15% (0.461538), val_f1: 41.98% (0.419837), test_acc: 47.33% (0.473282), test_f1: 42.76% (0.427561)
Epoch 17 completed in 115.12 seconds (1.92 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 18
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.300035, val_acc: 45.92% (0.459190), val_f1: 40.46% (0.404552), test_acc: 46.68% (0.466823), test_f1: 40.78% (0.407832)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.146691, val_acc: 46.56% (0.465649), val_f1: 41.77% (0.417680), test_acc: 46.98% (0.469759), test_f1: 41.66% (0.416555)
Epoch 18 completed in 115.05 seconds (1.92 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 19
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.248378, val_acc: 44.69% (0.446858), val_f1: 39.49% (0.394926), test_acc: 45.80% (0.458015), test_f1: 40.02% (0.400165)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.127491, val_acc: 43.69% (0.436876), val_f1: 40.16% (0.401627), test_acc: 45.33% (0.453318), test_f1: 40.78% (0.407789)
Epoch 19 completed in 115.01 seconds (1.92 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 20
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.261527, val_acc: 43.92% (0.439225), val_f1: 40.64% (0.406389), test_acc: 46.45% (0.464474), test_f1: 42.65% (0.426461)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.125517, val_acc: 45.80% (0.458015), val_f1: 41.16% (0.411559), test_acc: 45.63% (0.456254), test_f1: 40.17% (0.401719)
Epoch 20 completed in 114.83 seconds (1.91 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 21
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.218287, val_acc: 46.04% (0.460364), val_f1: 41.55% (0.415455), test_acc: 46.15% (0.461538), test_f1: 41.22% (0.412232)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.112548, val_acc: 45.45% (0.454492), val_f1: 41.94% (0.419411), test_acc: 45.39% (0.453905), test_f1: 41.44% (0.414359)
Epoch 21 completed in 115.04 seconds (1.92 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 22
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.191416, val_acc: 45.45% (0.454492), val_f1: 40.41% (0.404093), test_acc: 47.03% (0.470346), test_f1: 40.79% (0.407927)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.194381, val_acc: 45.39% (0.453905), val_f1: 41.02% (0.410214), test_acc: 46.33% (0.463300), test_f1: 41.76% (0.417567)
Epoch 22 completed in 114.59 seconds (1.91 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 23
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.360468, val_acc: 44.27% (0.442748), val_f1: 39.48% (0.394790), test_acc: 46.15% (0.461538), test_f1: 40.67% (0.406663)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.141446, val_acc: 43.04% (0.430417), val_f1: 39.97% (0.399658), test_acc: 44.10% (0.440986), test_f1: 40.46% (0.404618)
Epoch 23 completed in 114.60 seconds (1.91 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 24
[DEBUG] Sample predictions in evaluate:  tensor([2, 2, 1, 2, 1, 2, 2, 2, 1, 1], device='cuda:0')
Batch 0 completed in 0.83 seconds (0.01 minutes)
loss: 0.145611, val_acc: 45.92% (0.459190), val_f1: 41.66% (0.416586), test_acc: 44.69% (0.446858), test_f1: 40.20% (0.401988)
Batch 60 completed in 0.83 seconds (0.01 minutes)
loss: 0.092752, val_acc: 44.10% (0.440986), val_f1: 39.97% (0.399721), test_acc: 44.69% (0.446858), test_f1: 39.71% (0.397128)
Epoch 24 completed in 114.83 seconds (1.91 minutes)
RESULT: Max Val F1: 0.438926, Max Test F1: 0.423118
Training complete. Generating confusion matrix on the test set.
Confusion matrix saved to /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/SIMPLE-F3/2025-02-16/sub-1/004_Feb-16-2025_02:31_PM/confusion_matrix.png
Reading TensorBoard loss at each epoch:
Available tags: {'images': [], 'audio': [], 'histograms': [], 'scalars': ['Loss/train_batch', 'Loss/val_log_step', 'Loss/train_epoch', 'Loss/val_epoch'], 'distributions': [], 'tensors': [], 'graph': False, 'meta_graph': False, 'run_metadata': []}
Output File: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/SIMPLE-F3/2025-02-16/sub-1/004_Feb-16-2025_02:31_PM/trainval_loss_curves.png
Training and validation loss curves saved to /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/SIMPLE-F3/2025-02-16/sub-1/004_Feb-16-2025_02:31_PM/trainval_loss_curves.png
Total Completion Time: 55.55 minutes. (0.93 hours) 
