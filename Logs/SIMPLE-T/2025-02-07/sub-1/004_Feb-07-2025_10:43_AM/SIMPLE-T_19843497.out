SLURM Job ID: 19843497
Number of GPUs available: 1
Python PATH: ['/home/rgg2706/Multimodal-Sentiment-Analysis/Models/SIMPLE-T/src', '/home/rgg2706/Multimodal-Sentiment-Analysis', '/Models/SIMPLE-T/src', '/.autofs/tools/spack/var/spack/environments/default-nlp-x86_64-24072401/.spack-env/._view/wtxwc3mlkmzy7fbaxlum2674jarpitc2/lib/python311.zip', '/.autofs/tools/spack/var/spack/environments/default-nlp-x86_64-24072401/.spack-env/._view/wtxwc3mlkmzy7fbaxlum2674jarpitc2/lib/python3.11', '/.autofs/tools/spack/var/spack/environments/default-nlp-x86_64-24072401/.spack-env/._view/wtxwc3mlkmzy7fbaxlum2674jarpitc2/lib/python3.11/lib-dynload', '/.autofs/tools/spack/var/spack/environments/default-nlp-x86_64-24072401/.spack-env/._view/wtxwc3mlkmzy7fbaxlum2674jarpitc2/lib/python3.11/site-packages']
Logs directory: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/SIMPLE-T/2025-02-07/sub-1/004_Feb-07-2025_10:43_AM
> training arguments:
>>> rand_seed: 8
>>> model_fusion: simpletext
>>> dataset: mvsa-mts-v3
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f5270dc9440>
>>> learning_rate: 0.0005
>>> dropout_rate: 0.5
>>> weight_decay: 0.0
>>> num_layers: 3
>>> num_epoch: 20
>>> batch_size: 64
>>> log_step: 60
>>> max_seq_len: 64
>>> polarities_dim: 3
>>> clip_grad: 5.0
>>> path_image: ./images
>>> crop_size: 224
>>> n_head: 8
>>> hidden_dim: 256
>>> num_classes: 3
>>> log_dir: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/SIMPLE-T/2025-02-07/sub-1/004_Feb-07-2025_10:43_AM
>>> counter: 0
>>> model_class: <class 'models.simpletext.SimpleText'>
Loading dataset 'mvsa-mts-v3':
  Train path: Datasets//MVSA-MTS/mvsa-mts-v3/train.tsv
Validation path: Datasets//MVSA-MTS/mvsa-mts-v3/val.tsv
  Test path: Datasets//MVSA-MTS/mvsa-mts-v3/test.tsv
loading word vectors...
building embedding_matrix: 200_glove_embedding_matrix.dat
-------------- Loading Datasets//MVSA-MTS/mvsa-mts-v3/train.tsv ---------------
[DEBUG] raw_text: pc party, #youth, #education,opportunity,#renewableresources, proudly #canada's pcs #elxn42 http://t.co/nswtddchs8
[DEBUG] text_indices: [ 2  3  4  5  6  7  8  9 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
[DEBUG] polarity: 2
[DEBUG] raw_text: running through the 6 wit my woes #cometogether #bluejays #inthe6
[DEBUG] text_indices: [11 12 13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
[DEBUG] polarity: 1
[DEBUG] raw_text: #trucktuesday | | support@innovativeautoworx.com | 403.242.2767 | #trucks #yyc #calgary | http://t.co/ruweqcd3lt
[DEBUG] text_indices: [21 22 22 23 22 24 22 25 26 27 22 28  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
[DEBUG] polarity: 0
[DEBUG] raw_text: i dont even care how ridiculous this looks #otratoronto is officially tomorrow and i am more than ready @onedirection
[DEBUG] text_indices: [29 30 31 32 33 34 35 36 37 38 39 40 41 29 42 43 44 45 46  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
[DEBUG] polarity: 0
Time taken to load Datasets//MVSA-MTS/mvsa-mts-v3/train.tsv: 0.48 seconds(0.01 minutes)
Train classes: [0, 1, 2], count=3
[DEBUG] First 5 samples from train_data:
pc party, #youth, #education,opportunity,#renewableresources, proudly #canada's pcs #elxn42 http://t.co/nswtddchs8 2
running through the 6 wit my woes #cometogether #bluejays #inthe6 1
#trucktuesday | | support@innovativeautoworx.com | 403.242.2767 | #trucks #yyc #calgary | http://t.co/ruweqcd3lt 0
i dont even care how ridiculous this looks #otratoronto is officially tomorrow and i am more than ready @onedirection 0
#automotive alert: manufacturing controls... | nexteer automotive | #saginaw, mi #auto http://t.co/en5uq7jzdl 2
[DEBUG] Train label distribution:
{0: 3522, 1: 3468, 2: 6631}
-------------- Loading Datasets//MVSA-MTS/mvsa-mts-v3/val.tsv ---------------
[DEBUG] raw_text: ***steven thinking about the life he just left behind with his beloved, sam. should he have stayed?...to be continued
[DEBUG] text_indices: [40162  2690  1193    13  1285   884   496  1983   981   213   324 40163
 26627   842   884   616 40164    72 34059     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0]
[DEBUG] polarity: 2
[DEBUG] raw_text: thanks for an amazing summer #yyc,53 organizations engaged youth in 350 projects to contribute 20000 volunteer hours!
[DEBUG] text_indices: [  848    59   741   117   985 40165 22299 32591  3840    63 32476  5997
   130 40166 40167 10226 40168     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0]
[DEBUG] polarity: 2
[DEBUG] raw_text: hsr fares go up on tuesday. tickets (new issue) are $2.15. don't be overcharged! #hamont #hsr https://t.co/zbxytmcy1o
[DEBUG] text_indices: [19936 33376   593   292   100 18529   787 40169 40170   866 40171   725
    72 40172   262  6707 33378     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0]
[DEBUG] polarity: 1
[DEBUG] raw_text: @calum5sos just saw this on my instagram feed and instantly thought of you #jetblackheart #sheskindahotvma
[DEBUG] text_indices: [ 3533   496  2315    35   100    16  6963  6450    41 38093   554   145
   456  2617   329     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0]
[DEBUG] polarity: 0
Time taken to load Datasets//MVSA-MTS/mvsa-mts-v3/val.tsv: 0.06 seconds(0.00 minutes)
Val classes: [0, 1, 2], count=3
[DEBUG] First 5 samples from train_data:
***steven thinking about the life he just left behind with his beloved, sam. should he have stayed?...to be continued 2
thanks for an amazing summer #yyc,53 organizations engaged youth in 350 projects to contribute 20000 volunteer hours! 2
hsr fares go up on tuesday. tickets (new issue) are $2.15. don't be overcharged! #hamont #hsr https://t.co/zbxytmcy1o 1
@calum5sos just saw this on my instagram feed and instantly thought of you #jetblackheart #sheskindahotvma 0
#selfiefornash @nashgrier you've helped me get through the rough times nash. i love you ???????? 1
[DEBUG] Train label distribution:
{0: 3522, 1: 3468, 2: 6631}
-------------- Loading Datasets//MVSA-MTS/mvsa-mts-v3/test.tsv ---------------
[DEBUG] raw_text: candid shot at #montreal @fetishweekend. #smile latex: @hwd_latex #ilovebiancamondays http://t.co/edaohprlrp
[DEBUG] text_indices: [43624   433   109   350 43625 17603 43626 16153 43627 16135     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0]
[DEBUG] polarity: 2
[DEBUG] raw_text: #hamont stop by and help out lynwood hall raise some founds with a car wash! #lynwoodhallcarwash #machealth
[DEBUG] text_indices: [  262   567   357    41  2422    76 43628  1398  5034   125 43629   213
   206  8256 43630 43631 43632     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0]
[DEBUG] polarity: 0
[DEBUG] raw_text: even my neice wants to vote #sheskindahotvma
[DEBUG] text_indices: [   31    16 43633  6426   130  1160   329     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0]
[DEBUG] polarity: 2
[DEBUG] raw_text: looks like i'm going alone ????
[DEBUG] text_indices: [  36  203  205  542 3334  739    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0]
[DEBUG] polarity: 2
Time taken to load Datasets//MVSA-MTS/mvsa-mts-v3/test.tsv: 0.06 seconds(0.00 minutes)
Test classes: [0, 1, 2], count=3
[DEBUG] First 5 samples from train_data:
candid shot at #montreal @fetishweekend. #smile latex: @hwd_latex #ilovebiancamondays http://t.co/edaohprlrp 2
#hamont stop by and help out lynwood hall raise some founds with a car wash! #lynwoodhallcarwash #machealth 0
even my neice wants to vote #sheskindahotvma 2
looks like i'm going alone ???? 2
here it comes!! @comedynest sept 24-26 call 514-932-6378 for reservations! #derekseguin #comedy #montreal #fun 2
[DEBUG] Train label distribution:
{0: 3522, 1: 3468, 2: 6631}
Total Training Samples: 17027
Number of Training Samples: 13621
Number of Validation Samples: 1703
Number of Test Samples: 1703
Number of unique sentiment classes: 3
Building model
1
n_trainable_params: 394243, n_nontrainable_params: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
[DEBUG] text_indices.shape: torch.Size([64, 64])
[DEBUG] embedded_text.shape: torch.Size([64, 64, 200])
[DEBUG] lstm_output.shape: torch.Size([64, 64, 1536])
[DEBUG] h_n.shape: torch.Size([6, 64, 768])
[DEBUG] c_n.shape: torch.Size([6, 64, 768])
[DEBUG] text_features.shape: torch.Size([64, 1536])
[DEBUG] Sample predictions in evaluate:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')
[DEBUG] outputs.shape: torch.Size([64, 3])
[DEBUG] Sample of raw logits (first 5):
tensor([[ 0.0037, -0.0071, -0.0276],
        [ 0.0015, -0.0090, -0.0277],
        [ 0.0002, -0.0119, -0.0250],
        [ 0.0010, -0.0068, -0.0212],
        [-0.0009, -0.0146, -0.0240]], device='cuda:0',
       grad_fn=<SliceBackward0>)
[DEBUG] Sample of predicted probabilities (first 5):
tensor([[0.3380, 0.3344, 0.3276],
        [0.3377, 0.3342, 0.3280],
        [0.3375, 0.3334, 0.3291],
        [0.3367, 0.3341, 0.3293],
        [0.3374, 0.3328, 0.3297]], device='cuda:0', grad_fn=<SliceBackward0>)
Batch 0 completed in 0.40 seconds (0.01 minutes)
New best val_f1: 0.217563 (previous best: 0.000000)
loss: 1.104455, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 1.083638, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 1.101006, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 1.045646, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Epoch 0 completed in 6.45 seconds (0.11 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
Batch 0 completed in 0.02 seconds (0.00 minutes)
loss: 1.026329, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 0.982360, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 1.095383, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 1.057405, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Epoch 1 completed in 6.03 seconds (0.10 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
Batch 0 completed in 0.02 seconds (0.00 minutes)
loss: 1.043291, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 1.012779, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 1.011214, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 1.054967, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Epoch 2 completed in 6.04 seconds (0.10 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
Batch 0 completed in 0.02 seconds (0.00 minutes)
loss: 1.029762, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 0.948529, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 1.020805, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 1.083761, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Epoch 3 completed in 6.06 seconds (0.10 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
Batch 0 completed in 0.02 seconds (0.00 minutes)
loss: 1.056331, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 1.000070, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 1.063162, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 180 completed in 0.02 seconds (0.00 minutes)
New best val_f1: 0.220780 (previous best: 0.217563)
loss: 1.063324, val_acc: 48.56% (0.485614), val_f1: 22.08% (0.220780), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Epoch 4 completed in 6.06 seconds (0.10 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
Batch 0 completed in 0.02 seconds (0.00 minutes)
New best val_f1: 0.258543 (previous best: 0.220780)
loss: 0.992052, val_acc: 49.21% (0.492073), val_f1: 25.85% (0.258543), test_acc: 48.62% (0.486201), test_f1: 24.31% (0.243062)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 1.060478, val_acc: 49.03% (0.490311), val_f1: 25.44% (0.254417), test_acc: 48.68% (0.486788), test_f1: 24.33% (0.243295)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 1.032606, val_acc: 48.56% (0.485614), val_f1: 22.22% (0.222189), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 180 completed in 0.02 seconds (0.00 minutes)
New best val_f1: 0.284255 (previous best: 0.258543)
loss: 0.993766, val_acc: 49.50% (0.495009), val_f1: 28.43% (0.284255), test_acc: 48.85% (0.488550), test_f1: 27.00% (0.269951)
Epoch 5 completed in 6.20 seconds (0.10 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
Batch 0 completed in 0.02 seconds (0.00 minutes)
loss: 1.013974, val_acc: 49.44% (0.494422), val_f1: 26.61% (0.266081), test_acc: 48.85% (0.488550), test_f1: 25.19% (0.251867)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 1.004025, val_acc: 49.50% (0.495009), val_f1: 27.34% (0.273420), test_acc: 48.97% (0.489724), test_f1: 25.88% (0.258794)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 1.109785, val_acc: 49.44% (0.494422), val_f1: 28.05% (0.280510), test_acc: 48.62% (0.486201), test_f1: 26.13% (0.261258)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 0.973574, val_acc: 49.44% (0.494422), val_f1: 27.60% (0.276033), test_acc: 48.85% (0.488550), test_f1: 25.93% (0.259311)
Epoch 6 completed in 6.38 seconds (0.11 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 7
Batch 0 completed in 0.02 seconds (0.00 minutes)
loss: 1.037014, val_acc: 49.32% (0.493247), val_f1: 27.35% (0.273521), test_acc: 48.85% (0.488550), test_f1: 25.93% (0.259311)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 1.143894, val_acc: 49.27% (0.492660), val_f1: 26.42% (0.264210), test_acc: 48.91% (0.489137), test_f1: 25.32% (0.253205)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 0.994753, val_acc: 49.44% (0.494422), val_f1: 27.88% (0.278757), test_acc: 48.68% (0.486788), test_f1: 25.95% (0.259536)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 1.024601, val_acc: 49.32% (0.493247), val_f1: 28.17% (0.281668), test_acc: 48.85% (0.488550), test_f1: 26.90% (0.269040)
Epoch 7 completed in 6.20 seconds (0.10 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 8
Batch 0 completed in 0.02 seconds (0.00 minutes)
New best val_f1: 0.285780 (previous best: 0.284255)
loss: 0.959768, val_acc: 49.32% (0.493247), val_f1: 28.58% (0.285780), test_acc: 49.21% (0.492073), test_f1: 27.87% (0.278731)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 1.079737, val_acc: 49.32% (0.493247), val_f1: 27.72% (0.277186), test_acc: 48.85% (0.488550), test_f1: 26.04% (0.260354)
Batch 120 completed in 0.02 seconds (0.00 minutes)
New best val_f1: 0.299065 (previous best: 0.285780)
loss: 1.015877, val_acc: 49.56% (0.495596), val_f1: 29.91% (0.299065), test_acc: 49.38% (0.493834), test_f1: 29.79% (0.297942)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 0.996427, val_acc: 49.27% (0.492660), val_f1: 28.55% (0.285534), test_acc: 49.38% (0.493834), test_f1: 28.31% (0.283051)
Epoch 8 completed in 6.26 seconds (0.10 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 9
Batch 0 completed in 0.02 seconds (0.00 minutes)
loss: 1.004637, val_acc: 49.15% (0.491486), val_f1: 28.63% (0.286333), test_acc: 49.21% (0.492073), test_f1: 28.53% (0.285340)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 0.992651, val_acc: 49.15% (0.491486), val_f1: 29.74% (0.297445), test_acc: 49.15% (0.491486), test_f1: 30.06% (0.300627)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 1.073442, val_acc: 49.27% (0.492660), val_f1: 27.41% (0.274133), test_acc: 48.74% (0.487375), test_f1: 25.78% (0.257767)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 1.059758, val_acc: 49.50% (0.495009), val_f1: 29.54% (0.295362), test_acc: 49.38% (0.493834), test_f1: 29.45% (0.294512)
Epoch 9 completed in 6.71 seconds (0.11 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 10
Batch 0 completed in 0.02 seconds (0.00 minutes)
New best val_f1: 0.302267 (previous best: 0.299065)
loss: 1.023118, val_acc: 49.74% (0.497358), val_f1: 30.23% (0.302267), test_acc: 49.56% (0.495596), test_f1: 30.16% (0.301614)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 0.938119, val_acc: 49.68% (0.496770), val_f1: 30.05% (0.300490), test_acc: 49.27% (0.492660), test_f1: 29.72% (0.297235)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 0.971407, val_acc: 49.38% (0.493834), val_f1: 26.79% (0.267858), test_acc: 48.91% (0.489137), test_f1: 25.43% (0.254300)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 1.044599, val_acc: 49.50% (0.495009), val_f1: 27.14% (0.271439), test_acc: 48.85% (0.488550), test_f1: 25.62% (0.256179)
Epoch 10 completed in 6.24 seconds (0.10 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 11
Batch 0 completed in 0.02 seconds (0.00 minutes)
New best val_f1: 0.316703 (previous best: 0.302267)
loss: 1.013402, val_acc: 48.85% (0.488550), val_f1: 31.67% (0.316703), test_acc: 49.03% (0.490311), test_f1: 31.74% (0.317363)
Batch 60 completed in 0.02 seconds (0.00 minutes)
New best val_f1: 0.326599 (previous best: 0.316703)
loss: 0.981303, val_acc: 47.86% (0.478567), val_f1: 32.66% (0.326599), test_acc: 48.91% (0.489137), test_f1: 33.59% (0.335924)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 1.050512, val_acc: 49.27% (0.492660), val_f1: 31.02% (0.310177), test_acc: 49.03% (0.490311), test_f1: 30.77% (0.307688)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 1.021316, val_acc: 49.44% (0.494422), val_f1: 29.41% (0.294077), test_acc: 49.62% (0.496183), test_f1: 29.59% (0.295885)
Epoch 11 completed in 6.56 seconds (0.11 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 12
Batch 0 completed in 0.02 seconds (0.00 minutes)
New best val_f1: 0.326953 (previous best: 0.326599)
loss: 1.011840, val_acc: 48.56% (0.485614), val_f1: 32.70% (0.326953), test_acc: 49.15% (0.491486), test_f1: 33.36% (0.333609)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 0.921348, val_acc: 49.32% (0.493247), val_f1: 27.15% (0.271522), test_acc: 48.80% (0.487962), test_f1: 25.70% (0.257012)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 1.015665, val_acc: 49.32% (0.493247), val_f1: 28.33% (0.283336), test_acc: 48.97% (0.489724), test_f1: 27.58% (0.275830)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 0.896996, val_acc: 49.15% (0.491486), val_f1: 25.83% (0.258274), test_acc: 48.68% (0.486788), test_f1: 24.44% (0.244409)
Epoch 12 completed in 6.26 seconds (0.10 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 13
Batch 0 completed in 0.02 seconds (0.00 minutes)
loss: 0.985362, val_acc: 48.91% (0.489137), val_f1: 30.97% (0.309747), test_acc: 48.97% (0.489724), test_f1: 31.00% (0.309975)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 1.017256, val_acc: 49.68% (0.496770), val_f1: 29.49% (0.294937), test_acc: 49.68% (0.496770), test_f1: 29.33% (0.293277)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 1.071691, val_acc: 49.38% (0.493834), val_f1: 28.70% (0.287029), test_acc: 49.27% (0.492660), test_f1: 28.41% (0.284064)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 0.995063, val_acc: 49.15% (0.491486), val_f1: 31.17% (0.311735), test_acc: 48.97% (0.489724), test_f1: 30.96% (0.309631)
Epoch 13 completed in 6.50 seconds (0.11 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 14
Batch 0 completed in 0.02 seconds (0.00 minutes)
loss: 0.983546, val_acc: 49.15% (0.491486), val_f1: 26.97% (0.269660), test_acc: 48.80% (0.487962), test_f1: 26.11% (0.261079)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 0.960140, val_acc: 49.32% (0.493247), val_f1: 26.45% (0.264487), test_acc: 48.80% (0.487962), test_f1: 25.05% (0.250525)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 0.937491, val_acc: 49.03% (0.490311), val_f1: 31.00% (0.309955), test_acc: 49.09% (0.490898), test_f1: 30.98% (0.309835)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 0.955766, val_acc: 49.44% (0.494422), val_f1: 29.71% (0.297064), test_acc: 49.74% (0.497358), test_f1: 30.21% (0.302056)
Epoch 14 completed in 6.28 seconds (0.10 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 15
Batch 0 completed in 0.02 seconds (0.00 minutes)
loss: 0.990322, val_acc: 49.56% (0.495596), val_f1: 31.25% (0.312483), test_acc: 49.03% (0.490311), test_f1: 30.82% (0.308245)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 1.027536, val_acc: 49.21% (0.492073), val_f1: 25.96% (0.259638), test_acc: 48.74% (0.487375), test_f1: 24.58% (0.245787)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 1.049225, val_acc: 49.62% (0.496183), val_f1: 29.00% (0.289995), test_acc: 49.50% (0.495009), test_f1: 28.61% (0.286075)
Batch 180 completed in 0.02 seconds (0.00 minutes)
New best val_f1: 0.336038 (previous best: 0.326953)
loss: 1.012369, val_acc: 47.03% (0.470346), val_f1: 33.60% (0.336038), test_acc: 48.09% (0.480916), test_f1: 34.44% (0.344384)
Epoch 15 completed in 6.45 seconds (0.11 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 16
Batch 0 completed in 0.02 seconds (0.00 minutes)
loss: 0.999085, val_acc: 49.27% (0.492660), val_f1: 31.83% (0.318308), test_acc: 48.56% (0.485614), test_f1: 31.08% (0.310764)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 0.962144, val_acc: 48.62% (0.486201), val_f1: 32.65% (0.326519), test_acc: 49.03% (0.490311), test_f1: 32.82% (0.328166)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 0.977776, val_acc: 49.38% (0.493834), val_f1: 29.45% (0.294524), test_acc: 49.79% (0.497945), test_f1: 30.04% (0.300382)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 0.962215, val_acc: 49.44% (0.494422), val_f1: 28.57% (0.285709), test_acc: 49.09% (0.490898), test_f1: 27.64% (0.276424)
Epoch 16 completed in 6.62 seconds (0.11 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 17
Batch 0 completed in 0.02 seconds (0.00 minutes)
loss: 1.077508, val_acc: 47.33% (0.473282), val_f1: 33.18% (0.331838), test_acc: 48.50% (0.485026), test_f1: 34.15% (0.341531)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 0.954338, val_acc: 49.32% (0.493247), val_f1: 30.74% (0.307418), test_acc: 49.09% (0.490898), test_f1: 30.67% (0.306703)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 1.037383, val_acc: 49.21% (0.492073), val_f1: 29.90% (0.299035), test_acc: 49.32% (0.493247), test_f1: 30.22% (0.302227)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 0.984294, val_acc: 49.62% (0.496183), val_f1: 29.46% (0.294615), test_acc: 49.56% (0.495596), test_f1: 29.41% (0.294070)
Epoch 17 completed in 6.26 seconds (0.10 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 18
Batch 0 completed in 0.02 seconds (0.00 minutes)
loss: 0.967881, val_acc: 49.15% (0.491486), val_f1: 30.82% (0.308178), test_acc: 49.38% (0.493834), test_f1: 31.20% (0.312007)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 1.127836, val_acc: 49.44% (0.494422), val_f1: 31.63% (0.316318), test_acc: 48.80% (0.487962), test_f1: 30.85% (0.308483)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 0.859520, val_acc: 49.27% (0.492660), val_f1: 29.87% (0.298728), test_acc: 49.50% (0.495009), test_f1: 30.20% (0.302012)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 0.970354, val_acc: 49.32% (0.493247), val_f1: 30.81% (0.308147), test_acc: 49.15% (0.491486), test_f1: 30.73% (0.307259)
Epoch 18 completed in 6.43 seconds (0.11 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 19
[DEBUG] Sample predictions in evaluate:  tensor([2, 0, 2, 2, 2, 2, 2, 0, 2, 2], device='cuda:0')
Batch 0 completed in 0.03 seconds (0.00 minutes)
loss: 0.959112, val_acc: 49.32% (0.493247), val_f1: 30.11% (0.301085), test_acc: 49.32% (0.493247), test_f1: 30.29% (0.302928)
Batch 60 completed in 0.02 seconds (0.00 minutes)
loss: 1.027037, val_acc: 48.39% (0.483852), val_f1: 32.61% (0.326083), test_acc: 48.74% (0.487375), test_f1: 32.67% (0.326736)
Batch 120 completed in 0.02 seconds (0.00 minutes)
loss: 0.972806, val_acc: 49.15% (0.491486), val_f1: 31.14% (0.311377), test_acc: 49.15% (0.491486), test_f1: 31.05% (0.310510)
Batch 180 completed in 0.02 seconds (0.00 minutes)
loss: 1.017951, val_acc: 49.21% (0.492073), val_f1: 33.01% (0.330127), test_acc: 48.85% (0.488550), test_f1: 32.59% (0.325933)
Epoch 19 completed in 6.50 seconds (0.11 minutes)
RESULT: Max Val F1: 0.336038, Max Test F1: 0.344384
Training complete. Generating confusion matrix on the test set.
Confusion matrix saved to /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/SIMPLE-T/2025-02-07/sub-1/004_Feb-07-2025_10:43_AM/confusion_matrix.png
Reading TensorBoard loss at each epoch:
Available tags: {'images': [], 'audio': [], 'histograms': [], 'scalars': ['Loss/train_batch', 'Loss/val_log_step', 'Loss/train_epoch', 'Loss/val_epoch'], 'distributions': [], 'tensors': [], 'graph': False, 'meta_graph': False, 'run_metadata': []}
Output File: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/SIMPLE-T/2025-02-07/sub-1/004_Feb-07-2025_10:43_AM/trainval_loss_curves.png
Training and validation loss curves saved to /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/SIMPLE-T/2025-02-07/sub-1/004_Feb-07-2025_10:43_AM/trainval_loss_curves.png
Total Completion Time: 2.62 minutes. (0.04 hours) 
