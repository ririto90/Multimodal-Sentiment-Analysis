SLURM Job ID: 19847563
Number of GPUs available: 1
Python PATH: ['/home/rgg2706/Multimodal-Sentiment-Analysis/Models/SIMPLE-T/src', '/home/rgg2706/Multimodal-Sentiment-Analysis', '/Models/SIMPLE-T/src', '/.autofs/tools/spack/var/spack/environments/default-nlp-x86_64-24072401/.spack-env/._view/wtxwc3mlkmzy7fbaxlum2674jarpitc2/lib/python311.zip', '/.autofs/tools/spack/var/spack/environments/default-nlp-x86_64-24072401/.spack-env/._view/wtxwc3mlkmzy7fbaxlum2674jarpitc2/lib/python3.11', '/.autofs/tools/spack/var/spack/environments/default-nlp-x86_64-24072401/.spack-env/._view/wtxwc3mlkmzy7fbaxlum2674jarpitc2/lib/python3.11/lib-dynload', '/.autofs/tools/spack/var/spack/environments/default-nlp-x86_64-24072401/.spack-env/._view/wtxwc3mlkmzy7fbaxlum2674jarpitc2/lib/python3.11/site-packages']
Logs directory: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/SIMPLE-T/2025-02-11/sub-1/002_Feb-11-2025_05:38_PM
> training arguments:
>>> rand_seed: 8
>>> model_fusion: simpletext
>>> dataset: mvsa-mts-v3
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f29240e1440>
>>> learning_rate: 0.001
>>> dropout_rate: 0.5
>>> weight_decay: 0.0
>>> num_layers: 3
>>> num_epoch: 20
>>> batch_size: 64
>>> log_step: 60
>>> max_seq_len: 20
>>> polarities_dim: 3
>>> clip_grad: 5.0
>>> path_image: ./images
>>> crop_size: 224
>>> n_head: 8
>>> hidden_dim: 256
>>> num_classes: 3
>>> log_dir: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/SIMPLE-T/2025-02-11/sub-1/002_Feb-11-2025_05:38_PM
>>> counter: 0
>>> model_class: <class 'models.simpletext.SimpleText'>
Loading dataset 'mvsa-mts-v3':
  Train path: Datasets/MVSA-MTS/mvsa-mts-v3/train.tsv
Validation path: Datasets/MVSA-MTS/mvsa-mts-v3/val.tsv
  Test path: Datasets//MVSA-MTS/mvsa-mts-v3/test.tsv
loading word vectors...
building embedding_matrix: 200_glove_embedding_matrix.dat
-------------- Loading Datasets/MVSA-MTS/mvsa-mts-v3/train.tsv ---------------
[DEBUG] index: 706
[DEBUG] raw_text: PC Party, #Youth, #Education,Opportunity,#RenewableResources, Proudly #Canada's PCs #elxn42 http://t.co/NSwTddCHS8
[DEBUG] processed_str: pc party opportunity proudly pcs
[DEBUG] text_indices: [2 3 4 5 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
[DEBUG] polarity: 2
[DEBUG] index: 2699
[DEBUG] raw_text: Running through the 6 wit my woes #ComeTogether #BlueJays #inthe6
[DEBUG] processed_str: running through the wit my woes
[DEBUG] text_indices: [ 7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
[DEBUG] polarity: 1
[DEBUG] index: 15657
[DEBUG] raw_text: #TruckTuesday | | support@innovativeautoworx.com | 403.242.2767 | #Trucks #YYC #Calgary | http://t.co/ruwEqCd3LT
[DEBUG] processed_str: support
[DEBUG] text_indices: [13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
[DEBUG] polarity: 0
[DEBUG] index: 13219
[DEBUG] raw_text: I dont even care how ridiculous this looks #OTRAToronto is officially tomorrow and I am more than ready @onedirection
[DEBUG] processed_str: i dont even care how ridiculous this looks is officially tomorrow and i am more than ready onedirection
[DEBUG] text_indices: [14 15 16 17 18 19 20 21 22 23 24 25 14 26 27 28 29 30  0  0]
[DEBUG] polarity: 0
Time taken to load Datasets/MVSA-MTS/mvsa-mts-v3/train.tsv: 2.77 seconds(0.05 minutes)
Train classes: [0, 1, 2], count=3
[DEBUG] First 5 samples from train_data:
PC Party, #Youth, #Education,Opportunity,#RenewableResources, Proudly #Canada's PCs #elxn42 http://t.co/NSwTddCHS8 2
Running through the 6 wit my woes #ComeTogether #BlueJays #inthe6 1
#TruckTuesday | | support@innovativeautoworx.com | 403.242.2767 | #Trucks #YYC #Calgary | http://t.co/ruwEqCd3LT 0
I dont even care how ridiculous this looks #OTRAToronto is officially tomorrow and I am more than ready @onedirection 0
#Automotive alert: Manufacturing Controls... | Nexteer Automotive | #Saginaw, MI #Auto http://t.co/En5uQ7JZDL 2
[DEBUG] Train label distribution:
{0: 3522, 1: 3468, 2: 6631}
-------------- Loading Datasets/MVSA-MTS/mvsa-mts-v3/val.tsv ---------------
[DEBUG] index: 18681
[DEBUG] raw_text: ***Steven thinking about the life he just left behind with his beloved, Sam. Should he have stayed?...to be continued
[DEBUG] processed_str: steven thinking about the life he just left behind with his beloved sam should he have stayed to be continued
[DEBUG] text_indices: [ 5180  1615   777     9   825   594   339  1227   652   143   220  9092
  5368   562   594   428 15160    90    50 14601]
[DEBUG] polarity: 2
[DEBUG] index: 16242
[DEBUG] raw_text: Thanks for an amazing summer #yyc,53 organizations engaged youth in 350 projects to contribute 20000 volunteer hours!
[DEBUG] processed_str: thanks for an amazing summer organizations engaged youth in projects to contribute volunteer hours
[DEBUG] text_indices: [  567    39   498    80   655 10273 14072  2198    42  3274    90 16735
  5282  1135     0     0     0     0     0     0]
[DEBUG] polarity: 2
[DEBUG] index: 9628
[DEBUG] raw_text: HSR fares go up on Tuesday. Tickets (new issue) are $2.15. Don't be overcharged! #HamOnt #HSR https://t.co/zBxyTmcy1o
[DEBUG] processed_str: hsr fares go up on tuesday tickets new issue are do be overcharged
[DEBUG] text_indices: [ 9340 14360   413   197    69   656   528    76  1129   582   489    50
 16736     0     0     0     0     0     0     0]
[DEBUG] polarity: 1
[DEBUG] index: 6350
[DEBUG] raw_text: @Calum5SOS just saw this on my Instagram feed and instantly thought of you #JetBlackHeart #ShesKindaHotVMA
[DEBUG] processed_str: just saw this on my instagram feed and instantly thought of you
[DEBUG] text_indices: [  339  1395    20    69    11  1661  3485    25 16017   385   102   283
     0     0     0     0     0     0     0     0]
[DEBUG] polarity: 0
Time taken to load Datasets/MVSA-MTS/mvsa-mts-v3/val.tsv: 0.35 seconds(0.01 minutes)
Val classes: [0, 1, 2], count=3
[DEBUG] First 5 samples from train_data:
***Steven thinking about the life he just left behind with his beloved, Sam. Should he have stayed?...to be continued 2
Thanks for an amazing summer #yyc,53 organizations engaged youth in 350 projects to contribute 20000 volunteer hours! 2
HSR fares go up on Tuesday. Tickets (new issue) are $2.15. Don't be overcharged! #HamOnt #HSR https://t.co/zBxyTmcy1o 1
@Calum5SOS just saw this on my Instagram feed and instantly thought of you #JetBlackHeart #ShesKindaHotVMA 0
#selfiefornash @Nashgrier You've helped me get through the rough times Nash. I love you ???????? 1
[DEBUG] Train label distribution:
{0: 3522, 1: 3468, 2: 6631}
-------------- Loading Datasets//MVSA-MTS/mvsa-mts-v3/test.tsv ---------------
[DEBUG] index: 14949
[DEBUG] raw_text: Candid shot at #Montreal @FetishWeekend. #smile latex: @HWD_Latex #iLoveBiancaMondays http://t.co/eDaoHprlRP
[DEBUG] processed_str: candid shot at fetishweekend latex
[DEBUG] text_indices: [17897   297    75  7826 17898     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0]
[DEBUG] polarity: 2
[DEBUG] index: 9542
[DEBUG] raw_text: #hamont stop by and help out Lynwood Hall raise some founds with a car wash! #lynwoodhallcarwash #machealth
[DEBUG] processed_str: stop by and help out lynwood hall raise some founds with a car wash
[DEBUG] text_indices: [  394   243    25  1455    54 17899   723  2788    85 17900   143   139
   933  5787     0     0     0     0     0     0]
[DEBUG] polarity: 0
[DEBUG] index: 6309
[DEBUG] raw_text: EVEN MY NEICE WANTS TO VOTE #ShesKindaHotVMA
[DEBUG] processed_str: even my neice wants to vote
[DEBUG] text_indices: [   16    11 17901  3469    90   752     0     0     0     0     0     0
     0     0     0     0     0     0     0     0]
[DEBUG] polarity: 2
[DEBUG] index: 17974
[DEBUG] raw_text: Looks like I'm going alone ????
[DEBUG] processed_str: looks like i going alone
[DEBUG] text_indices: [  21  138   14  375 1954    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0]
[DEBUG] polarity: 2
Time taken to load Datasets//MVSA-MTS/mvsa-mts-v3/test.tsv: 0.35 seconds(0.01 minutes)
Test classes: [0, 1, 2], count=3
[DEBUG] First 5 samples from train_data:
Candid shot at #Montreal @FetishWeekend. #smile latex: @HWD_Latex #iLoveBiancaMondays http://t.co/eDaoHprlRP 2
#hamont stop by and help out Lynwood Hall raise some founds with a car wash! #lynwoodhallcarwash #machealth 0
EVEN MY NEICE WANTS TO VOTE #ShesKindaHotVMA 2
Looks like I'm going alone ???? 2
Here it comes!! @comedynest Sept 24-26 Call 514-932-6378 for reservations! #derekseguin #comedy #montreal #fun 2
[DEBUG] Train label distribution:
{0: 3522, 1: 3468, 2: 6631}
[DEBUG] 95th percentile sequence length across all splits: 17.00
Total Training Samples: 17027
Number of Training Samples: 13621
Number of Validation Samples: 1703
Number of Test Samples: 1703
Number of unique sentiment classes: 3
Building model
1
n_trainable_params: 460547, n_nontrainable_params: 0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
[DEBUG] text_indices.shape: torch.Size([64, 20])
[DEBUG] embedded_text.shape: torch.Size([64, 20, 200])
[DEBUG] lstm_output.shape: torch.Size([64, 20, 1536])
[DEBUG] h_n.shape: torch.Size([6, 64, 768])
[DEBUG] c_n.shape: torch.Size([6, 64, 768])
[DEBUG] text_features.shape: torch.Size([64, 1536])
[DEBUG] Sample predictions in evaluate:  tensor([2, 2, 0, 1, 0, 2, 0, 0, 0, 0], device='cuda:0')
[DEBUG] outputs.shape: torch.Size([64, 3])
[DEBUG] Sample of raw logits (first 5):
tensor([[ 0.3835, -1.2063,  0.6414],
        [ 0.7313, -0.2020,  1.4299],
        [ 1.2053, -0.2254,  0.9878],
        [ 0.6155,  1.9485, -0.8589],
        [ 1.1772,  0.2542,  0.3722]], device='cuda:0',
       grad_fn=<SliceBackward0>)
[DEBUG] Sample of predicted probabilities (first 5):
tensor([[0.4003, 0.0816, 0.5181],
        [0.2938, 0.1155, 0.5907],
        [0.4893, 0.1170, 0.3937],
        [0.1992, 0.7552, 0.0456],
        [0.5422, 0.2154, 0.2424]], device='cuda:0', grad_fn=<SliceBackward0>)
Batch 0 completed in 0.34 seconds (0.01 minutes)
New best val_f1: 0.135889 (previous best: 0.000000)
loss: 1.238682, val_acc: 25.60% (0.256019), val_f1: 13.59% (0.135889), test_acc: 26.42% (0.264240), test_f1: 13.93% (0.139340)
Batch 60 completed in 0.01 seconds (0.00 minutes)
New best val_f1: 0.217563 (previous best: 0.135889)
loss: 1.058131, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 1.050436, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 1.069517, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Epoch 0 completed in 3.30 seconds (0.06 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.298625, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 0.990363, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 0.988023, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 0.995011, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Epoch 1 completed in 2.93 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.048361, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 1.066506, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 1.148755, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 1.065485, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Epoch 2 completed in 2.96 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.435616, val_acc: 48.44% (0.484439), val_f1: 21.76% (0.217563), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 60 completed in 0.01 seconds (0.00 minutes)
New best val_f1: 0.263212 (previous best: 0.217563)
loss: 1.024603, val_acc: 48.62% (0.486201), val_f1: 26.32% (0.263212), test_acc: 49.15% (0.491486), test_f1: 27.04% (0.270425)
Batch 120 completed in 0.01 seconds (0.00 minutes)
New best val_f1: 0.324019 (previous best: 0.263212)
loss: 1.016891, val_acc: 48.44% (0.484439), val_f1: 32.40% (0.324019), test_acc: 49.50% (0.495009), test_f1: 33.42% (0.334190)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 1.076787, val_acc: 48.39% (0.483852), val_f1: 22.04% (0.220384), test_acc: 48.27% (0.482678), test_f1: 21.98% (0.219782)
Epoch 3 completed in 2.92 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.494544, val_acc: 48.44% (0.484439), val_f1: 21.91% (0.219076), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 1.052512, val_acc: 48.39% (0.483852), val_f1: 21.75% (0.217472), test_acc: 48.27% (0.482678), test_f1: 21.70% (0.217030)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 1.006485, val_acc: 48.44% (0.484439), val_f1: 22.05% (0.220489), test_acc: 48.27% (0.482678), test_f1: 21.98% (0.219782)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 0.992298, val_acc: 49.38% (0.493834), val_f1: 30.60% (0.306026), test_acc: 50.50% (0.504991), test_f1: 31.63% (0.316312)
Epoch 4 completed in 2.97 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.136809, val_acc: 48.74% (0.487375), val_f1: 31.62% (0.316250), test_acc: 50.85% (0.508514), test_f1: 33.60% (0.335994)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 0.962799, val_acc: 48.80% (0.487962), val_f1: 30.19% (0.301903), test_acc: 50.44% (0.504404), test_f1: 31.71% (0.317106)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 1.100720, val_acc: 49.56% (0.495596), val_f1: 29.40% (0.294015), test_acc: 49.62% (0.496183), test_f1: 29.41% (0.294064)
Batch 180 completed in 0.01 seconds (0.00 minutes)
New best val_f1: 0.335174 (previous best: 0.324019)
loss: 1.036211, val_acc: 48.74% (0.487375), val_f1: 33.52% (0.335174), test_acc: 51.44% (0.514386), test_f1: 35.74% (0.357376)
Epoch 5 completed in 2.96 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 2.371084, val_acc: 49.91% (0.499119), val_f1: 29.52% (0.295220), test_acc: 49.79% (0.497945), test_f1: 29.36% (0.293641)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 0.960995, val_acc: 49.38% (0.493834), val_f1: 27.16% (0.271639), test_acc: 49.32% (0.493247), test_f1: 27.31% (0.273069)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 1.064805, val_acc: 48.97% (0.489724), val_f1: 33.49% (0.334916), test_acc: 50.91% (0.509102), test_f1: 35.25% (0.352455)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 0.989011, val_acc: 48.91% (0.489137), val_f1: 32.75% (0.327493), test_acc: 50.85% (0.508514), test_f1: 34.36% (0.343571)
Epoch 6 completed in 2.96 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 7
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 0.990374, val_acc: 43.04% (0.430417), val_f1: 33.00% (0.330030), test_acc: 44.27% (0.442748), test_f1: 33.85% (0.338478)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 1.037449, val_acc: 48.91% (0.489137), val_f1: 31.62% (0.316172), test_acc: 50.79% (0.507927), test_f1: 33.36% (0.333617)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 0.960391, val_acc: 49.09% (0.490898), val_f1: 31.62% (0.316155), test_acc: 50.62% (0.506166), test_f1: 33.16% (0.331613)
Batch 180 completed in 0.01 seconds (0.00 minutes)
New best val_f1: 0.339077 (previous best: 0.335174)
loss: 1.026587, val_acc: 48.21% (0.482090), val_f1: 33.91% (0.339077), test_acc: 51.15% (0.511450), test_f1: 36.12% (0.361169)
Epoch 7 completed in 2.96 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 8
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.227085, val_acc: 49.09% (0.490898), val_f1: 32.89% (0.328900), test_acc: 50.97% (0.509689), test_f1: 34.61% (0.346073)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 1.079726, val_acc: 49.15% (0.491486), val_f1: 32.24% (0.322433), test_acc: 51.09% (0.510863), test_f1: 33.95% (0.339517)
Batch 120 completed in 0.01 seconds (0.00 minutes)
New best val_f1: 0.339942 (previous best: 0.339077)
loss: 1.035962, val_acc: 47.68% (0.476806), val_f1: 33.99% (0.339942), test_acc: 50.32% (0.503230), test_f1: 35.94% (0.359410)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 0.988922, val_acc: 48.97% (0.489724), val_f1: 33.19% (0.331891), test_acc: 51.03% (0.510276), test_f1: 34.92% (0.349193)
Epoch 8 completed in 2.97 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 9
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.571212, val_acc: 48.91% (0.489137), val_f1: 26.15% (0.261520), test_acc: 49.38% (0.493834), test_f1: 26.48% (0.264767)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 1.023466, val_acc: 48.91% (0.489137), val_f1: 30.59% (0.305906), test_acc: 50.03% (0.500294), test_f1: 31.67% (0.316740)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 1.067697, val_acc: 49.27% (0.492660), val_f1: 31.81% (0.318085), test_acc: 50.32% (0.503230), test_f1: 32.88% (0.328798)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 0.989762, val_acc: 49.44% (0.494422), val_f1: 31.58% (0.315838), test_acc: 50.09% (0.500881), test_f1: 32.09% (0.320924)
Epoch 9 completed in 2.96 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 10
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.370631, val_acc: 48.85% (0.488550), val_f1: 33.11% (0.331082), test_acc: 51.15% (0.511450), test_f1: 35.33% (0.353331)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 1.114479, val_acc: 49.91% (0.499119), val_f1: 30.64% (0.306410), test_acc: 50.09% (0.500881), test_f1: 31.07% (0.310722)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 1.015243, val_acc: 48.44% (0.484439), val_f1: 24.30% (0.242973), test_acc: 49.03% (0.490311), test_f1: 25.51% (0.255054)
Batch 180 completed in 0.01 seconds (0.00 minutes)
New best val_f1: 0.344744 (previous best: 0.339942)
loss: 1.067790, val_acc: 47.97% (0.479742), val_f1: 34.47% (0.344744), test_acc: 50.44% (0.504404), test_f1: 36.16% (0.361592)
Epoch 10 completed in 2.97 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 11
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.042910, val_acc: 49.62% (0.496183), val_f1: 30.64% (0.306425), test_acc: 50.26% (0.502642), test_f1: 31.48% (0.314768)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 0.954800, val_acc: 49.50% (0.495009), val_f1: 30.76% (0.307641), test_acc: 50.32% (0.503230), test_f1: 31.68% (0.316838)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 0.968150, val_acc: 49.09% (0.490898), val_f1: 32.98% (0.329811), test_acc: 51.20% (0.512038), test_f1: 34.82% (0.348234)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 0.992292, val_acc: 49.27% (0.492660), val_f1: 31.76% (0.317630), test_acc: 50.56% (0.505578), test_f1: 33.06% (0.330598)
Epoch 11 completed in 2.97 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 12
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.190658, val_acc: 49.74% (0.497358), val_f1: 30.53% (0.305281), test_acc: 50.26% (0.502642), test_f1: 31.42% (0.314196)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 0.931063, val_acc: 49.56% (0.495596), val_f1: 31.64% (0.316427), test_acc: 50.38% (0.503817), test_f1: 32.52% (0.325227)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 0.963498, val_acc: 49.74% (0.497358), val_f1: 29.05% (0.290474), test_acc: 49.62% (0.496183), test_f1: 28.49% (0.284863)
Batch 180 completed in 0.01 seconds (0.00 minutes)
New best val_f1: 0.348922 (previous best: 0.344744)
loss: 1.017712, val_acc: 46.04% (0.460364), val_f1: 34.89% (0.348922), test_acc: 46.74% (0.467410), test_f1: 35.24% (0.352352)
Epoch 12 completed in 2.96 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 13
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.065039, val_acc: 49.21% (0.492073), val_f1: 32.71% (0.327058), test_acc: 51.03% (0.510276), test_f1: 34.39% (0.343857)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 1.047402, val_acc: 49.56% (0.495596), val_f1: 31.43% (0.314327), test_acc: 50.32% (0.503230), test_f1: 32.30% (0.323004)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 1.056967, val_acc: 48.85% (0.488550), val_f1: 33.43% (0.334274), test_acc: 51.32% (0.513212), test_f1: 35.64% (0.356376)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 0.939969, val_acc: 49.74% (0.497358), val_f1: 29.99% (0.299884), test_acc: 49.97% (0.499706), test_f1: 29.98% (0.299784)
Epoch 13 completed in 2.97 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 14
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.174754, val_acc: 47.92% (0.479154), val_f1: 34.75% (0.347488), test_acc: 50.09% (0.500881), test_f1: 36.09% (0.360898)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 0.978409, val_acc: 49.32% (0.493247), val_f1: 32.63% (0.326270), test_acc: 50.79% (0.507927), test_f1: 34.04% (0.340352)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 0.978732, val_acc: 49.62% (0.496183), val_f1: 29.66% (0.296648), test_acc: 50.38% (0.503817), test_f1: 30.70% (0.306961)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 1.072832, val_acc: 49.68% (0.496770), val_f1: 30.61% (0.306095), test_acc: 50.38% (0.503817), test_f1: 31.43% (0.314325)
Epoch 14 completed in 2.97 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 15
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.086400, val_acc: 49.27% (0.492660), val_f1: 27.77% (0.277722), test_acc: 49.68% (0.496770), test_f1: 28.45% (0.284485)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 1.009678, val_acc: 48.85% (0.488550), val_f1: 32.91% (0.329148), test_acc: 50.56% (0.505578), test_f1: 34.52% (0.345196)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 0.997104, val_acc: 49.79% (0.497945), val_f1: 30.20% (0.301964), test_acc: 50.03% (0.500294), test_f1: 30.34% (0.303435)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 1.053613, val_acc: 48.91% (0.489137), val_f1: 33.45% (0.334538), test_acc: 50.85% (0.508514), test_f1: 35.29% (0.352917)
Epoch 15 completed in 3.01 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 16
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.108846, val_acc: 49.68% (0.496770), val_f1: 31.90% (0.318956), test_acc: 50.91% (0.509102), test_f1: 33.74% (0.337374)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 0.995191, val_acc: 48.21% (0.482090), val_f1: 33.30% (0.333044), test_acc: 51.03% (0.510276), test_f1: 35.76% (0.357595)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 0.959530, val_acc: 49.62% (0.496183), val_f1: 29.97% (0.299650), test_acc: 50.32% (0.503230), test_f1: 30.72% (0.307199)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 0.911260, val_acc: 49.44% (0.494422), val_f1: 32.67% (0.326697), test_acc: 50.91% (0.509102), test_f1: 34.17% (0.341733)
Epoch 16 completed in 2.92 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 17
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.165749, val_acc: 49.03% (0.490311), val_f1: 33.79% (0.337931), test_acc: 50.15% (0.501468), test_f1: 34.16% (0.341565)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 1.033077, val_acc: 49.79% (0.497945), val_f1: 31.41% (0.314111), test_acc: 50.21% (0.502055), test_f1: 31.87% (0.318675)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 1.026852, val_acc: 49.38% (0.493834), val_f1: 32.38% (0.323845), test_acc: 51.09% (0.510863), test_f1: 34.53% (0.345292)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 1.040378, val_acc: 48.44% (0.484439), val_f1: 33.73% (0.337306), test_acc: 50.73% (0.507340), test_f1: 35.56% (0.355632)
Epoch 17 completed in 2.91 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 18
Batch 0 completed in 0.01 seconds (0.00 minutes)
loss: 1.119375, val_acc: 47.97% (0.479742), val_f1: 34.10% (0.340970), test_acc: 50.68% (0.506753), test_f1: 36.26% (0.362649)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 0.937449, val_acc: 47.62% (0.476218), val_f1: 34.38% (0.343782), test_acc: 50.62% (0.506166), test_f1: 36.48% (0.364762)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 1.048699, val_acc: 49.97% (0.499706), val_f1: 30.96% (0.309617), test_acc: 50.38% (0.503817), test_f1: 31.20% (0.311970)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 0.982015, val_acc: 48.39% (0.483852), val_f1: 33.44% (0.334434), test_acc: 50.79% (0.507927), test_f1: 35.59% (0.355884)
Epoch 18 completed in 2.83 seconds (0.05 minutes)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 19
[DEBUG] Sample predictions in evaluate:  tensor([1, 0, 2, 0, 2, 2, 0, 1, 1, 0], device='cuda:0')
Batch 0 completed in 0.02 seconds (0.00 minutes)
New best val_f1: 0.365490 (previous best: 0.348922)
loss: 1.075924, val_acc: 48.21% (0.482090), val_f1: 36.55% (0.365490), test_acc: 50.21% (0.502055), test_f1: 37.70% (0.377037)
Batch 60 completed in 0.01 seconds (0.00 minutes)
loss: 1.032909, val_acc: 48.33% (0.483265), val_f1: 33.50% (0.335040), test_acc: 50.73% (0.507340), test_f1: 35.76% (0.357601)
Batch 120 completed in 0.01 seconds (0.00 minutes)
loss: 1.103678, val_acc: 49.32% (0.493247), val_f1: 33.02% (0.330216), test_acc: 51.20% (0.512038), test_f1: 35.02% (0.350239)
Batch 180 completed in 0.01 seconds (0.00 minutes)
loss: 0.995052, val_acc: 49.44% (0.494422), val_f1: 29.81% (0.298071), test_acc: 49.62% (0.496183), test_f1: 29.69% (0.296902)
Epoch 19 completed in 2.85 seconds (0.05 minutes)
RESULT: Max Val F1: 0.365490, Max Test F1: 0.377037
Training complete. Generating confusion matrix on the test set.
Confusion matrix saved to /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/SIMPLE-T/2025-02-11/sub-1/002_Feb-11-2025_05:38_PM/confusion_matrix.png
Reading TensorBoard loss at each epoch:
Available tags: {'images': [], 'audio': [], 'histograms': [], 'scalars': ['Loss/train_batch', 'Loss/val_log_step', 'Loss/train_epoch', 'Loss/val_epoch'], 'distributions': [], 'tensors': [], 'graph': False, 'meta_graph': False, 'run_metadata': []}
Output File: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/SIMPLE-T/2025-02-11/sub-1/002_Feb-11-2025_05:38_PM/trainval_loss_curves.png
Training and validation loss curves saved to /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/SIMPLE-T/2025-02-11/sub-1/002_Feb-11-2025_05:38_PM/trainval_loss_curves.png
Total Completion Time: 1.55 minutes. (0.03 hours) 
