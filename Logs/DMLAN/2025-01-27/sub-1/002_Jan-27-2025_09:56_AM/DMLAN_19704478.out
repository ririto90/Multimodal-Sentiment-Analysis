SLURM Job ID: 19704478
Number of GPUs available: 1
Logs directory: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/DMLAN/2025-01-27/sub-1/002_Jan-27-2025_09:56_AM
> training arguments:
>>> rand_seed: 8
>>> model_fusion: dmlanfusion
>>> dataset: mvsa-mts-v3-30
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7fe23c3e5440>
>>> learning_rate: 0.001
>>> dropout_rate: 0.5
>>> weight_decay: 0.0
>>> num_layers: 3
>>> num_epoch: 100
>>> batch_size: 256
>>> log_step: 60
>>> max_seq_len: 64
>>> polarities_dim: 3
>>> clip_grad: 5.0
>>> path_image: ./images
>>> crop_size: 224
>>> n_head: 8
>>> hidden_dim: 768
>>> num_classes: 3
>>> log_dir: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/DMLAN/2025-01-27/sub-1/002_Jan-27-2025_09:56_AM
>>> counter: 0
>>> model_class: <class 'models.dmlanfusion.DMLANFUSION'>
Preparing mvsa-mts-v3-30 dataset...
loading word vectors...
building embedding_matrix: 200_glove_embedding_matrix.dat
-------------- Loading Datasets/MVSA-MTS/mvsa-mts-v3-30/train.tsv ---------------
Time taken to load Datasets/MVSA-MTS/mvsa-mts-v3-30/train.tsv: 0.55 seconds (0.01 minutes)
The number of problematic samples: 0
-------------- Loading Datasets/MVSA-MTS/mvsa-mts-v3-30/train.tsv ---------------
Time taken to load Datasets/MVSA-MTS/mvsa-mts-v3-30/train.tsv: 0.13 seconds (0.00 minutes)
The number of problematic samples: 0
-------------- Loading Datasets/MVSA-MTS/mvsa-mts-v3-30/train.tsv ---------------
Time taken to load Datasets/MVSA-MTS/mvsa-mts-v3-30/train.tsv: 0.13 seconds (0.00 minutes)
The number of problematic samples: 0
Total Training Samples: 72
Number of Training Samples: 24
Number of Validation Samples: 24
Number of Test Samples: 24
Number of unique sentiment classes: 3
Building model
n_trainable_params: 2297703, n_nontrainable_params: 0
No weight decay
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
targets.shape: torch.Size([24]) targets.dtype: torch.int64
0
text_features: torch.Size([24, 64, 1536]) image_features: torch.Size([24, 2048, 8, 8])
batch_size: 24 C: 2048 H: 8 W: 8
avg_pool: torch.Size([24, 2048]) max_pool: torch.Size([24, 2048])
avg_pool_proj: torch.Size([24, 256]) max_pool_proj: torch.Size([24, 256])
channel_attention: torch.Size([24, 256, 1, 1])
